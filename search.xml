<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Spring事务]]></title>
    <url>%2F2019%2F09%2F26%2FSpring%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Spring事务Spring在TransactionDefinition接口中规定了7种类型的事务传播行为。事务传播行为是Spring框架独有的事务增强特性，他不属于的事务实际提供方数据库行为。这是Spring为我们提供的强大的工具箱，使用事务传播行可以为我们的开发工作提供许多便利。但是人们对他的误解也颇多，你一定也听过“service方法事务最好不要嵌套”的传言。要想正确的使用工具首先需要了解工具。本文对七种事务传播行为做详细介绍，内容主要代码示例的方式呈现。 基础概念什么是事务传播行为？事务传播行为用来描述由某一个事务传播行为修饰的方法被嵌套进另一个方法的时事务如何传播。 用伪代码说明： public void methodA(){ methodB(); //doSomething } @Transaction(Propagation=XXX) public void methodB(){ //doSomething } 代码中methodA()方法嵌套调用了methodB()方法，methodB()的事务传播行为由@Transaction(Propagation=XXX)设置决定。这里需要注意的是methodA()并没有开启事务，某一个事务传播行为修饰的方法并不是必须要在开启事务的外围方法中调用。 事务的7种传播级别 PROPAGATION_REQUIRED如果存在一个事务，则支持当前事务。如果没有事务则开启一个新的事务。可以把事务想像成一个胶囊，在这个场景下方法B用的是方法A产生的胶囊（事务）。 @Transactional(propagation = Propagation.REQUIRED) public void methodA() { methodB(); // do something } @Transactional(propagation = Propagation.REQUIRED) public void methodB() { // do something } 单独调用methodB方法时，因为当前上下文不存在事务，所以会开启一个新的事务。调用methodA方法时，因为当前上下文不存在事务，所以会开启一个新的事务。当执行到methodB时，methodB发现当前上下文有事务，因此就加入到当前事务中来。 PROPAGATION_SUPPORTS如果存在一个事务，支持当前事务。如果没有事务，则非事务的执行。但是对于事务同步的事务管理器，PROPAGATION_SUPPORTS与不使用事务有少许不同。举例有两个方法： @Transactional(propagation = Propagation.REQUIRED) public void methodA() { methodB(); // do something } // 事务属性为SUPPORTS @Transactional(propagation = Propagation.SUPPORTS) public void methodB() { // do something } 单纯的调用methodB时，methodB方法是非事务的执行的。当调用methdA时,methodB则加入了methodA的事务中,事务地执行。 PROPAGATION_MANDATORY如果已经存在一个事务，支持当前事务。如果没有一个活动的事务，则抛出异常。 @Transactional(propagation = Propagation.REQUIRED) public void methodA() { methodB(); // do something } // 事务属性为MANDATORY @Transactional(propagation = Propagation.MANDATORY) public void methodB() { // do something } 当单独调用methodB时，因为当前没有一个活动的事务，则会抛出异常throw new IllegalTransactionStateException(“Transaction propagation ‘mandatory’ but no existing transaction found”);当调用methodA时，methodB则加入到methodA的事务中，事务地执行。 PROPAGATION_REQUIRES_NEW 使用PROPAGATION_REQUIRES_NEW,需要使用 JtaTransactionManager作为事务管理器。它会开启一个新的事务。如果一个事务已经存在，则先将这个存在的事务挂起。 @Transactional(propagation = Propagation.REQUIRED) public void methodA() { doSomeThingA(); methodB(); doSomeThingB(); // do something else } // 事务属性为REQUIRES_NEW @Transactional(propagation = Propagation.REQUIRES_NEW) public void methodB() { // do something } 当调用 main{methodA();} 相当于调用 main(){ TransactionManager tm = null; try{ //获得一个JTA事务管理器 tm = getTransactionManager(); tm.begin();//开启一个新的事务 Transaction ts1 = tm.getTransaction(); doSomeThing(); tm.suspend();//挂起当前事务 try{ tm.begin();//重新开启第二个事务 Transaction ts2 = tm.getTransaction(); methodB(); ts2.commit();//提交第二个事务 } Catch(RunTimeException ex) { ts2.rollback();//回滚第二个事务 } finally { //释放资源 } //methodB执行完后，恢复第一个事务 tm.resume(ts1); doSomeThingB(); ts1.commit();//提交第一个事务 } catch(RunTimeException ex) { ts1.rollback();//回滚第一个事务 } finally { //释放资源 } } 在这里，我把ts1称为外层事务，ts2称为内层事务。从上面的代码可以看出，ts2与ts1是两个独立的事务，互不相干。Ts2是否成功并不依赖于 ts1。如果methodA方法在调用methodB方法后的doSomeThingB方法失败了，而methodB方法所做的结果依然被提交。而除了 methodB之外的其它代码导致的结果却被回滚了 PROPAGATION_NOT_SUPPORTEDPROPAGATION_NOT_SUPPORTED 总是非事务地执行，并挂起任何存在的事务。使用PROPAGATION_NOT_SUPPORTED,也需要使用JtaTransactionManager作为事务管理器。 PROPAGATION_NEVER总是非事务地执行，如果存在一个活动事务，则抛出异常。 PROPAGATION_NESTED 如果一个活动的事务存在，则运行在一个嵌套的事务中。 如果没有活动事务, 则按TransactionDefinition.PROPAGATION_REQUIRED 属性执行。这是一个嵌套事务,使用JDBC 3.0驱动时,仅仅支持DataSourceTransactionManager作为事务管理器。需要JDBC 驱动的java.sql.Savepoint类。使用PROPAGATION_NESTED，还需要把PlatformTransactionManager的nestedTransactionAllowed属性设为true(属性值默认为false)。 这里关键是嵌套执行。 @Transactional(propagation = Propagation.REQUIRED) methodA(){ doSomeThingA(); methodB(); doSomeThingB(); } @Transactional(propagation = Propagation.NEWSTED) methodB(){ …… } 如果单独调用methodB方法，则按REQUIRED属性执行。如果调用methodA方法，相当于下面的效果： main(){ Connection con = null; Savepoint savepoint = null; try{ con = getConnection(); con.setAutoCommit(false); doSomeThingA(); savepoint = con2.setSavepoint(); try{ methodB(); } catch(RuntimeException ex) { con.rollback(savepoint); } finally { //释放资源 } doSomeThingB(); con.commit(); } catch(RuntimeException ex) { con.rollback(); } finally { //释放资源 } } 当methodB方法调用之前，调用setSavepoint方法，保存当前的状态到savepoint。如果methodB方法调用失败，则恢复到之前保存的状态。但是需要注意的是，这时的事务并没有进行提交，如果后续的代码(doSomeThingB()方法)调用失败，则回滚包括methodB方法的所有操作。嵌套事务一个非常重要的概念就是内层事务依赖于外层事务。外层事务失败时，会回滚内层事务所做的动作。而内层事务操作失败并不会引起外层事务的回滚。 PROPAGATION_NESTED 与PROPAGATION_REQUIRES_NEW的区别:它们非常类似,都像一个嵌套事务，如果不存在一个活动的事务，都会开启一个新的事务。使用 PROPAGATION_REQUIRES_NEW时，内层事务与外层事务就像两个独立的事务一样，一旦内层事务进行了提交后，外层事务不能对其进行回滚。两个事务互不影响。两个事务不是一个真正的嵌套事务。同时它需要JTA事务管理器的支持。 使用PROPAGATION_NESTED时，外层事务的回滚可以引起内层事务的回滚。而内层事务的异常并不会导致外层事务的回滚，它是一个真正的嵌套事务。DataSourceTransactionManager使用savepoint支持PROPAGATION_NESTED时，需要JDBC 3.0以上驱动及1.4以上的JDK版本支持。其它的JTATrasactionManager实现可能有不同的支持方式。 PROPAGATION_REQUIRES_NEW 启动一个新的, 不依赖于环境的 “内部” 事务. 这个事务将被完全 commited 或 rolled back 而不依赖于外部事务, 它拥有自己的隔离范围, 自己的锁, 等等. 当内部事务开始执行时, 外部事务将被挂起, 内务事务结束时, 外部事务将继续执行。 另一方面, PROPAGATION_NESTED 开始一个 “嵌套的” 事务, 它是已经存在事务的一个真正的子事务. 潜套事务开始执行时, 它将取得一个 savepoint. 如果这个嵌套事务失败, 我们将回滚到此 savepoint. 潜套事务是外部事务的一部分, 只有外部事务结束后它才会被提交。 由此可见, PROPAGATION_REQUIRES_NEW 和 PROPAGATION_NESTED 的最大区别在于, PROPAGATION_REQUIRES_NEW 完全是一个新的事务, 而 PROPAGATION_NESTED 则是外部事务的子事务, 如果外部事务 commit, 嵌套事务也会被 commit, 这个规则同样适用于 roll back. 数据隔离级别但是除了传播级别，在读取数据库的过程中，如果两个事务并发执行，那么彼此之间的数据是如何影响的呢？ 这就需要了解一下事务的另一个特性：数据隔离级别 数据隔离级别分为不同的四种： 1、Serializable ：最严格的级别，事务串行执行，资源消耗最大； 2、REPEATABLE READ ：保证了一个事务不会修改已经由另一个事务读取但未提交（回滚）的数据。避免了“脏读取”和“不可重复读取”的情况，但是带来了更多的性能损失。 3、READ COMMITTED :大多数主流数据库的默认事务等级，保证了一个事务不会读到另一个并行事务已修改但未提交的数据，避免了“脏读取”。该级别适用于大多数系统。 4、Read Uncommitted ：保证了读取过程中不会读取到非法数据。 上面的解释其实每个定义都有一些拗口，其中涉及到几个术语：脏读、不可重复读、幻读。这里解释一下： 脏读 :所谓的脏读，其实就是读到了别的事务回滚前的脏数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。 不可重复读 ：不可重复读字面含义已经很明了了，比如事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。 幻读 ：小的时候数手指，第一次数十10个，第二次数是11个，怎么回事？产生幻觉了？幻读也是这样子，事务A首先根据条件索引得到10条数据，然后事务B改变了数据库一条数据，导致也符合事务A当时的搜索条件，这样事务A再次搜索发现有11条数据了，就产生了幻读。 一个对照关系表： Dirty reads non-repeatable reads phantom reads Serializable 不会 不会 不会 REPEATABLE READ 不会 不会 会 READ COMMITTED 不会 会 会 Read Uncommitted 会 会 会 所以最安全的，是Serializable，但是伴随而来也是高昂的性能开销。另外，事务常用的两个属性：readonly和timeout一个是设置事务为只读以提升性能。另一个是设置事务的超时时间，一般用于防止大事务的发生。还是那句话，事务要尽可能的小！ 最后引入一个问题一个逻辑操作需要检查的条件有20条，能否为了减小事务而将检查性的内容放到事务之外呢？ 很多系统都是在DAO的内部开始启动事务，然后进行操作，最后提交或者回滚。这其中涉及到代码设计的问题。小一些的系统可以采用这种方式来做，但是在一些比较大的系统，逻辑较为复杂的系统中，势必会将过多的业务逻辑嵌入到DAO中，导致DAO的复用性下降。所以这不是一个好的实践。 来回答这个问题：能否为了缩小事务，而将一些业务逻辑检查放到事务外面？答案是：对于核心的业务检查逻辑，不能放到事务之外，而且必须要作为分布式下的并发控制！一旦在事务之外做检查，那么势必会造成事务A已经检查过的数据被事务B所修改，导致事务A徒劳无功而且出现并发问题，直接导致业务控制失败。所以，在分布式的高并发环境下，对于核心业务逻辑的检查，要采用加锁机制。比如事务开启需要读取一条数据进行验证，然后逻辑操作中需要对这条数据进行修改，最后提交。这样的一个过程，如果读取并验证的代码放到事务之外，那么读取的数据极有可能已经被其他的事务修改，当前事务一旦提交，又会重新覆盖掉其他事务的数据，导致数据异常。所以在进入当前事务的时候，必须要将这条数据锁住，使用for update就是一个很好的在分布式环境下的控制手段。 一种好的实践方式是使用编程式事务而非生命式，尤其是在较为规模的项目中。对于事务的配置，在代码量非常大的情况下，将是一种折磨，而且人肉的方式，绝对不能避免这种问题。将DAO保持针对一张表的最基本操作，然后业务逻辑的处理放入manager和service中进行，同时使用编程式事务更精确的控制事务范围。 特别注意的，对于事务内部一些可能抛出异常的情况，捕获要谨慎，不能随便的catch Exception 导致事务的异常被吃掉而不能正常回滚。 Spring配置声明式事务Spring配置声明式事务： 配置DataSource 配置事务管理器 事务的传播特性 那些类那些方法使用事务 Spring配置文件中关于事务配置总是由三个组成部分，分别是DataSource、TransactionManager和代理机制这三部分，无论哪种配置方式，一般变化的只是代理机制这部分。 DataSource、TransactionManager这两部分只是会根据数据访问方式有所变化， 比如使用Hibernate进行数据访问 时，DataSource实际为SessionFactory，TransactionManager的实现为 HibernateTransactionManage 根据代理机制的不同，Spring事务的配置又有几种不同的方式： 第一种方式：每个Bean都有一个代 第二种方式：所有Bean共享一个代理基类 第三种方式：使用拦截器 第四种方式：使用tx标签配置的拦截器 第五种方式：全注解]]></content>
      <categories>
        <category>spring事务传播</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA并发之各种锁]]></title>
    <url>%2F2019%2F09%2F22%2FJAVA%E5%B9%B6%E5%8F%91%E4%B9%8B%E5%90%84%E7%A7%8D%E9%94%81%2F</url>
    <content type="text"><![CDATA[JAVA并发之各种锁锁作为并发共享数据，保证一致性的工具，在JAVA平台有多种实现(如 synchronized 和 ReentrantLock等等 ) 。这些已经写好提供的锁为我们开发提供了便利，但是锁的具体性质以及类型却很少被提及。 主要有： 1、 公平锁 / 非公平锁 2、 可重入锁 / 不可重入锁 3、 独享锁 / 共享锁 4、 互斥锁 / 读写锁 5、 乐观锁 / 悲观锁 6、 分段锁 7、 偏向锁 / 轻量级锁 / 重量级锁 8、 自旋锁 / 自旋锁的其他种类 公平锁/非公平锁公平锁公平锁是指多个线程按照申请锁的顺序来获取锁。 非公平锁非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。 对于Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。 对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。 可重入锁 / 不可重入锁可重入锁广义上的可重入锁指的是可重复可递归调用的锁，在外层使用锁之后，在内层仍然可以使用，并且不发生死锁（前提得是同一个对象或者class），这样的锁就叫做可重入锁。ReentrantLock和synchronized都是可重入锁 synchronized void setA() throws Exception{ Thread.sleep(1000); setB(); } synchronized void setB() throws Exception{ Thread.sleep(1000); } 上面的代码就是一个可重入锁的一个特点，如果不是可重入锁的话，setB可能不会被当前线程执行，可能造成死锁。 不可重入锁不可重入锁，与可重入锁相反，不可递归调用，递归调用就发生死锁。看到一个经典的讲解，使用自旋锁来模拟一个不可重入锁，代码如下 public class UnreentrantLock { private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;Thread&gt;(); public void lock() { Thread current = Thread.currentThread(); //这句是很经典的“自旋”语法，AtomicInteger中也有 for (;;) { if (!owner.compareAndSet(null, current)) { return; } } } public void unlock() { Thread current = Thread.currentThread(); owner.compareAndSet(current, null); } } 代码也比较简单，使用原子引用来存放线程，同一线程两次调用lock()方法，如果不执行unlock()释放锁的话，第二次调用自旋的时候就会产生死锁，这个锁就不是可重入的，而实际上同一个线程不必每次都去释放锁再来获取锁，这样的调度切换是很耗资源的。 把它变成一个可重入锁： public class UnreentrantLock { private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;Thread&gt;(); private int state = 0; public void lock() { Thread current = Thread.currentThread(); if (current == owner.get()) { state++; return; } //这句是很经典的“自旋”式语法，AtomicInteger中也有 for (;;) { if (!owner.compareAndSet(null, current)) { return; } } } public void unlock() { Thread current = Thread.currentThread(); if (current == owner.get()) { if (state != 0) { state--; } else { owner.compareAndSet(current, null); } } } } 在执行每次操作之前，判断当前锁持有者是否是当前对象，采用state计数，不用每次去释放锁。 ReentrantLock中可重入锁实现 这里看非公平锁的锁获取方法： final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //就是这里 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } 在AQS中维护了一个private volatile int state来计数重入次数，避免了频繁的持有释放操作，这样既提升了效率，又避免了死锁。 独享锁 / 共享锁独享锁和共享锁在你去读C.U.T包下的ReeReentrantLock和ReentrantReadWriteLock你就会发现，它俩一个是独享一个是共享锁。 独享锁该锁每一次只能被一个线程所持有。 共享锁该锁可被多个线程共有，典型的就是ReentrantReadWriteLock里的读锁，它的读锁是可以被共享的，但是它的写锁确每次只能被独占 另外读锁的共享可保证并发读是非常高效的，但是读写和写写，写读都是互斥的。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 对于Synchronized而言，当然是独享锁。 互斥锁 / 读写锁互斥锁在访问共享资源之前对进行加锁操作，在访问完成之后进行解锁操作。 加锁后，任何其他试图再次加锁的线程会被阻塞，直到当前进程解锁。 如果解锁时有一个以上的线程阻塞，那么所有该锁上的线程都被编程就绪状态， 第一个变为就绪状态的线程又执行加锁操作，那么其他的线程又会进入等待。 在这种方式下，只有一个线程能够访问被互斥锁保护的资源 读写锁读写锁既是互斥锁，又是共享锁，read模式是共享，write是互斥(排它锁)的。 读写锁有三种状态：读加锁状态、写加锁状态和不加锁状态 读写锁在Java中的具体实现就是ReadWriteLock 一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁。 只有一个线程可以占有写状态的锁，但可以有多个线程同时占有读状态锁，这也是它可以实现高并发的原因。当其处于写状态锁下，任何想要尝试获得锁的线程都会被阻塞，直到写状态锁被释放；如果是处于读状态锁下，允许其它线程获得它的读状态锁，但是不允许获得它的写状态锁，直到所有线程的读状态锁被释放；为了避免想要尝试写操作的线程一直得不到写状态锁，当读写锁感知到有线程想要获得写状态锁时，便会阻塞其后所有想要获得读状态锁的线程。所以读写锁非常适合资源的读操作远多于写操作的情况。 乐观锁 / 悲观锁悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。 乐观锁总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 分段锁分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 并发容器类的加锁机制是基于粒度更小的分段锁，分段锁也是提升多并发程序性能的重要手段之一。 在并发程序中，串行操作是会降低可伸缩性，并且上下文切换也会减低性能。在锁上发生竞争时将通水导致这两种问题，使用独占锁时保护受限资源的时候，基本上是采用串行方式—-每次只能有一个线程能访问它。所以对于可伸缩性来说最大的威胁就是独占锁。 我们一般有三种方式降低锁的竞争程度： 1、减少锁的持有时间 2、降低锁的请求频率 3、使用带有协调机制的独占锁，这些机制允许更高的并发性。 在某些情况下我们可以将锁分解技术进一步扩展为一组独立对象上的锁进行分解，这成为分段锁。 其实说的简单一点就是： 容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 比如：在ConcurrentHashMap中使用了一个包含16个锁的数组，每个锁保护所有散列桶的1/16，其中第N个散列桶由第（N mod 16）个锁来保护。假设使用合理的散列算法使关键字能够均匀的分部，那么这大约能使对锁的请求减少到越来的1/16。也正是这项技术使得ConcurrentHashMap支持多达16个并发的写入线程。 偏向锁 / 轻量级锁 / 重量级锁锁的状态： 1.无锁状态 2.偏向锁状态 3.轻量级锁状态 4.重量级锁状态 锁的状态是通过对象监视器在对象头中的字段来表明的。 四种状态会随着竞争的情况逐渐升级，而且是不可逆的过程，即不可降级。 这四种状态都不是Java语言中的锁，而是Jvm为了提高锁的获取与释放效率而做的优化(使用synchronized时)。 偏向锁偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。 轻量级轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。 重量级锁重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。 自旋锁我们知道CAS算法是乐观锁的一种实现方式，CAS算法中又涉及到自旋锁，所以这里给大家讲一下什么是自旋锁。 简单回顾一下CAS算法 CAS是英文单词Compare and Swap（比较并交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数 1.需要读写的内存值 V 2.进行比较的值 A 3.拟写入的新值 B 更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B，否则不会执行任何操作。一般情况下是一个自旋操作，即不断的重试。 什么是自旋锁？ 自旋锁（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。 它是为实现保护共享资源而提出一种锁机制。其实，自旋锁与互斥锁比较类似，它们都是为了解决对某项资源的互斥使用。无论是互斥锁，还是自旋锁，在任何时刻，最多只能有一个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁。但是两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，”自旋”一词就是因此而得名。 Java如何实现自旋锁？ 下面是个简单的例子： public class SpinLock { private AtomicReference&lt;Thread&gt; sign =new AtomicReference&lt;&gt;(); public void lock(){ Thread current = Thread.currentThread(); while(!sign .compareAndSet(null, current)){ } } public void unlock (){ Thread current = Thread.currentThread(); sign .compareAndSet(current, null); } } 使用了CAS原子操作，lock函数将owner设置为当前线程，并且预测原来的值为空。unlock函数将owner设置为null，并且预测值为当前线程。 当有第二个线程调用lock操作时由于owner值不为空，导致循环一直被执行，直至第一个线程调用unlock函数将owner设置为null，第二个线程才能进入临界区。 由于自旋锁只是将当前线程不停地执行循环体，不进行线程状态的改变，所以响应速度更快。但当线程数不停增加时，性能下降明显，因为每个线程都需要执行，占用CPU时间。如果线程竞争不激烈，并且保持锁的时间段。适合使用自旋锁。 注：该例子为非公平锁，获得锁的先后顺序，不会按照进入lock的先后顺序进行。 lock（)方法利用的CAS，当第一个线程A获取锁的时候，能够成功获取到，不会进入while循环，如果此时线程A没有释放锁，另一个线程B又来获取锁，此时由于不满足CAS，所以就会进入while循环，不断判断是否满足CAS，直到A线程调用unlock方法释放了该锁。 自旋锁存在的问题 1、如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。 2、上面Java实现的自旋锁不是公平的，即无法满足等待时间最长的线程优先获取锁。不公平的锁就会存在“线程饥饿”问题。 自旋锁的优点 1、自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快 2、非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能） 可重入的自旋锁和不可重入的自旋锁 文章开始的时候的那段代码，仔细分析一下就可以看出，它是不支持重入的，即当一个线程第一次已经获取到了该锁，在锁释放之前又一次重新获取该锁，第二次就不能成功获取到。由于不满足CAS，所以第二次获取会进入while循环等待，而如果是可重入锁，第二次也是应该能够成功获取到的。 而且，即使第二次能够成功获取，那么当第一次释放锁的时候，第二次获取到的锁也会被释放，而这是不合理的。 为了实现可重入锁，我们需要引入一个计数器，用来记录获取锁的线程数。 public class ReentrantSpinLock { private AtomicReference&lt;Thread&gt; cas = new AtomicReference&lt;Thread&gt;(); private int count; public void lock() { Thread current = Thread.currentThread(); if (current == cas.get()) { // 如果当前线程已经获取到了锁，线程数增加一，然后返回 count++; return; } // 如果没获取到锁，则通过CAS自旋 while (!cas.compareAndSet(null, current)) { // DO nothing } } public void unlock() { Thread cur = Thread.currentThread(); if (cur == cas.get()) { if (count &gt; 0) {// 如果大于0，表示当前线程多次获取了该锁，释放锁通过count减一来模拟 count--; } else {// 如果count==0，可以将锁释放，这样就能保证获取锁的次数与释放锁的次数是一致的了。 cas.compareAndSet(cur, null); } } } } 自旋锁的其他种类自旋锁中 另有三种常见的锁形式:TicketLock ，CLHlock 和MCSlock Ticket锁主要解决的是访问顺序的问题，主要的问题是在多核cpu上 public class TicketLock { private AtomicInteger serviceNum = new AtomicInteger(); private AtomicInteger ticketNum = new AtomicInteger(); private static final ThreadLocal&lt;Integer&gt; LOCAL = new ThreadLocal&lt;Integer&gt;(); public void lock() { int myticket = ticketNum.getAndIncrement(); LOCAL.set(myticket); while (myticket != serviceNum.get()) { } } public void unlock() { int myticket = LOCAL.get(); serviceNum.compareAndSet(myticket, myticket + 1); } } 每次都要查询一个serviceNum 服务号，影响性能（必须要到主内存读取，并阻止其他cpu修改）。 CLHLock 和MCSLock 则是两种类型相似的公平锁，采用链表的形式进行排序， public class CLHLock { public static class CLHNode { private volatile boolean isLocked = true; } @SuppressWarnings(&quot;unused&quot;) private volatile CLHNode tail; private static final ThreadLocal&lt;CLHNode&gt; LOCAL = new ThreadLocal&lt;CLHNode&gt;(); private static final AtomicReferenceFieldUpdater&lt;CLHLock, CLHNode&gt; UPDATER = AtomicReferenceFieldUpdater.newUpdater(CLHLock.class, CLHNode.class, &quot;tail&quot;); public void lock() { CLHNode node = new CLHNode(); LOCAL.set(node); CLHNode preNode = UPDATER.getAndSet(this, node); if (preNode != null) { while (preNode.isLocked) { } preNode = null; LOCAL.set(node); } } public void unlock() { CLHNode node = LOCAL.get(); if (!UPDATER.compareAndSet(this, node, null)) { node.isLocked = false; } node = null; } } CLHlock是不停的查询前驱变量， 导致不适合在NUMA 架构下使用（在这种结构下，每个线程分布在不同的物理内存区域） MCSLock则是对本地变量的节点进行循环。不存在CLHlock 的问题。 public class MCSLock { public static class MCSNode { volatile MCSNode next; volatile boolean isLocked = true; } private static final ThreadLocal&lt;MCSNode&gt; NODE = new ThreadLocal&lt;MCSNode&gt;(); @SuppressWarnings(&quot;unused&quot;) private volatile MCSNode queue; private static final AtomicReferenceFieldUpdater&lt;MCSLock, MCSNode&gt; UPDATER = AtomicReferenceFieldUpdater.newUpdater(MCSLock.class, MCSNode.class, &quot;queue&quot;); public void lock() { MCSNode currentNode = new MCSNode(); NODE.set(currentNode); MCSNode preNode = UPDATER.getAndSet(this, currentNode); if (preNode != null) { preNode.next = currentNode; while (currentNode.isLocked) { } } } public void unlock() { MCSNode currentNode = NODE.get(); if (currentNode.next == null) { if (UPDATER.compareAndSet(this, currentNode, null)) { } else { while (currentNode.next == null) { } } } else { currentNode.next.isLocked = false; currentNode.next = null; } } } 从代码上 看，CLH 要比 MCS 更简单， CLH 的队列是隐式的队列，没有真实的后继结点属性。 MCS 的队列是显式的队列，有真实的后继结点属性。 JUC ReentrantLock 默认内部使用的锁 即是 CLH锁（有很多改进的地方，将自旋锁换成了阻塞锁等等）。 自旋锁与互斥锁1.自旋锁与互斥锁都是为了实现保护资源共享的机制。 2.无论是自旋锁还是互斥锁，在任意时刻，都最多只能有一个保持者。 3获取互斥锁的线程，如果锁已经被占用，则该线程将进入睡眠状态；获取自旋锁的线程则不会睡眠，而是一直循环等待锁释放。 自旋锁总结 1.自旋锁：线程获取锁的时候，如果锁被其他线程持有，则当前线程将循环等待，直到获取到锁。 2.自旋锁等待期间，线程的状态不会改变，线程一直是用户态并且是活动的(active)。 3.自旋锁如果持有锁的时间太长，则会导致其它等待获取锁的线程耗尽CPU。 4.自旋锁本身无法保证公平性，同时也无法保证可重入性。 5.基于自旋锁，可以实现具备公平性和可重入性质的锁。]]></content>
      <categories>
        <category>多线程</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java对象在Java虚拟机中的创建过程]]></title>
    <url>%2F2019%2F09%2F21%2FJava%E5%AF%B9%E8%B1%A1%E5%9C%A8Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%AD%E7%9A%84%E5%88%9B%E5%BB%BA%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Java对象在Java虚拟机中的创建过程下面我们详细了解Java程序中new一个普通对象时，HotSpot虚拟机是怎么样创建这个对象的，包括5个步骤：相应类加载检查过程、在Java堆中为对象分配内存、分配后内存初始化为零、对对象进行必要的设置、以及执行对象实例方法，最后我们再从JVM指令角度来解释下Java对象创建。 相应类加载检查过程 JVM（本文特指HotSpot）遇到new指令时，先检查指令参数是否能在常量池中定位到一个类的符号引用： （A）、如果能定位到，检查这个符号引用代表的类是否已被加载、解析和初始化过； （B）、如果不能定位到，或没有检查到，就先执行相应的类加载过程； 为对象分配内存对象所需内存的大小在类加载完成后便完全确定（JVM可以通过普通Java对象的类元数据信息确定对象大小）； 为对象分配内存相当于把一块确定大小的内存从Java堆里划分出来； （A）、分配方式： （I）、指针碰撞 如果Java堆是绝对规整的：一边是用过的内存，一边是空闲的内存，中间一个指针作为边界指示器； 分配内存只需向空闲那边移动指针，这种分配方式称为&quot;指针碰撞&quot;（Bump the Pointer）； （II）、空闲列表 如果Java堆不是规整的：用过的和空闲的内存相互交错； 需要维护一个列表，记录哪些内存可用； 分配内存时查表找到一个足够大的内存，并更新列表，这种分配方式称为&quot;空闲列表&quot;（Free List）； Java堆是否规整由JVM采用的垃圾收集器是否带有压缩功能决定的； 所以，使用Serial、ParNew等带Compact过程的收集器时，JVM采用指针碰撞方式分配内存；而使用CMS这种基于标记-清除（Mark-Sweep）算法的收集器时，采用空闲列表方式； 后面再介绍垃圾收集算法和垃圾收集器，了解垃圾收集时应注意这里的内容； （B）、线程安全问题 并发时，上面两种方式分配内存的操作都不是线程安全的，有两种解决方案： （I）、同步处理 对分配内存的动作进行同步处理： JVM采用CAS（Compare and Swap）机制加上失败重试的方式，保证更新操作的原子性； CAS：有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做； （II）、本地线程分配缓冲区 把分配内存的动作按照线程划分在不同的空间中进行： 在每个线程在Java堆预先分配一小块内存，称为本地线程分配缓冲区（Thread Local Allocation Buffer,TLAB）； 哪个线程需要分配内存就从哪个线程的TLAB上分配； 只有TLAB用完需要分配新的TLAB时，才需要同步处理； JVM通过”-XX：+/-UseTLAB”指定是否使用TLAB； 对象内存初始化为零对象内存初始化为零，但不包括对象头； 如果使用TLAB，提前至分配TLAB时； 这保证了程序中对象（及实例变量）不显式初始赋零值，程序也能访问到零值； 对象内存初始化为零 主要设置对象头信息，包括类元数据引用、对象的哈希码、对象的GC分代年龄等（详见下节）； 执行对象实例方法该方法把对象（实例变量）按照程序中定义的初始赋值进行初始化；通常，经过上面5步对象才完全new出来。另外，还可以参考HotSpot虚拟机源码中的”bytecodeInterpreter.cpp”文件，这个文件有表示解释器处理”new”指令基本类似上面的5个过程。 Java对象创建的JVM指令通过前面一些文章，我们还可以从JVM指令的角度来看对象的创建过程：（A）、new指令 &quot;new&quot;指令有一个类符号引用的常量，JVM解析该常量也就对应步骤1&quot;相应类加载检查过程&quot;； &quot;new&quot;指令执行完毕后，一个代表（指向）该对象实例内存数据的reference类型变量数据将压入到操作数栈中； （B）、dup指令 接着会执行&quot;dup&quot;指令复制该reference数据，这时操作数栈栈顶就有两个指向该对象实例内存的reference数据；（如果&lt;init&gt;方法有参数，还需要把参数加载到操作栈） （C）、invokespecial指令 再执行&quot;invokespecial&quot;指令调用对象实例方法&lt;init&gt;，这时操作数栈最上面的一个reference数据会出栈（如果有参数，包括方法参数）； 然后在Java虚拟机栈中创建&lt;init&gt;方法的栈帧，把出栈的reference数据（和参数）放入该栈帧的局部变量表中，该reference数据在方法中也就是&quot;this&quot;，表示对该对象实例进行的操作； 当然这些参数的数值、数据类型和顺序都必须遵循实例方法的描述符中的描述； 另外，操作数栈中还有一个对象reference数据一般被“astore”到局部变量表或保存到字段变量，给后面访问对象使用。]]></content>
      <categories>
        <category>jvm基础</category>
        <category>对象创建</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存管理]]></title>
    <url>%2F2019%2F09%2F21%2FJava%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Java内存管理Java内存区域概述C/C++与Java程序开发的内存管理 在内存管理领域，C/C++程序开发与Java程序开发有着完全不同的理念： 1、C/C++程序开发 自己管理内存是一项基础的工作； 自已分配内存，但也得自己来及时回收； 比较自由，但多了些工作量，且容易出现内存泄露和内存溢出等问题； 2、Java程序开发 JVM管理内存，不需要自己手动分配内存和释放内存； 不容易出现内存泄露和内存溢出； 一旦出现问题不容易排查，所以得了解JVM是怎么使用内存； Java内存区域与JVM运行时数据区 如上图， Java虚拟机规范定义了字节码执行期间使用的各种运行时数据区，即JVM在执行Java程序的过程中，会把它管理的内存划分为若干个不同的数据区域，包括： 程序计数器、java虚拟机栈、本地方法栈、java堆、方法区、运行时常量池； 从线程共享角度来说，可以分为两类： 1、所有线程共享的数据区 方法区、运行时常量池、java堆； 这些数据区域是在Java虚拟机启动时创建的，只有当Java虚拟机退出时才会被销毁； 2、线程间隔离的数据区 程序计数器、java虚拟机栈、本地方法栈、 这些数据区域是每个线程的&quot;私有&quot;数据区，每个线程都有自己的，不与其他线程共享； 每个线程的数据区在创建线程时创建，并在线程退出时被销毁； 3、另外，还一种特殊的数据区 直接内存--使用Native函数库直接分配的堆外内存； 即Java内存区域 = JVM运行时数据区 +直接内存。 Java各内存区域说明上面图片展示的是JVM规范定义的运行时数据概念模型，实际上JVM的实现可能有所差别，下面在介绍各内存数据区时会给出一些HotSpot虚拟机实现的不同点和调整参数。 程序计数器 程序计数器（Program Counter Register），简称PC计数器；1、生存特点 每个线程都需要一个独立的PC计数器，生命周期与所属线程相同，各线程的计数器互不影响； 2、作用 JVM字节码解释器通过改变这个计数器的值来选取线程的下一条执行指令； 3、存储内容 JVM的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的； 在任意时刻，一个线程只会执行一个方法的代码（称为该线程的当前方法（Current Method））； （A）、如果这个方法是Java方法，那PC计数器就保存JVM正在执行的字节码指令的地址； （B）、如果该方法是native的，那PC计数器的值是空（undefined）； 4、内存分配特点 PC计数器占用较小的内存空间； 容量至少应当能保存一个returnAddress类型的数据或者一个与平台相关的本地指针的值； 5、异常情况 唯一一个JVM规范中没有规定会抛出OutOfMemoryError情况的区域； Java虚拟机栈 Java虚拟机栈（Java Virtual Machine Stack，JVM Stack），指常说的栈内存（Stack）； 和Java堆指的堆内存（Heap），都是需要重点关注的内存区域； 1、生存特点 每个线程都有一个私有的，生命周期与所属线程相同； 2、作用 描述的是Java方法执行的内存模型，与传统语言中（如C/C++）的栈类似； 在方法调用和返回中也扮演了很重要的角色； 3、存储内容 用于保存方法的栈帧（Stack Frame）； 每个方法从调用到执行结束，对应其栈帧在JVM栈上的入栈到出栈的过程； 栈帧： 每个方法执行时都会创建一个栈帧，随着方法调用而创建（入栈），随着方法结束而销毁（出栈）； 栈帧是方法运行时的基础结构； 栈帧用于存储局部变量表、操作数栈、动态连接、方法出口等信息； （A）、局部变量表 局部变量表（Local Variables Table）是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。 这些都是在编译期可知的数据，所以一个方法调用时，在JVM栈中分配给该方法的局部变量空间是完全确定的，运行中不改变； 一个方法分配局部变量表的最大容量由Class文件中该方法的Code属性的max_locals数据项确定； （B）、操作数栈 操作数栈（Operand Stack）简称操作栈，它是一个后进先出（Last-In-First-Out，LIFO）栈； 在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容（任意类型的值），也就是入栈/出栈操作； 在方法调用的时候，操作数栈也用来准备调用方法的参数以及接收方法返回结果； 一个方法的操作数栈长度由Class文件中该方法的Code属性的max_stacks数据项确定； （C）、动态链接 每一个栈帧内部都包含一个指向运行时常量池的引用，来支持当前方法的执行过程中实现动态链接 （Dynamic Linking）； 在 Class 文件里面，描述一个方法调用了其他方法，或者访问其成员变量是通过符号引用（Symbolic Reference）来表示的； 动态链接的作用就是将这些符号引用所表示的方法转换为实际方法的直接引用(除了在类加载阶段解析的一部分符号)； 4、内存分配特点 因为除了栈帧的出栈和入栈之外，JVM栈从来不被直接操作，所以栈帧可以在堆中分配； JVM栈所使用的内存不需要保证是连续的； JVM规范允许JVM栈被实现成固定大小的或者是根据计算动态扩展和收缩的： （A）、固定大小 如果JVM栈是固定大小的，则当创建新线程的栈时，可以独立地选择每个JVM栈的大小； （B）、动态扩展或收缩 在动态扩展或收缩JVM栈的情况下，JVM实现应该提供调节JVM栈最大和最小内存空间的手段； 两种情况下，JVM实现都应当提供调节JVM栈初始内存空间大小的手段； HotSpot VM通过&quot;-Xss&quot;参数设置JVM栈内存空间大小； 5、异常情况 JVM规范中对该区域，规定了两种可能的异常状况： （A）、StackOverflowError 如果线程请求分配的栈深度超过JVM栈允许的最大深度时，JVM将会抛出一个StackOverflowError异常； （B）、 OutOfMemoryError 如果JVM栈可以动态扩展，当然扩展的动作目前无法申请到足够的内存去完成扩展，或者在建立新的线程时没有足够的内存去创建对应的虚拟机栈，那JVM将会抛出一个OutOfMemoryError异常； 该区域与方法执行的JVM字节码指令密切相关，这里篇幅有限，以后有时间会分析方法的调用与执行过程，再来详细介绍该区域。 本地方法栈本地方法栈（Native Method Stack）与 Java虚拟机栈类似； 1、与Java虚拟机栈的区别 Java虚拟机栈为JVM执行Java方法（也就是字节码）服务； 本地方法栈则为Native方法（指使用Java以外的其他语言编写的方法）服务； 2、HotSpot VM实现方式 JVM规范中没有规定本地方法栈中方法使用的语言、方式和数据结构，JVM可以自由实现； HotSpot VM直接把本地方法栈和Java虚拟机栈合并为一个； Java堆Java堆（Java Heap）指常说的堆内存（Heap）； 1、生存特点 所有线程共享； 生命周期与JVM相同； 2、作用 为&quot;new&quot;创建的实例对象提供存储空间； 里面存储的这些对象实例都是通过垃圾收集器（Garbage Collector）进行自动管理，所以Java堆也称&quot;GC堆&quot;（Garbage Collected Heap）； 对GC堆以及GC的参数设置调整，就是JVM调优的主要内容； 3、存储内容 用于存放几乎所有对象实例； （随JIT编译技术和逃逸分析技术发展，少量对象实例可能在栈上分配，详见后面介绍JIT编译的文章）； 4、内存分配特点 （A）、Java堆划分 为更好回收内存，或更快分配内存，需要对Java堆进行划分： （I）、从垃圾收集器的角度来看 JVM规范没有规定JVM如何实现垃圾收集器； 由于很多JVM采用分代收集算法，所以Java堆还可以细分为：新生代、老年代和永久代； （II）、从内存分配角度来看 为解决分配内存线程不安全问题，需要同步处理； Java堆可能划分出每个线程私有的分配缓冲区（Thread Local Allocation Buffer,TLAB）,减少线程同步； HotSpot VM通过”-XX：+/-UseTLAB”指定是否使用TLAB； （B）、分配调整 和JVM栈一样，Java堆所使用的物理内存不需要保证是连续的，逻辑连续即可； JVM规范允许Java堆被实现成固定大小的或者是根据计算动态扩展和收缩的： 两种情况下，JVM实现都应当提供调节JJava堆初始内存空间大小的手段； 在动态扩展或收缩的情况下，还应该提供调节最大和最小内存空间的手段； （C）、HotSpot VM相关调整 目前主流的JVM都把Java堆实现成动态扩展的，如HotSpot VM： （1）、初始空间大小 通过&quot;-Xms&quot;或&quot;-XX:InitialHeapSize&quot;参数指定Java堆初始空间大小； 默认为1/64的物理内存空间； （2）、最大空间大小 通过&quot;-Xmx&quot;或&quot;-XX:MaxHeapSize&quot;参数指定ava堆内存分配池的最大空间大小； 默认为1/4的物理内存空间； Parallel垃圾收集器默认的最大堆大小是当小于等于192MB物理内存时，为物理内存的一半，否则为物理内存的四分之一； （3）、各年代内存的占用空间与可用空间的比例 通过&quot;-XX:MinHeapFreeRatio&quot;和&quot;-XX:MaxHeapFreeRatio&quot;参数设置堆中各年代内存的占用空间与可用空间的比例保持在特定范围内； 默认： &quot;-XX:MinHeapFreeRatio=40&quot;：即一个年代（新生代或老年代）内存空余小于40%时，JVM会从未分配的堆内存中分配给该年代，以保持该年代40%的空余内存，直到分配完&quot;-Xmx&quot;指定的堆内存最大限制； &quot;-XX:MaxHeapFreeRatio=70&quot;：即一个年代（新生代或老年代）内存空余大于70%时，JVM会缩减该年代内存，以保持该年代70%的空余内存，直到缩减到&quot;-Xms&quot;指定的堆内存最小限制； 这两个参数不适用于Parallel垃圾收集器（通过“-XX:YoungGenerationSizeIncrement”、“-XX:TenuredGenerationSizeIncrement ”能及“-XX:AdaptiveSizeDecrementScaleFactor”调节）； （4）、年轻代与老年代的大小比例 通过&quot;-XX:NewRatio&quot;：控制年轻代与老年代的大小比例； 默认设置&quot;-XX:NewRatio=2&quot;表新生代和老年代之间的比例为1：2； 换句话说，eden和survivor空间组合的年轻代大小将是总堆大小的三分之一； （5）、年轻代空间大小 通过&quot;-Xmn&quot;参数指定年轻代（nursery）的堆的初始和最大大小； 或通过&quot;-XX：NewSize&quot;和&quot;-XX：MaxNewSize&quot;限制年轻代的最小大小和最大大小； （6）、定永久代空间大小 通过&quot;-XX：MaxPermSize（JDK7）&quot;或&quot;-XX：MaxMetaspaceSize（JDK8）&quot;参数指定永久代的最大内存大小； 通过&quot;-XX：PermSize（JDK7）&quot;或&quot;-XX：MetaspaceSize（JDK8）&quot;参数指定永久代的内存阈值--超过将触发垃圾回收； 注：JDK8中永久代已被删除，类元数据存储空间在本地内存中分配； （D）、调整策略 关于这些参数的调整需要垃圾收集的一些知识（以后文章会介绍），先来简单了解： 当使用某种并行垃圾收集器时，应该指定期望的具体行为而不是指定堆的大小； 让垃圾收集器自动地、动态的调整堆的大小来满足期望的行为； 调整的一般规则： 除非你的应用程序无法接受长时间的暂停，否则你可以将堆调的尽可能大一些； 除非你发现问题的原因在于老年代的垃圾收集或应用程序暂停次数过多，否则你应该将堆的较大部分分给年轻代； 5、异常情况 如果实际所需的堆超过了垃圾收集器能提供的最大容量，那Java虚拟机将会抛出一个OutOfMemoryError异常； 该部分的内存如何分配、垃圾如何收集，上面这些参数如何调整，将在以后的文章详细说明。 方法区方法区（Method Area）是堆的逻辑组成部分，但有一个别名”Non-Heap”（非堆）用以区分； 1、生存特点 所有线程共享； 生命周期与JVM相同； 2、作用 为类加载器加载Class文件并解析后的类结构信息提供存储空间； 以及提供JVM运行时常量存储的空间； 3、存储内容 用于存储JVM加载的每一个类的结构信息，主要包括： （A）、运行时常量池（Runtime Constant Pool）、字段和方法数据； （B）、构造函数、普通方法的字节码内容以及JIT编译后的代码； （C）、还包括一些在类、实例、接口初始化时用到的特殊方法； 4、内存分配特点 （A）、分配调整 和Java堆一样，所使用的物理内存不需要保证是连续的； 或以实现成固定大小的或者是根据计算动态扩展和收缩的； （B）、方法区的实现与垃圾回收 JVM规范规定： 虽然方法区是堆的逻辑组成部分，但不限定实现方法区的内存位置； 甚至简单的虚拟机实现可以选择在这个区域不实现垃圾收集； 因为垃圾收集主要针对常量池和类型卸载，效果不佳； 但方法区实现垃圾回收是必要的，否则容易引起内存溢出问题； （C）、HotSpot VM相关调整 （I）、在JDK7中 使用永久代（Permanent Generation）实现方法区，这样就可以不用专门实现方法区的内存管理，但这容易引起内存溢出问题； 有规划放弃永久代而改用Native Memory来实现方法区； 不再在Java堆的永久代中生成中分配字符串常量池，而是在Java堆其他的主要部分（年轻代和老年代）中分配； （II）、在JDK8中 永久代已被删除，类元数据（Class Metadata）存储空间在本地内存中分配，并用显式管理元数据的空间： 从OS请求空间，然后分成块； 类加载器从它的块中分配元数据的空间（一个块被绑定到一个特定的类加载器）； 当为类加载器卸载类时，它的块被回收再使用或返回到操作系统； 元数据使用由mmap分配的空间，而不是由malloc分配的空间； 通过&quot;-XX：MaxMetaspaceSize&quot; （JDK8）参数指定类元数据区的最大内存大小； 通过&quot;-XX：MetaspaceSize&quot; （JDK8）参数指定类元数据区的内存阈值--超过将触发垃圾回收； 5、异常情况 如果方法区的内存空间不能满足内存分配请求，那Java虚拟机将抛出一个OutOfMemoryError异常； 运行常量池 运行常量池(Runtime Constant Pool）是方法区的一部分； 1、存储内容 是每一个类或接口的常量池（Constant_Pool）的运行时表示形式； 包括了若干种不同的常量： （A）、从编译期可知的字面量和符号引用，也即Class文件结构中的常量池； （B）、必须运行期解析后才能获得的方法或字段的直接引用； （C）、还包括运行时可能创建的新常量（如JDK1.6中的String类intern（）方法） 直接内存 直接内存(Direct Memory）不是JVM运行时数据区，也不是JVM规范中定义的内存区域； 1、特点 是使用Native函数库直接分配的堆外内存； 被频繁使用，且容易出现OutOfMemoryError异常； 2、作用 因为避免了在Java堆中来回复制数据，能在一些场景中显著提高性能； 3、实现方式 JDK1.4中新加入NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式； 它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java椎中的DirectByteBuffer对象作为这块内存的引用进行操作； 4、HotSpot VM相关调整 可以通过&quot;-XX:MaxDirectMemorySize&quot;参数指定直接内存最大空间； 不会受到Java堆大小的限制，即&quot;-Xmx&quot;参数限制的空间不包括直接内存； 这容易导致各个内存区域总和大于物理内存限制，出现OutOfMemoryError异常；]]></content>
      <categories>
        <category>内存管理</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java虚拟机垃圾回收(三)7种垃圾收集器]]></title>
    <url>%2F2019%2F09%2F21%2FJava%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E4%B8%89-7%E7%A7%8D%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Java虚拟机垃圾回收(三)7种垃圾收集器先来了解HotSpot虚拟机中的7种垃圾收集器：Serial、ParNew、Parallel Scavenge、Serial Old、Parallel Old、CMS、G1，先介绍一些垃圾收集的相关概念，再介绍它们的主要特点、应用场景、以及一些设置参数和基本运行原理。 垃圾收集器概述垃圾收集器是垃圾回收算法（标记-清除算法、复制算法、标记-整理算法、火车算法）的具体实现，不同商家、不同版本的JVM所提供的垃圾收集器可能会有很在差别，本文主要介绍HotSpot虚拟机中的垃圾收集器。 垃圾收集器组合 JDK7/8后，HotSpot虚拟机所有收集器及组合（连线），如下图： （A）、图中展示了7种不同分代的收集器： Serial、ParNew、Parallel Scavenge、Serial Old、Parallel Old、CMS、G1； （B）、而它们所处区域，则表明其是属于新生代收集器还是老年代收集器： 新生代收集器：Serial、ParNew、Parallel Scavenge； 老年代收集器：Serial Old、Parallel Old、CMS； 整堆收集器：G1； （C）、两个收集器间有连线，表明它们可以搭配使用： Serial/Serial Old、Serial/CMS、 ParNew/Serial Old、ParNew/CMS、 Parallel Scavenge/Serial Old、 Parallel Scavenge/Parallel Old、G1； （D）、其中Serial Old作为CMS出现”Concurrent Mode Failure”失败的后备预案（后面介绍）； 并发垃圾收集和并行垃圾收集的区别（A）、并行（Parallel） 指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态； 如ParNew、Parallel Scavenge、Parallel Old； （B）、并发（Concurrent） 指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行）； 用户程序在继续运行，而垃圾收集程序线程运行于另一个CPU上； 如CMS、G1（也有并行）； Minor GC和Full GC的区别（A）、Minor GC 又称新生代GC，指发生在新生代的垃圾收集动作； 因为Java对象大多是朝生夕灭，所以Minor GC非常频繁，一般回收速度也比较快； （B）、Full GC 又称Major GC或老年代GC，指发生在老年代的GC； 出现Full GC经常会伴随至少一次的Minor GC（不是绝对，Parallel Sacvenge收集器就可以选择设置Major GC策略）； Major GC速度一般比Minor GC慢10倍以上； 下面将介绍这些收集器的特性、基本原理和使用场景，并重点分析CMS和G1这两款相对复杂的收集器；但需要明确一个观点： 没有最好的收集器，更没有万能的收集； 选择的只能是适合具体应用场景的收集器。 新生代收集器Serial收集器 Serial（串行）垃圾收集器是最基本、发展历史最悠久的收集器； JDK1.3.1前是HotSpot新生代收集的唯一选择； 1、特点 针对新生代； 采用复制算法； 单线程收集； 进行垃圾收集时，必须暂停所有工作线程，直到完成； 即会&quot;Stop The World&quot;； Serial/Serial Old组合收集器运行示意图如下： 2、应用场景 依然是HotSpot在Client模式下默认的新生代收集器； 也有优于其他收集器的地方： 简单高效（与其他收集器的单线程相比）； 对于限定单个CPU的环境来说，Serial收集器没有线程交互（切换）开销，可以获得最高的单线程收集效率； 在用户的桌面应用场景中，可用内存一般不大（几十M至一两百M），可以在较短时间内完成垃圾收集（几十MS至一百多MS）,只要不频繁发生，这是可以接受的 3、设置参数 &quot;-XX:+UseSerialGC&quot;：添加该参数来显式的使用串行垃圾收集器； 4、Stop TheWorld说明 JVM在后台自动发起和自动完成的，在用户不可见的情况下，把用户正常的工作线程全部停掉，即GC停顿； 会带给用户不良的体验； 从JDK1.3到现在，从Serial收集器-》Parallel收集器-》CMS-》G1，用户线程停顿时间不断缩短，但仍然无法完全消除； ParNew收集器 ParNew垃圾收集器是Serial收集器的多线程版本。 1、特点 除了多线程外，其余的行为、特点和Serial收集器一样； 如Serial收集器可用控制参数、收集算法、Stop The World、内存分配规则、回收策略等； 两个收集器共用了不少代码； ParNew/Serial Old组合收集器运行示意图如下： 2、应用场景 在Server模式下，ParNew收集器是一个非常重要的收集器，因为除Serial外，目前只有它能与CMS收集器配合工作； 但在单个CPU环境中，不会比Serail收集器有更好的效果，因为存在线程交互开销。 3、设置参数 &quot;-XX:+UseConcMarkSweepGC&quot;：指定使用CMS后，会默认使用ParNew作为新生代收集器； &quot;-XX:+UseParNewGC&quot;：强制指定使用ParNew； &quot;-XX:ParallelGCThreads&quot;：指定垃圾收集的线程数量，ParNew默认开启的收集线程与CPU的数量相同； 4、为什么只有ParNew能与CMS收集器配合 CMS是HotSpot在JDK1.5推出的第一款真正意义上的并发（Concurrent）收集器，第一次实现了让垃圾收集线程与用户线程（基本上）同时工作； CMS作为老年代收集器，但却无法与JDK1.4已经存在的新生代收集器Parallel Scavenge配合工作； 因为Parallel Scavenge（以及G1）都没有使用传统的GC收集器代码框架，而另外独立实现；而其余几种收集器则共用了部分的框架代码； Parallel Scavenge收集器 Parallel Scavenge垃圾收集器因为与吞吐量关系密切，也称为吞吐量收集器（Throughput Collector）。 1、特点 （A）、有一些特点与ParNew收集器相似 新生代收集器； 采用复制算法； 多线程收集； （B）、主要特点是：它的关注点与其他收集器不同 CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间； 而Parallel Scavenge收集器的目标则是达一个可控制的吞吐量（Throughput）； 关于吞吐量与收集器关注点说明详见本节后面； 2、应用场景 高吞吐量为目标，即减少垃圾收集时间，让用户代码获得更长的运行时间； 当应用程序运行在具有多个CPU上，对暂停时间没有特别高的要求时，即程序主要在后台进行计算，而不需要与用户进行太多交互； 例如，那些执行批量处理、订单处理、工资支付、科学计算的应用程序； 3、设置参数 Parallel Scavenge收集器提供两个参数用于精确控制吞吐量： （A）、”-XX:MaxGCPauseMillis” 控制最大垃圾收集停顿时间，大于0的毫秒数； MaxGCPauseMillis设置得稍小，停顿时间可能会缩短，但也可能会使得吞吐量下降； 因为可能导致垃圾收集发生得更频繁； （B）、”-XX:GCTimeRatio” 设置垃圾收集时间占总时间的比率，0&lt;n&lt;100的整数； GCTimeRatio相当于设置吞吐量大小； 垃圾收集执行时间占应用程序执行时间的比例的计算方法是： 1 / (1 + n) 例如，选项-XX:GCTimeRatio=19，设置了垃圾收集时间占总时间的5%--1/(1+19)； 默认值是1%--1/(1+99)，即n=99； 垃圾收集所花费的时间是年轻一代和老年代收集的总时间； 如果没有满足吞吐量目标，则增加代的内存大小以尽量增加用户程序运行的时间； 此外，还有一个值得关注的参数： （C）、”-XX:+UseAdptiveSizePolicy” 开启这个参数后，就不用手工指定一些细节参数，如： 新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX:SurvivorRation）、晋升老年代的对象年龄（-XX:PretenureSizeThreshold）等； JVM会根据当前系统运行情况收集性能监控信息，动态调整这些参数，以提供最合适的停顿时间或最大的吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomiscs）； 这是一种值得推荐的方式： (1)、只需设置好内存数据大小（如&quot;-Xmx&quot;设置最大堆）； (2)、然后使用&quot;-XX:MaxGCPauseMillis&quot;或&quot;-XX:GCTimeRatio&quot;给JVM设置一个优化目标； (3)、那些具体细节参数的调节就由JVM自适应完成； 这也是Parallel Scavenge收集器与ParNew收集器一个重要区别； 4、吞吐量与收集器关注点说明 （A）、吞吐量（Throughput） CPU用于运行用户代码的时间与CPU总消耗时间的比值； 即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间）； 高吞吐量即减少垃圾收集时间，让用户代码获得更长的运行时间； （B）、垃圾收集器期望的目标（关注点） （1）、停顿时间 停顿时间越短就适合需要与用户交互的程序； 良好的响应速度能提升用户体验； （2）、吞吐量 高吞吐量则可以高效率地利用CPU时间，尽快完成运算的任务； 主要适合在后台计算而不需要太多交互的任务； （3）、覆盖区（Footprint） 在达到前面两个目标的情况下，尽量减少堆的内存空间； 可以获得更好的空间局部性； 老年代收集器Serial Old收集器 Serial Old是 Serial收集器的老年代版本； 1、特点 针对老年代； 采用&quot;标记-整理&quot;算法（还有压缩，Mark-Sweep-Compact）； 单线程收集； Serial/Serial Old收集器运行示意图如下： 2、应用场景 主要用于Client模式； 而在Server模式有两大用途： （A）、在JDK1.5及之前，与Parallel Scavenge收集器搭配使用（JDK1.6有Parallel Old收集器可搭配）； （B）、作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用（后面详解）； Parallel Old收集器 Parallel Old垃圾收集器是Parallel Scavenge收集器的老年代版本； JDK1.6中才开始提供； 1、特点 针对老年代； 采用&quot;标记-整理&quot;算法； 多线程收集； Parallel Scavenge/Parallel Old收集器运行示意图如下： 2、应用场景 JDK1.6及之后用来代替老年代的Serial Old收集器； 特别是在Server模式，多CPU的情况下； 这样在注重吞吐量以及CPU资源敏感的场景，就有了Parallel Scavenge加Parallel Old收集器的&quot;给力&quot;应用组合； 3、设置参数 &quot;-XX:+UseParallelOldGC&quot;：指定使用Parallel Old收集器； CMS收集器 并发标记清理（Concurrent Mark Sweep，CMS）收集器也称为并发低停顿收集器（Concurrent Low Pause Collector）或低延迟（low-latency）垃圾收集器； 在前面ParNew收集器曾简单介绍过其特点；1、特点 针对老年代； 基于&quot;标记-清除&quot;算法(不进行压缩操作，产生内存碎片)； 以获取最短回收停顿时间为目标； 并发收集、低停顿； 需要更多的内存（看后面的缺点）； 是HotSpot在JDK1.5推出的第一款真正意义上的并发（Concurrent）收集器； 第一次实现了让垃圾收集线程与用户线程（基本上）同时工作； 2、应用场景 与用户交互较多的场景； 希望系统停顿时间最短，注重服务的响应速度； 以给用户带来较好的体验； 如常见WEB、B/S系统的服务器上的应用； 3、设置参数 &quot;-XX:+UseConcMarkSweepGC&quot;：指定使用CMS收集器； 4、CMS收集器运作过程 比前面几种收集器更复杂，可以分为4个步骤: （A）、初始标记（CMS initial mark） 仅标记一下GC Roots能直接关联到的对象； 速度很快； 但需要&quot;Stop The World&quot;； （B）、并发标记（CMS concurrent mark） 进行GC Roots Tracing的过程； 刚才产生的集合中标记出存活对象； 应用程序也在运行； 并不能保证可以标记出所有的存活对象； （C）、重新标记（CMS remark） 为了修正并发标记期间因用户程序继续运作而导致标记变动的那一部分对象的标记记录； 需要&quot;Stop The World&quot;，且停顿时间比初始标记稍长，但远比并发标记短； 采用多线程并行执行来提升效率； （D）、并发清除（CMS concurrent sweep） 回收所有的垃圾对象； 整个过程中耗时最长的并发标记和并发清除都可以与用户线程一起工作； 所以总体上说，CMS收集器的内存回收过程与用户线程一起并发执行； CMS收集器运行示意图如下： CMS收集器3个明显的缺点 （A）、对CPU资源非常敏感 并发收集虽然不会暂停用户线程，但因为占用一部分CPU资源，还是会导致应用程序变慢，总吞吐量降低。 CMS的默认收集线程数量是=(CPU数量+3)/4； 当CPU数量多于4个，收集线程占用的CPU资源多于25%，对用户程序影响可能较大；不足4个时，影响更大，可能无法接受。 增量式并发收集器： 针对这种情况，曾出现了&quot;增量式并发收集器&quot;（Incremental Concurrent Mark Sweep/i-CMS）； 类似使用抢占式来模拟多任务机制的思想，让收集线程和用户线程交替运行，减少收集线程运行时间； 但效果并不理想，JDK1.6后就官方不再提倡用户使用。 （B）、无法处理浮动垃圾,可能出现”Concurrent Mode Failure”失败 （1）、浮动垃圾（Floating Garbage） 在并发清除时，用户线程新产生的垃圾，称为浮动垃圾； 这使得并发清除时需要预留一定的内存空间，不能像其他收集器在老年代几乎填满再进行收集； 也要可以认为CMS所需要的空间比其他垃圾收集器大； &quot;-XX:CMSInitiatingOccupancyFraction&quot;：设置CMS预留内存空间； JDK1.5默认值为68%； JDK1.6变为大约92%； （2）、&quot;Concurrent Mode Failure&quot;失败 如果CMS预留内存空间无法满足程序需要，就会出现一次&quot;Concurrent Mode Failure&quot;失败； 这时JVM启用后备预案：临时启用Serail Old收集器，而导致另一次Full GC的产生； 这样的代价是很大的，所以CMSInitiatingOccupancyFraction不能设置得太大。 （C）、产生大量内存碎片 由于CMS基于&quot;标记-清除&quot;算法，清除后不进行压缩操作； 产生大量不连续的内存碎片会导致分配大内存对象时，无法找到足够的连续内存，从而需要提前触发另一次Full GC动作 解决方法： （1）、”-XX:+UseCMSCompactAtFullCollection” 使得CMS出现上面这种情况时不进行Full GC，而开启内存碎片的合并整理过程； 但合并整理过程无法并发，停顿时间会变长； 默认开启（但不会进行，结合下面的CMSFullGCsBeforeCompaction）； （2）、”-XX:+CMSFullGCsBeforeCompaction” 设置执行多少次不压缩的Full GC后，来一次压缩整理； 为减少合并整理过程的停顿时间； 默认为0，也就是说每次都执行Full GC，不会进行压缩整理； 由于空间不再连续，CMS需要使用可用&quot;空闲列表&quot;内存分配方式，这比简单实用&quot;碰撞指针&quot;分配内存消耗大； 由于空间不再连续，CMS需要使用可用”空闲列表”内存分配方式，这比简单实用”碰撞指针”分配内存消耗大； 总体来看，与Parallel Old垃圾收集器相比，CMS减少了执行老年代垃圾收集时应用暂停的时间；但却增加了新生代垃圾收集时应用暂停的时间、降低了吞吐量而且需要占用更大的堆空间； G1收集器 G1（Garbage-First）是JDK7-u4才推出商用的收集器； 1、特点 （A）、并行与并发 能充分利用多CPU、多核环境下的硬件优势； 可以并行来缩短&quot;Stop The World&quot;停顿时间； 也可以并发让垃圾收集与用户程序同时进行； （B）、分代收集，收集范围包括新生代和老年代 能独立管理整个GC堆（新生代和老年代），而不需要与其他收集器搭配； 能够采用不同方式处理不同时期的对象； 虽然保留分代概念，但Java堆的内存布局有很大差别； 将整个堆划分为多个大小相等的独立区域（Region）； 新生代和老年代不再是物理隔离，它们都是一部分Region（不需要连续）的集合； （C）、结合多种垃圾收集算法，空间整合，不产生碎片 从整体看，是基于标记-整理算法； 从局部（两个Region间）看，是基于复制算法； 这是一种类似火车算法的实现； 都不会产生内存碎片，有利于长时间运行； （D）、可预测的停顿：低停顿的同时实现高吞吐量 G1除了追求低停顿处，还能建立可预测的停顿时间模型； 可以明确指定M毫秒时间片内，垃圾收集消耗的时间不超过N毫秒； 2、应用场景 面向服务端应用，针对具有大内存、多处理器的机器； 最主要的应用是为需要低GC延迟，并具有大堆的应用程序提供解决方案； 如：在堆大小约6GB或更大时，可预测的暂停时间可以低于0.5秒； 用来替换掉JDK1.5中的CMS收集器； 在下面的情况时，使用G1可能比CMS好： （1）、超过50％的Java堆被活动数据占用； （2）、对象分配频率或年代提升频率变化很大； （3）、GC停顿时间过长（长于0.5至1秒）。 是否一定采用G1呢？也未必： 如果现在采用的收集器没有出现问题，不用急着去选择G1； 如果应用程序追求低停顿，可以尝试选择G1； 是否代替CMS需要实际场景测试才知道。 3、设置参数 &quot;-XX:+UseG1GC&quot;：指定使用G1收集器； &quot;-XX:InitiatingHeapOccupancyPercent&quot;：当整个Java堆的占用率达到参数值时，开始并发标记阶段；默认为45； &quot;-XX:MaxGCPauseMillis&quot;：为G1设置暂停时间目标，默认值为200毫秒； &quot;-XX:G1HeapRegionSize&quot;：设置每个Region大小，范围1MB到32MB；目标是在最小Java堆时可以拥有约2048个Region； 4、为什么G1收集器可以实现可预测的停顿 G1可以建立可预测的停顿时间模型，是因为： 可以有计划地避免在Java堆的进行全区域的垃圾收集； G1跟踪各个Region获得其收集价值大小，在后台维护一个优先列表； 每次根据允许的收集时间，优先回收价值最大的Region（名称Garbage-First的由来）； 这就保证了在有限的时间内可以获取尽可能高的收集效率； 5、一个对象被不同区域引用的问题 一个Region不可能是孤立的，一个Region中的对象可能被其他任意Region中对象引用，判断对象存活时，是否需要扫描整个Java堆才能保证准确？ 在其他的分代收集器，也存在这样的问题（而G1更突出）： 回收新生代也不得不同时扫描老年代？ 这样的话会降低Minor GC的效率； 解决方法： 无论G1还是其他分代收集器，JVM都是使用Remembered Set来避免全局扫描： 每个Region都有一个对应的Remembered Set； 每次Reference类型数据写操作时，都会产生一个Write Barrier暂时中断操作； 然后检查将要写入的引用指向的对象是否和该Reference类型数据在不同的Region（其他收集器：检查老年代对象是否引用了新生代对象）； 如果不同，通过CardTable把相关引用信息记录到引用指向对象的所在Region对应的Remembered Set中； 当进行垃圾收集时，在GC根节点的枚举范围加入Remembered Set； 就可以保证不进行全局扫描，也不会有遗漏。 6、G1收集器运作过程 不计算维护Remembered Set的操作，可以分为4个步骤（与CMS较为相似）。（A）、初始标记（Initial Marking） 仅标记一下GC Roots能直接关联到的对象； 且修改TAMS（Next Top at Mark Start）,让下一阶段并发运行时，用户程序能在正确可用的Region中创建新对象； 需要&quot;Stop The World&quot;，但速度很快； （B）、并发标记（Concurrent Marking） 进行GC Roots Tracing的过程； 刚才产生的集合中标记出存活对象； 耗时较长，但应用程序也在运行； 并不能保证可以标记出所有的存活对象； （C）、最终标记（Final Marking） 为了修正并发标记期间因用户程序继续运作而导致标记变动的那一部分对象的标记记录； 上一阶段对象的变化记录在线程的Remembered Set Log； 这里把Remembered Set Log合并到Remembered Set中； 需要&quot;Stop The World&quot;，且停顿时间比初始标记稍长，但远比并发标记短； 采用多线程并行执行来提升效率； （D）、筛选回收（Live Data Counting and Evacuation） 首先排序各个Region的回收价值和成本； 然后根据用户期望的GC停顿时间来制定回收计划； 最后按计划回收一些价值高的Region中垃圾对象； 回收时采用&quot;复制&quot;算法，从一个或多个Region复制存活对象到堆上的另一个空的Region，并且在此过程中压缩和释放内存； 可以并发进行，降低停顿时间，并增加吞吐量；]]></content>
      <categories>
        <category>垃圾回收</category>
        <category>垃圾收集器</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java虚拟机垃圾回收(二) 垃圾回收算法]]></title>
    <url>%2F2019%2F09%2F21%2FJava%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E4%BA%8C-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Java虚拟机垃圾回收(二) 垃圾回收算法在《Java虚拟机垃圾回收(一) 基础》中了解到如何判断对象是存活还是已经死亡？ 介绍了垃圾回收基础算法：引用计数算法、可达性分析算法，以及HotSpot虚拟机中实现对象可达性分析的一些问题。 下面先来了解Java虚拟机垃圾回收的几种常见算法：标记-清除算法、复制算法、标记-整理算法、分代收集算法、火车算法，介绍它们的算法思路，有什么优点和缺点，以及主要应用场景。 标记-清除算法标记-清除（Mark-Sweep）算法是一种基础的收集算法。 1、算法思路 &quot;标记-清除&quot;算法，分为两个阶段： （A）、标记 首先标记出所有需要回收的对象； 标记过程如《Java虚拟机垃圾回收(一) 基础》&quot;2-4、判断对象生存还是死亡&quot;中所述--分为两个标记过程（详细请参考前文）： （1）、第一次标记 在可达性分析后发现对象到GC Roots没有任何引用链相连时，被第一次标记； 并且进行一次筛选：此对象是否必要执行finalize()方法； 对有必要执行finalize()方法的对象，被放入F-Queue队列中； （2）、第二次标记 GC将对F-Queue队列中的对象进行第二次小规模标记； 在其finalize()方法中重新与引用链上任何一个对象建立关联，第二次标记时会将其移出&quot;即将回收&quot;的集合； 对第一次被标记，且第二次还被标记（如果需要，但没有移出&quot;即将回收&quot;的集合），就可以认为对象已死，可以进行回收。 （B）、清除 两次标记后，还在&quot;即将回收&quot;集合的对象将被统一回收； 执行过程如下图： 2、优点 基于最基础的可达性分析算法，它是最基础的收集算法； 而后续的收集算法都是基于这种思路并对其不足进行改进得到的； 3、缺点 主要有两个缺点： （A）、效率问题 标记和清除两个过程的效率都不高； （B）、空间问题 标记清除后会产生大量不连续的内存碎片； 这会导致分配大内存对象时，无法找到足够的连续内存； 从而需要提前触发另一次垃圾收集动作； 4、应用场景 针对老年代的CMS收集器； 复制算法算法“复制”（Copying）收集算法，为了解决标记-清除算法的效率问题； 1、算法思路 （A）、把内存划分为大小相等的两块，每次只使用其中一块； （B）、当一块内存用完了，就将还存活的对象复制到另一块上（而后使用这一块）； （C）、再把已使用过的那块内存空间一次清理掉，而后重复步骤2； 执行过程如下图： 2、优点 这使得每次都是只对整个半区进行内存回收； 内存分配时也不用考虑内存碎片等问题（可使用&quot;指针碰撞&quot;的方式分配内存）； 实现简单，运行高效； （关于&quot;指针碰撞&quot;请参考《Java对象在HotSpot虚拟机中的创建过程》） 3、缺点 （A）、空间浪费 可用内存缩减为原来的一半，太过浪费（解决：可以改良，不按1:1比例划分）； （B）、效率随对象存活率升高而变低 当对象存活率较高时，需要进行较多复制操作，效率将会变低（解决：后面的标记-整理算法）； 4、应用场景 现在商业JVM都采用这种算法（通过改良缺点1）来回收新生代； 如Serial收集器、ParNew收集器、Parallel Scavenge收集器、、G1（从局部看）； 5、HotSpot虚拟机的改良算法 （A）、弱代理论 分代垃圾收集基于弱代理论（weak generational hypothesis），具体描述如下： （1）、大多数分配了内存的对象并不会存活太长时间，在处于年轻代时就会死掉； （2）、很少有对象会从老年代变成年轻代； 其中IBM研究表明：新生代中98%的对象都是&quot;朝生夕死&quot;； 所以并不需要按1:1比例来划分内存（解决了缺点1）； （B）、HotSpot虚拟机新生代内存布局及算法 （1）、将新生代内存分为一块较大的Eden空间和两块较小的Survivor空间； （2）、每次使用Eden和其中一块Survivor； （3）、当回收时，将Eden和使用中的Survivor中还存活的对象一次性复制到另外一块Survivor； （4）、而后清理掉Eden和使用过的Survivor空间； （5）、后面就使用Eden和复制到的那一块Survivor空间，重复步骤3； 默认Eden：Survivor=8:1，即每次可以使用90%的空间，只有一块Survivor的空间被浪费； （C）、分配担保 如果另一块Survivor空间没有足够空间存放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制（Handle Promotion）进入老年代； 分配担保在以后讲解垃圾收集器执行规则时再详解； 标记-整理算法 “标记-整理”（Mark-Compact）算法是根据老年代的特点提出的。 1、算法思路 （1）、标记 标记过程与&quot;标记-清除&quot;算法一样； （2）、整理 但后续不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动； 然后直接清理掉端边界以外的内存； 执行过程如下图： 2、优点 （A）、不会像复制算法，效率随对象存活率升高而变低 老年代特点： 对象存活率高，没有额外的空间可以分配担保； 所以老年代一般不能直接选用复制算法算法； 而选用标记-整理算法； （B）、不会像标记-清除算法，产生内存碎片 因为清除前，进行了整理，存活对象都集中到空间一侧； 3、缺点 主要是效率问题：除像标记-清除算法的标记过程外，还多了需要整理的过程，效率更低； 4、应用场景 很多垃圾收集器采用这种算法来回收老年代； 如Serial Old收集器、G1（从整体看）； 分代收集算法 “分代收集”（Generational Collection）算法结合不同的收集算法处理不同区域。 1、算法思路 基于前面说的弱代理论，其实并没有什么新的思想； 只是根据对象存活周期的不同将内存划分为几块； 这样就可以根据各个年代的特点采用最适当的收集算法； 一般把Java堆分为新生代和老年代； （A）、新生代 每次垃圾收集都有大批对象死去，只有少量存活； 所以可采用复制算法； （B）、老年代 对象存活率高，没有额外的空间可以分配担保； 使用&quot;标记-清理&quot;或&quot;标记-整理&quot;算法； 结合上面对新生代的内存划分介绍和上篇文章对Java堆的介绍，可以得出HotSpot虚拟机一般的年代内存划分，如下图： 2、优点 可以根据各个年代的特点采用最适当的收集算法； 3、缺点 仍然不能控制每次垃圾收集的时间； 4、应用场景 目前几乎所有商业虚拟机的垃圾收集器都采用分代收集算法； 如HotSpot虚拟机中全部垃圾收集器：Serial、ParNew、Parallel Scavenge、Serial Old、Parallel Old、CMS、G1（也保留）； 火车算法 火车算法也称列车算法，是一种更彻底的分区域处理收集算法，是对分代收集算法的一个有力补充。 1、算法思路 在火车算法中，内存被分为块，多个块组成一个集合。为了形象化，一节车厢代表一个块，一列火车代表一个集合，如下图； 火车与车箱都按创建顺序标号，每个车厢大小相等，但每个火车包含的车厢数不一定相等； 每节车箱有一个被记忆集合，而每辆火车的记忆集合是它所有车厢记忆集合的总和； 记忆集合由指向车箱中对象的引用组成，这些引用来自同一辆火车中序号较高的车箱中的对象，以及序号较高中的对象； 垃圾收集以车厢为单位，整体算法流程如下： （1）、选择标号最小的火车； （2）、如果火车的记忆集合是空的, 释放整列火车并终止, 否则进行第三步操作； （3）、选择火车中标号最小的车厢； （4）、对于车厢记忆集合的每个元素： 如果它是一个被根引用引用的对象, 那么, 将拷贝到一列新的火车中去； 如果是一个被其它火车的对象指向的对象, 那么, 将它拷贝到这个指向它的火车中去.； 假设有一些对象已经被保留下来了, 那么通过这些对象可以触及到的对象将会被拷贝到同一列火车中去； 如果一个对象被来自多个火车的对象引用, 那么它可以被拷贝到任意一个火车去； 这个步骤中, 有必要对受影响的引用集合进行相应地更新； （5）、释放车厢并且终止； 执行过程如下图： 2、优点 可以在成熟对象空间提供限定时间的渐近收集； 而不需要每次都进行一个大区域的垃圾回收过程； 即可以控制垃圾回收的时间，在指定时间内进行一些小区域的回收； 3、缺点 实现较为复杂，如采用类似的算法的G1收集器在JDK7才实现； 一些场景下可能性价比不高； 4、应用场景JDK7后HotSpot虚拟机G1收集器采用类似的算法，能建立可预测的停顿时间模型；]]></content>
      <categories>
        <category>垃圾回收</category>
        <category>垃圾回收算法</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java虚拟机垃圾回收(一)基础]]></title>
    <url>%2F2019%2F09%2F21%2FJava%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-%E4%B8%80-%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Java虚拟机垃圾回收(一)基础回收哪些内存/对象 引用计数算法 可达性分析算法 finalize()方法 HotSpot实现分析 Java虚拟机垃圾回收 垃圾回收，或称垃圾收集（Garbage Collection，GC）是指自动管理回收不再被引用的内存数据。 在1960年诞生于MIT的Lisp语言首次使用了动态内存分配和垃圾收集技术，可以实现垃圾回收的一个基本要求是语言是类型安全的，现在使用的包括Java、Perl、ML等。 为什么需要了解垃圾回收目前内存的动态分配与内存回收技术已经相当成熟，但为什么还需要去了解内存分配与GC呢？ 1、当需要排查各种内存溢出、内存泄漏问题时； 2、当垃圾收集成为系统达到更高并发量的瓶颈时； 我们就需要对这些&quot;自动化&quot;技术实话必要的监控和调节； 垃圾回收需要了解什么 思考GC完成的3件事： 1、哪些内存需要回收？即如何判断对象已经死亡； 2、什么时候回收？即GC发生在什么时候？需要了解GC策略，与垃圾回收器实现有关； 3、如何回收？即需要了解垃圾回收算法，及算法的实现--垃圾回收器； 第一点就是本文下面的主题，这是垃圾回收的基础，如：可达性分析算法是后面垃圾回收算法的基础，而判断哪些对象可以回收是垃圾回收的首要任务。 判断对象可以回收垃圾收集器对堆进行回收前，首先要确定堆中的对象哪些还”存活”，哪些已经”死去”； 下面先来了解两种判断对象不再被引用的算法，再来谈谈对象的引用，最后来看如何真正宣告一个对象死亡。 引用计数算法（Recference Counting）1、算法基本思路 给对象添加一个引用计数器，每当有一个地方引用它，计数器加1； 当引用失效，计数器值减1； 任何时刻计数器值为0，则认为对象是不再被使用的； 2、优点 实现简单，判定高效，可以很好解决大部分场景的问题，也有一些著名的应用案例； 3、缺点 （A）、很难解决对象之间相互循环引用的问题 如： ReferenceCountingGC objA = new ReferenceCountingGC(); ReferenceCountingGC objB = new ReferenceCountingGC(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; 当两个对象不再被访问时，因为相互引用对方，导致引用计数不为0；（B）、并且开销较大，频繁且大量的引用变化，带来大量的额外运算； 主流的JVM都没有选用引用计数算法来管理内存； 可达性分析算法（Reachability Analysis）也称为传递跟踪算法； 主流的调用程序语言（Java、C#等）在主流的实现中，都是通过可达性分析来判定对象是否存活的。 1、算法基本思路 通过一系列&quot;GC Roots&quot;对象作为起始点，开始向下搜索； 搜索所走过和路径称为引用链（Reference Chain）； 当一个对象到GC Roots没有任何引用链相连时（从GC Roots到这个对象不可达），则证明该对象是不可用的； 2、GC Roots对象 Java中，GC Roots对象包括： （1）、虚拟机栈（栈帧中本地变量表）中引用的对象； （2）、方法区中类静态属性引用的对象； （3）、方法区中常量引用的对象； （4）、本地方法栈中JNI（Native方法）引用的对象； 主要在执行上下文中和全局性的引用； 3、优点 更加精确和严谨，可以分析出循环数据结构相互引用的情况； 4、缺点 实现比较复杂； 需要分析大量数据，消耗大量时间； 分析过程需要GC停顿（引用关系不能发生变化），即停顿所有Java执行线程（称为&quot;Stop The World&quot;，是垃圾回收重点关注的问题）； 后面会针对HotSpot虚拟机实现的可达性分析算法进行介绍，看看是它如何解决这些缺点的。 再谈对象引用 java程序通过reference类型数据操作堆上的具体对象； 1、JVM层面的引用 reference类型是引用类型（Reference Types）的一种； JVM规范规定reference类型来表示对某个对象的引用，可以想象成类似于一个指向对象的指针； 对象的操作、传递和检查都通过引用它的reference类型的数据进行操作； 2、Java语言层面的引用 （i）、JDK1.2前的引用定义 如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用； 这种定义太过狭隘，无法描述更多信息； （ii）、JDK1.2后，对引用概念进行了扩充，将引用分为： （1）、强引用（Strong Reference） 程序代码普遍存在的，类似&quot;Object obj=new Object()&quot;； 只要强引用还存在，GC永远不会回收被引用的对象； （2）、软引用（Soft Reference） 用来描述还有用但并非必需的对象； 直到内存空间不够时（抛出OutOfMemoryError之前），才会被垃圾回收； 最常用于实现对内存敏感的缓存； SoftReference类实现； （3）、弱引用（Weak Reference） 用来描述非必需对象； 只能生存到下一次垃圾回收之前，无论内存是否足够； WeakReference类实现； （4）、虚引用（Phantom Reference） 也称为幽灵引用或幻影引用； 完全不会对其生存时间构成影响； 唯一目的就是能在这个对象被回收时收到一个系统通知； PhantomRenference类实现； 判断对象生存还是死亡要真正宣告一个对象死亡，至少要经历两次标记过程。 1、第一次标记 在可达性分析后发现到GC Roots没有任何引用链相连时，被第一次标记； 并且进行一次筛选：此对象是否必要执行finalize()方法； （A）、没有必要执行 没有必要执行的情况： （1）、对象没有覆盖finalize()方法； （2）、finalize()方法已经被JVM调用过； 这两种情况就可以认为对象已死，可以回收； （B）、有必要执行 对有必要执行finalize()方法的对象，被放入F-Queue队列中； 稍后在JVM自动建立、低优先级的Finalizer线程（可能多个线程）中触发这个方法； 2、第二次标记 GC将对F-Queue队列中的对象进行第二次小规模标记； finalize()方法是对象逃脱死亡的最后一次机会： （A）、如果对象在其finalize()方法中重新与引用链上任何一个对象建立关联，第二次标记时会将其移出&quot;即将回收&quot;的集合； （B）、如果对象没有，也可以认为对象已死，可以回收了； 一个对象的finalize()方法只会被系统自动调用一次，经过finalize()方法逃脱死亡的对象，第二次不会再调用； finalize()方法 上面已经说到finalize()方法与垃圾回收第二次标记相关，下面了解下在Java语言层面有哪些需要注意的。 finalize()是Object类的一个方法，是Java刚诞生时为了使C/C++程序员容易接受它所做出的一个妥协，但不要当作类似C/C++的析构函数； 因为它执行的时间不确定，甚至是否被执行也不确定（Java程序的不正常退出），而且运行代价高昂，无法保证各个对象的调用顺序（甚至有不同线程中调用）； 如果需要&quot;释放资源&quot;，可以定义显式的终止方法，并在&quot;try-catch-finally&quot;的finally{}块中保证及时调用，如File相关类的close()方法； 此外，finalize()方法主要有两种用途： 1、充当”安全网” 当显式的终止方法没有调用时，在finalize()方法中发现后发出警告； 但要考虑是否值得付出这样的代价； 如FileInputStream、FileOutputStream、Timer和Connection类中都有这种应用； 2、与对象的本地对等体有关 本地对等体：普通对象调用本地方法（JNI）委托的本地对象； 本地对等体不会被GC回收； 如果本地对等体不拥有关键资源，finalize()方法里可以回收它（如C/C++中malloc()，需要调用free()）； 如果有关键资源，必须显式的终止方法； HotSpot虚拟机中对象可达性分析的实现前面对可达性分析算法进行介绍，并看到了它在判断对象存活与死亡的作用，下面看看是HotSpot虚拟机是如何实现可达性分析算法，如何解决相关缺点的。 可达性分析的问题1、消耗大量时间 从前面可达性分析知道，GC Roots主要在全局性的引用（常量或静态属性）和执行上下文中（栈帧中的本地变量表）； 要在这些大量的数据中，逐个检查引用，会消耗很多时间； 2、GC停顿 可达性分析期间需要保证整个执行系统的一致性，对象的引用关系不能发生变化； 导致GC进行时必须停顿所有Java执行线程（称为&quot;Stop The World&quot;）； （几乎不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的） Stop The World： 是JVM在后台自动发起和自动完成的； 在用户不可见的情况下，把用户正常的工作线程全部停掉； 枚举根节点枚举根节点也就是查找GC Roots； 目前主流JVM都是准确式GC，可以直接得知哪些地方存放着对象引用，所以执行系统停顿下来后，并不需要全部、逐个检查完全局性的和执行上下文中的引用位置； 在HotSpot中，是使用一组称为OopMap的数据结构来达到这个目的的； 在类加载时，计算对象内什么偏移量上是什么类型的数据； 在JIT编译时，也会记录栈和寄存器中的哪些位置是引用； 这样GC扫描时就可以直接得知这些信息； 安全点1、安全点是什么，为什么需要安全点 HotSpot在OopMap的帮助下可以快速且准确的完成GC Roots枚举，但是这有一个问题： 运行中，非常多的指令都会导致引用关系变化； 如果为这些指令都生成对应的OopMap，需要的空间成本太高； 问题解决： 只在特定的位置记录OopMap引用关系，这些位置称为安全点（Safepoint）； 即程序执行时并非所有地方都能停顿下来开始GC； 2、安全点的选定 不能太少，否则GC等待时间太长；也不能太多，否则GC过于频繁，增大运行时负荷； 所以，基本上是以程序&quot;是否具有让程序长时间执行的特征&quot;为标准选定； &quot;长时间执行&quot;最明显的特征就是指令序列复用，如：方法调用、循环跳转、循环的末尾、异常跳转等； 只有具有这些功能的指令才会产生Safepoint； 3、如何在安全点上停顿 对于Safepoint，如何在GC发生时让所有线程（不包括JNI线程）运行到其所在最近的Safepoint上再停顿下来？ 主要有两种方案可选： （A）、抢先式中断（Preemptive Suspension） 不需要线程主动配合，实现如下： （1）、在GC发生时，首先中断所有线程； （2）、如果发现不在Safepoint上的线程，就恢复让其运行到Safepoint上； 现在几乎没有JVM实现采用这种方式； （B）、主动式中断（Voluntary Suspension） （1）、在GC发生时，不直接操作线程中断，而是仅简单设置一个标志； （2）、让各线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起； 而轮询标志的地方和Safepoint是重合的； 在JIT执行方式下：test指令是HotSpot生成的轮询指令； 一条test汇编指令便完成Safepoint轮询和触发线程中断； 安全区域1、为什么需要安全区域 对于上面的Safepoint还有一个问题： 程序不执行时没有CPU时间（Sleep或Blocked状态），无法运行到Safepoint上再中断挂起； 这就需要安全区域来解决； 2、什么是安全区域（Safe Region） 指一段代码片段中，引用关系不会发生变化； 在这个区域中的任意地方开始GC都是安全的； 3、如何用安全区域解决问题 安全区域解决问题的思路： （1）、线程执行进入Safe Region，首先标识自己已经进入Safe Region； （2）、线程被唤醒离开Safe Region时，其需要检查系统是否已经完成根节点枚举（或整个GC）； 如果已经完成，就继续执行； 否则必须等待，直到收到可以安全离开Safe Region的信号通知； 这样就不会影响标记结果； 虽然HotSpot虚拟机中采用了这些方法来解决对象可达性分析的问题，但只是大大减少了这些问题影响，并不能完全解决，如GC停顿”Stop The World”是垃圾回收重点关注的问题，后面介绍垃圾回收器时应注意：低GC停顿是其一个关注。]]></content>
      <categories>
        <category>垃圾回收</category>
        <category>jvm基础</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库隔离]]></title>
    <url>%2F2019%2F09%2F21%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9A%94%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[数据库常用的事务隔离级别什么是事务隔离？ 任何支持事务的数据库，都必须具备四个特性，分别是：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability），也就是我们常说的事务ACID，这样才能保证事务（（Transaction）中数据的正确性。 而事务的隔离性就是指，多个并发的事务同时访问一个数据库时，一个事务不应该被另一个事务所干扰，每个并发的事务间要相互进行隔离。 如果没有事务隔离，会出现什么样的情况呢？ 假设我们现在有这样一张表（T），里面记录了很多牛人的名字，我们不进行事务的隔离看看会发生什么呢？ 第一天，事务A访问了数据库，它干了一件事情，往数据库里加上了新来的牛人的名字，但是没有提交事务。 insert into T values (4, ‘牛D’); 这时，来了另一个事务B，他要查询所有牛人的名字。 select Name from T; 这时，如果没有事务之间没有有效隔离，那么事务B返回的结果中就会出现“牛D”的名字。这就是“脏读（dirty read）”。 第二天，事务A访问了数据库，他要查看ID是1的牛人的名字，于是执行了 select Name from T where ID = 1; 这时，事务B来了，因为ID是1的牛人改名字了，所以要更新一下，然后提交了事务。 update T set Name = ‘不牛’ where ID = 1; 接着，事务A还想再看看ID是1的牛人的名字，于是又执行了 select Name from T where ID = 1; 结果，两次读出来的ID是1的牛人名字竟然不相同，这就是不可重复读（unrepeatable read）。 第三天，事务A访问了数据库，他想要看看数据库的牛人都有哪些，于是执行了 select * from T; 这时候，事务B来了，往数据库加入了一个新的牛人。 insert into T values(4, ‘牛D’); 这时候，事务A忘了刚才的牛人都有哪些了，于是又执行了。 select * from T; 结果，第一次有三个牛人，第二次有四个牛人。 相信这个时候事务A就蒙了，刚才发生了什么？这种情况就叫“幻读（phantom problem）”。 为了防止出现脏读、不可重复读、幻读等情况，我们就需要根据我们的实际需求来设置数据库的隔离级别。 数据库都有哪些隔离级别呢？ 一般的数据库，都包括以下四种隔离级别： 读未提交（Read Uncommitted）读提交（Read Committed）可重复读（Repeated Read）串行化（Serializable）如何使用这些隔离级别，那就需要根据业务的实际情况来进行判断了。 我们接下来就看看这四个隔离级别的具体情况 隔离级别读未提交（Read Uncommitted）读未提交，顾名思义，就是可以读到未提交的内容。 因此，在这种隔离级别下，查询是不会加锁的，也由于查询的不加锁，所以这种隔离级别的一致性是最差的，可能会产生“脏读”、“不可重复读”、“幻读”。 如无特殊情况，基本是不会使用这种隔离级别的。 读提交（Read Committed）读提交，顾名思义，就是只能读到已经提交了的内容。 这是各种系统中最常用的一种隔离级别，也是SQL Server和Oracle的默认隔离级别。这种隔离级别能够有效的避免脏读，但除非在查询中显示的加锁，如： select * from T where ID=2 lock in share mode; select * from T where ID=2 for update; 不然，普通的查询是不会加锁的。 那为什么“读提交”同“读未提交”一样，都没有查询加锁，但是却能够避免脏读呢？ 这就要说道另一个机制“快照（snapshot）”，而这种既能保证一致性又不加锁的读也被称为“快照读（Snapshot Read）” 假设没有“快照读”，那么当一个更新的事务没有提交时，另一个对更新数据进行查询的事务会因为无法查询而被阻塞，这种情况下，并发能力就相当的差。 而“快照读”就可以完成高并发的查询，不过，“读提交”只能避免“脏读”，并不能避免“不可重复读”和“幻读”。 可重复读(Repeated Read)可重复读，顾名思义，就是专门针对“不可重复读”这种情况而制定的隔离级别，自然，它就可以有效的避免“不可重复读”。而它也是MySql的默认隔离级别。 在这个级别下，普通的查询同样是使用的“快照读”，但是，和“读提交”不同的是，当事务启动时，就不允许进行“修改操作（Update）”了，而“不可重复读”恰恰是因为两次读取之间进行了数据的修改，因此，“可重复读”能够有效的避免“不可重复读”，但却避免不了“幻读”，因为幻读是由于“插入或者删除操作（Insert or Delete）”而产生的。 串行化（Serializable）这是数据库最高的隔离级别，这种级别下，事务“串行化顺序执行”，也就是一个一个排队执行。 这种级别下，“脏读”、“不可重复读”、“幻读”都可以被避免，但是执行效率奇差，性能开销也最大，所以基本没人会用。 总结为什么会出现“脏读”？因为没有“select”操作没有规矩。 为什么会出现“不可重复读”？因为“update”操作没有规矩。 为什么会出现“幻读”？因为“insert”和“delete”操作没有规矩。 “读未提（Read Uncommitted）”能预防啥？啥都预防不了。 “读提交（Read Committed）”能预防啥？使用“快照读（Snapshot Read）”，避免“脏读”，但是可能出现“不可重复读”和“幻读”。 “可重复读（Repeated Red）”能预防啥？使用“快照读（Snapshot Read）”，锁住被读取记录，避免出现“脏读”、“不可重复读”，但是可能出现“幻读”。 “串行化（Serializable）”能预防啥？排排坐，吃果果，有效避免“脏读”、“不可重复读”、“幻读”，不过效果谁用谁知道。]]></content>
      <categories>
        <category>mysql</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库隔离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA内部类]]></title>
    <url>%2F2019%2F09%2F17%2FJAVA%E5%86%85%E9%83%A8%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[JAVA内部类内部类在 Java 里面算是非常常见的一个功能了，在日常开发中我们肯定多多少少都用过，这里总结一下关于 Java 中内部类的相关知识点和一些使用内部类时需要注意的点。从种类上说，内部类可以分为四类：普通内部类、静态内部类、匿名内部类、局部内部类。我们来一个个看： 普通内部类这个是最常见的内部类之一了，其定义也很简单，在一个类里面作为类的一个字段直接定义就可以了，例 public class InnerClassTest { public class InnerClassA { } } 在这里 InnerClassA 类为 InnerClassTest 类的普通内部类，在这种定义方式下，普通内部类对象依赖外部类对象而存在，即在创建一个普通内部类对象时首先需要创建其外部类对象，我们在创建上面代码中的 InnerClassA 对象时先要创建 InnerClassTest 对象，例： public class InnerClassTest { public int outField1 = 1; protected int outField2 = 2; int outField3 = 3; private int outField4 = 4; public InnerClassTest() { // 在外部类对象内部，直接通过 new InnerClass(); 创建内部类对象 InnerClassA innerObj = new InnerClassA(); System.out.println(&quot;创建 &quot; + this.getClass().getSimpleName() + &quot; 对象&quot;); System.out.println(&quot;其内部类的 field1 字段的值为: &quot; + innerObj.field1); System.out.println(&quot;其内部类的 field2 字段的值为: &quot; + innerObj.field2); System.out.println(&quot;其内部类的 field3 字段的值为: &quot; + innerObj.field3); System.out.println(&quot;其内部类的 field4 字段的值为: &quot; + innerObj.field4); } public class InnerClassA { public int field1 = 5; protected int field2 = 6; int field3 = 7; private int field4 = 8; // static int field5 = 5; // 编译错误！普通内部类中不能定义 static 属性 public InnerClassA() { System.out.println(&quot;创建 &quot; + this.getClass().getSimpleName() + &quot; 对象&quot;); System.out.println(&quot;其外部类的 outField1 字段的值为: &quot; + outField1); System.out.println(&quot;其外部类的 outField2 字段的值为: &quot; + outField2); System.out.println(&quot;其外部类的 outField3 字段的值为: &quot; + outField3); System.out.println(&quot;其外部类的 outField4 字段的值为: &quot; + outField4); } } public static void main(String[] args) { InnerClassTest outerObj = new InnerClassTest(); // 不在外部类内部，使用：外部类对象. new 内部类构造器(); 的方式创建内部类对象 // InnerClassA innerObj = outerObj.new InnerClassA(); } } 这里的内部类就像外部类声明的一个属性字段一样，可以有访问限定符，也因此new其对象时依附于外部类对象而存在的，我们来看一下结果 我们注意到，内部类对象可以访问外部类对象中所有访问权限的字段，同时，外部类对象也可以通过内部类的对象引用来访问内部类中定义的所有访问权限的字段，后面我们将从源码里面分析具体的原因。成员内部类不能定义静态成员。 静态内部类我们知道，一个类的静态成员独立于这个类的任何一个对象存在，只要在具有访问权限的地方，我们就可以通过 类名.静态成员名 的形式来访问这个静态成员，同样的，静态内部类也是作为一个外部类的静态成员而存在，创建一个类的静态内部类对象不需要依赖其外部类对象。例： public class InnerClassTest { public int field1 = 1; public InnerClassTest() { System.out.println(&quot;创建 &quot; + this.getClass().getSimpleName() + &quot; 对象&quot;); // 创建静态内部类对象 StaticClass innerObj = new StaticClass(); System.out.println(&quot;其内部类的 field1 字段的值为: &quot; + innerObj.field1); System.out.println(&quot;其内部类的 field2 字段的值为: &quot; + innerObj.field2); System.out.println(&quot;其内部类的 field3 字段的值为: &quot; + innerObj.field3); System.out.println(&quot;其内部类的 field4 字段的值为: &quot; + innerObj.field4); } static class StaticClass { public int field1 = 1; protected int field2 = 2; int field3 = 3; private int field4 = 4; // 静态内部类中可以定义 static 属性 static int field5 = 5; public StaticClass() { System.out.println(&quot;创建 &quot; + StaticClass.class.getSimpleName() + &quot; 对象&quot;); // System.out.println(&quot;其外部类的 field1 字段的值为: &quot; + field1); // 编译错误！！ } } public static void main(String[] args) { // 无需依赖外部类对象，直接创建内部类对象 InnerClassTest.StaticClass staticClassObj = new InnerClassTest.StaticClass(); } } 可以看到，静态内部类就像外部类的一个静态成员一样，创建其对象无需依赖外部类对象（访问一个类的静态成员也无需依赖这个类的对象，因为它是独立于所有类的对象的,new它的对象时无需加载外部类）。但是于此同时，静态内部类中也无法访问外部类的非静态成员，因为外部类的非静态成员是属于每一个外部类对象的，而本身静态内部类就是独立外部类对象存在的，所以静态内部类不能访问外部类的非静态成员，而外部类依然可以访问静态内部类对象的所有访问权限的成员，这一点和普通内部类无异。 匿名内部类匿名内部类有多种形式，其中最常见的一种形式莫过于在方法参数中新建一个接口对象 / 类对象，并且实现这个接口声明 / 类中原有的方法了： public class InnerClassTest { public int field1 = 1; protected int field2 = 2; int field3 = 3; private int field4 = 4; public InnerClassTest() { System.out.println(&quot;创建 &quot; + this.getClass().getSimpleName() + &quot; 对象&quot;); } // 自定义接口 interface OnClickListener { void onClick(Object obj); } private void anonymousClassTest() { // 在这个过程中会新建一个匿名内部类对象， // 这个匿名内部类实现了 OnClickListener 接口并重写 onClick 方法 OnClickListener clickListener = new OnClickListener() { // 可以在内部类中定义属性，但是只能在当前内部类中使用， // 无法在外部类中使用，因为外部类无法获取当前匿名内部类的类名， // 也就无法创建匿名内部类的对象 int field = 1; @Override public void onClick(Object obj) { System.out.println(&quot;对象 &quot; + obj + &quot; 被点击&quot;); System.out.println(&quot;其外部类的 field1 字段的值为: &quot; + field1); System.out.println(&quot;其外部类的 field2 字段的值为: &quot; + field2); System.out.println(&quot;其外部类的 field3 字段的值为: &quot; + field3); System.out.println(&quot;其外部类的 field4 字段的值为: &quot; + field4); } }; // new Object() 过程会新建一个匿名内部类，继承于 Object 类， // 并重写了 toString() 方法 clickListener.onClick(new Object() { @Override public String toString() { return &quot;obj1&quot;; } }); } public static void main(String[] args) { InnerClassTest outObj = new InnerClassTest(); outObj.anonymousClassTest(); } } 上面的代码中展示了常见的两种使用匿名内部类的情况：1、直接 new 一个接口，并实现这个接口声明的方法，在这个过程其实会创建一个匿名内部类实现这个接口，并重写接口声明的方法，然后再创建一个这个匿名内部类的对象并赋值给前面的 OnClickListener 类型的引用；2、new 一个已经存在的类 / 抽象类，并且选择性的实现这个类中的一个或者多个非 final 的方法，这个过程会创建一个匿名内部类对象继承对应的类 / 抽象类，并且重写对应的方法。 同样的，在匿名内部类中可以使用外部类的属性，但是外部类却不能使用匿名内部类中定义的属性，因为是匿名内部类，因此在外部类中无法获取这个类的类名，也就无法得到属性信息。 局部内部类局部内部类使用的比较少，其声明在一个方法体 / 一段代码块的内部，而且不在定义类的定义域之内便无法使用，其提供的功能使用匿名内部类都可以实现，而本身匿名内部类可以写得比它更简洁，因此局部内部类用的比较少。来看一个局部内部类的小例子： public class InnerClassTest { public int field1 = 1; protected int field2 = 2; int field3 = 3; private int field4 = 4; public InnerClassTest() { System.out.println(&quot;创建 &quot; + this.getClass().getSimpleName() + &quot; 对象&quot;); } private void localInnerClassTest() { // 局部内部类 A，只能在当前方法中使用 class A { // static int field = 1; // 编译错误！局部内部类中不能定义 static 字段 public A() { System.out.println(&quot;创建 &quot; + A.class.getSimpleName() + &quot; 对象&quot;); System.out.println(&quot;其外部类的 field1 字段的值为: &quot; + field1); System.out.println(&quot;其外部类的 field2 字段的值为: &quot; + field2); System.out.println(&quot;其外部类的 field3 字段的值为: &quot; + field3); System.out.println(&quot;其外部类的 field4 字段的值为: &quot; + field4); } } A a = new A(); if (true) { // 局部内部类 B，只能在当前代码块中使用 class B { public B() { System.out.println(&quot;创建 &quot; + B.class.getSimpleName() + &quot; 对象&quot;); System.out.println(&quot;其外部类的 field1 字段的值为: &quot; + field1); System.out.println(&quot;其外部类的 field2 字段的值为: &quot; + field2); System.out.println(&quot;其外部类的 field3 字段的值为: &quot; + field3); System.out.println(&quot;其外部类的 field4 字段的值为: &quot; + field4); } } B b = new B(); } // B b1 = new B(); // 编译错误！不在类 B 的定义域内，找不到类 B， } public static void main(String[] args) { InnerClassTest outObj = new InnerClassTest(); outObj.localInnerClassTest(); } } 同样的，在局部内部类里面可以访问外部类对象的所有访问权限的字段，而外部类却不能访问局部内部类中定义的字段，因为局部内部类的定义只在其特定的方法体 / 代码块中有效，一旦出了这个定义域，那么其定义就失效了，就像代码注释中描述的那样，即外部类不能获取局部内部类的对象，因而无法访问局部内部类的字段。最后看看运行结果： 内部类的嵌套内部类的嵌套，即为内部类中再定义内部类，这个问题从内部类的分类角度去考虑比较合适： 普通内部类：在这里我们可以把它看成一个外部类的普通成员方法，在其内部可以定义普通内部类（嵌套的普通内部类），但是无法定义 static 修饰的内部类，就像你无法在成员方法中定义 static 类型的变量一样，当然也可以定义匿名内部类和局部内部类； 静态内部类：因为这个类独立于外部类对象而存在，我们完全可以将其拿出来，去掉修饰它的 static 关键字，他就是一个完整的类，因此在静态内部类内部可以定义普通内部类，也可以定义静态内部类，同时也可以定义 static 成员； 匿名内部类：和普通内部类一样，定义的普通内部类只能在这个匿名内部类中使用，定义的局部内部类只能在对应定义域内使用； 局部内部类：和匿名内部类一样，但是嵌套定义的内部类只能在对应定义域内使用。 深入理解内部类不知道小伙伴们对上面的代码有没有产生疑惑：非静态内部类可以访问外部类所有访问权限修饰的字段（即包括了 private 权限的），同时，外部类也可以访问内部类的所有访问权限修饰的字段。而我们知道，private 权限的字段只能被当前类本身访问。然而在上面我们确实在代码中直接访问了对应外部类 / 内部类的 private 权限的字段，要解除这个疑惑，只能从编译出来的类下手了，为了简便，这里采用下面的代码进行测试： public class InnerClassTest { int field1 = 1; private int field2 = 2; public InnerClassTest() { InnerClassA inner = new InnerClassA(); int v = inner.x2; } public class InnerClassA { int x1 = field1; private int x2 = field2; } } 我在外部类中定义了一个默认访问权限（同一个包内的类可以访问）的字段 field1， 和一个 private 权限的字段 field2 ，并且定义了一个内部类 InnerClassA ，并且在这个内部类中也同样定义了两个和外部类中定义的相同修饰权限的字段，并且访问了外部类对应的字段。最后在外部类的构造方法中我定义了一个方法内变量赋值为内部类中 private 权限的字段。我们用 javac 命令（javac InnerClassTest.java）编译这个 .java 文件，会得到两个 .classs 文件：InnerClassTest.class 和 InnerClassTest$InnerClassA.class，我们再用 javap -c 命令（javap -c InnerClassTest 和 javap -c InnerClassTest$InnerClassA）分别反编译这两个 .class 文件，InnerClassTest.class 的字节码如下： 我们注意到字节码中多了一个默认修饰权限并且名为 access$100 的静态方法，其接受一个 InnerClassTest 类型的参数，即其接受一个外部类对象作为参数，方法内部用三条指令取到参数对象的 field2 字段的值并返回。由此，我们现在大概能猜到内部类对象是怎么取到外部类的 private 权限的字段了：就是通过这个外部类提供的静态方法。类似的，我们注意到 24 行字节码指令 invokestatic ，这里代表执行了一个静态方法，而后面的注释也写的很清楚，调用的是 InnerClassTest$InnerClassA.access$000 方法，即调用了内部类中名为 access$000 的静态方法，根据我们上面的外部类字节码规律，我们也能猜到这个方法就是内部类编译过程中编译器自动生成的，那么我们赶紧来看一下 InnerClassTest$InnerClassA 类的字节码吧： 果然，我们在这里发现了名为 access$000 的静态方法，并且这个静态方法接受一个 InnerClassTest$InnerClassA 类型的参数，方法的作用也很简单：返回参数代表的内部类对象的 x2 字段值。我们还注意到编译器给内部类提供了一个接受 InnerClassTest 类型对象（即外部类对象）的构造方法，内部类本身还定义了一个名为 this$0 的 InnerClassTest 类型的引用，这个引用在构造方法中指向了参数所对应的外部类对象。 最后，我们在 25 行字节码指令发现：内部类的构造方法通过 invokestatic 指令执行外部类的 access$100 静态方法（在 InnerClassTest 的字节码中已经介绍了）得到外部类对象的 field2 字段的值，并且在后面赋值给 x2 字段。这样的话内部类就成功的通过外部类提供的静态方法得到了对应外部类对象的 field2 。 上面我们只是对普通内部类进行了分析，但其实匿名内部类和局部内部类的原理和普通内部类是类似的，只是在访问上有些不同：外部类无法访问匿名内部类和局部内部类对象的字段，因为外部类根本就不知道匿名内部类 / 局部内部类的类型信息（匿名内部类的类名被隐匿，局部内部类只能在定义域内使用）。但是匿名内部类和局部内部类却可以访问外部类的私有成员，原理也是通过外部类提供的静态方法来得到对应外部类对象的私有成员的值。而对于静态内部类来说，因为其实独立于外部类对象而存在，因此编译器不会为静态内部类对象提供外部类对象的引用，因为静态内部类对象的创建根本不需要外部类对象支持。但是外部类对象还是可以访问静态内部类对象的私有成员，因为外部类可以知道静态内部类的类型信息，即可以得到静态内部类的对象，那么就可以通过静态内部类提供的静态方法来获得对应的私有成员值。来看一个简单的代码证明： public class InnerClassTest { int field1 = 1; private int field2 = 2; public InnerClassTest() { InnerClassA inner = new InnerClassA(); int v = inner.x2; } // 这里改成了静态内部类，因而不能访问外部类的非静态成员 public static class InnerClassA { private int x2 = 0; } } 同样的编译步骤，得到了两个 .class 文件，这里看一下内部类的 .class 文件反编译的字节码 InnerClassTest$InnerClassA： 仔细看一下，确实没有找到指向外部类对象的引用，编译器只为这个静态内部类提供了一个无参构造方法。而且因为外部类对象需要访问当前类的私有成员，编译器给这个静态内部类生成了一个名为 access$000 的静态方法，作用已不用我多说了。如果我们不看类名，这个类完全可以作为一个普通的外部类来看，这正是静态内部类和其余的内部类的区别所在：静态内部类对象不依赖其外部类对象存在，而其余的内部类对象必须依赖其外部类对象而存在。 OK，到这里问题都得到了解释：在非静态内部类访问外部类私有成员 / 外部类访问内部类私有成员 的时候，对应的外部类 / 外部类会生成一个静态方法，用来返回对应私有成员的值，而对应外部类对象 / 内部类对象通过调用其内部类 / 外部类提供的静态方法来获取对应的私有成员的值。 内部类和多重继承我们已经知道，Java 中的类不允许多重继承，也就是说 Java 中的类只能有一个直接父类，而 Java 本身提供了内部类的机制，这是否可以在一定程度上弥补 Java 不允许多重继承的缺陷呢？我们这样来思考这个问题：假设我们有三个基类分别为 A、B、C，我们希望有一个类 D 达成这样的功能：通过这个 D 类的对象，可以同时产生 A 、B 、C 类的对象，通过刚刚的内部类的介绍，我们也应该想到了怎么完成这个需求了，创建一个类 D.java： class A {} class B {} class C {} public class D extends A { // 内部类，继承 B 类 class InnerClassB extends B { } // 内部类，继承 C 类 class InnerClassC extends C { } // 生成一个 B 类对象 public B makeB() { return new InnerClassB(); } // 生成一个 C 类对象 public C makeC() { return new InnerClassC(); } public static void testA(A a) { // ... } public static void testB(B b) { // ... } public static void testC(C c) { // ... } public static void main(String[] args) { D d = new D(); testA(d); testB(d.makeB()); testC(d.makeC()); } } 程序正确运行。而且因为普通内部类可以访问外部类的所有成员并且外部类也可以访问普通内部类的所有成员，因此这种方式在某种程度上可以说是 Java 多重继承的一种实现机制。但是这种方法也是有一定代价的，首先这种结构在一定程度上破坏了类结构，一般来说，建议一个 .java 文件只包含一个类，除非两个类之间有非常明确的依赖关系（比如说某种汽车和其专用型号的轮子），或者说一个类本来就是为了辅助另一个类而存在的（比如说 HashMap 类和其内部用于遍历其元素的 HashIterator 类），那么这个时候使用内部类会有较好代码结构和实现效果。而在其他情况，将类分开写会有较好的代码可读性和代码维护性。 内部类和内存泄露在 Java 中，因为 JVM 有垃圾回收功能，对于我们自己创建的对象无需手动回收这些对象的内存空间，这种机制确实在一定程度上减轻了开发者的负担，但是也增加了开发者对 JVM 垃圾回收机制的依赖性，从某个方面来说，也是弱化了开发者防止内存泄露的意识。当然，JVM 的垃圾回收机制的利是远远大于弊的，只是我们在开发过程中不应该丧失了这种对象和内存的意识。 内部类和内存泄露又有什么关系呢？我们在上面已经知道了，创建非静态内部类的对象时，新建的非静态内部类对象会持有对外部类对象的引用，这个我们在上面的源码反编译中已经介绍过了，正是因为非静态内部类对象会持有外部类对象的引用，因此如果说这个非静态内部类对象因为某些原因无法被回收，就会导致这个外部类对象也无法被回收，这个听起来是有道理的，因为我们在上文也已经介绍了：非静态内部类对象依赖于外部类对象而存在，所以内部类对象没被回收，其外部类对象自然也不能被回收。但是可能存在这种情况：非静态内部类对象在某个时刻已经不在被使用，或者说这个内部类对象可以在不影响程序正确运行的情况下被回收，而因为我们对这个内部类的使用不当而使得其无法被 JVM 回收，同时会导致其外部类对象无法被回收，即为发生内存泄露。那么这个 “使用不当” 具体指的是哪个方面呢？看一个简单的例子，新建一个 MemoryLeakTest 的类： public class MemoryLeakTest { // 抽象类，模拟一些组件的基类 abstract static class Component { final void create() { onCreate(); } final void destroy() { onDestroy(); } // 子类实现，模拟组件创建的过程 abstract void onCreate(); // 子类实现，模拟组件摧毁的过程 abstract void onDestroy(); } // 具体某个组件 static class MyComponent extends Component { // 组件中窗口的单击事件监听器 static OnClickListener clickListener; // 模拟组件中的窗口 MyWindow myWindow; @Override void onCreate() { // 执行组件内一些资源初始化的代码 clickListener = new OnClickListener() { @Override public void onClick(Object obj) { System.out.println(&quot;对象 &quot; + obj + &quot; 被单击&quot;); } }; // 新建我的窗口对象，并设置其单击事件监听器 myWindow = new MyWindow(); myWindow.setClickListener(clickListener); } @Override void onDestroy() { // 执行组件内一些资源回收的代码 myWindow.removeClickListener(); } } // 我的窗口类，模拟一个可视化控件 static class MyWindow { OnClickListener clickListener; // 设置当前控件的单击事件监听器 void setClickListener(OnClickListener clickListener) { this.clickListener = clickListener; } // 移除当前控件的单击事件监听器 void removeClickListener() { this.clickListener = null; } } // 对象的单击事件的监听接口 public interface OnClickListener { void onClick(Object obj); } public static void main(String[] args) { MyComponent myComponent = new MyComponent(); myComponent.create(); myComponent.destroy(); // myComponent 引用置为 null，排除它的干扰 myComponent = null; // 调用 JVM 的垃圾回收动作，回收无用对象 System.gc(); System.out.println(&quot;&quot;); } 我们在代码中添加一些断点，然后采用 debug 模式查看： 程序执行到 72 行代码，此时 72 行代码还未执行，因此 myComponent 引用和其对象还未创建，继续执行： 这里成功创建了一个 MyComponent 对象，但是其 create 方法还未执行，所以 myWindow 字段为 null，这里可能有小伙伴会问了，myComponent 对象的 clickListener 字段呢？怎么不见了？其实这和我们在代码中定义 clickListener 字段的形式有关，我们定义的是 static OnClickListener clickListener; ，因此 clickListener 是一个静态字段，其在类加载的完成的时候储存在 JVM 中内存区域的 方法区 中，而创建的 Java 对象储存在 JVM 的堆内存中，两者不在同一块内存区域。关于这些细节，想深入了解的小伙伴建议阅读《深入理解JVM虚拟机》。好了，我们继续执行代码： myComponent.destroy 方法执行完成之后，myWindow.removeClickListener 方法也执行完成，此时 myWindow 对象中的 clickListener 字段为 null。我们继续： 代码执行到了 80 行，在此之前，所有的代码和解释都没有什么难度，跟着运行图走，一切都那么顺利成章，其实这张图的运行结果也很好理解，只不过图中的文字需要思考一下：myComponent 引用指向的对象真的被回收了吗？要解答这个问题，我们需要借助 Java 中提供的内存分析工具 jvisualvm (以前它还不叫这个名字…），它一般在你安装 JDK 的目录下的 bin 子目录下： 在程序左边可以找到我们当前正在执行的 Java 进程，双击进入： 单击 tab 中的 监视 选项卡，可以看到当前正在执行的 Java 进程的一些资源占用信息，当然我们现在的主要目的是分析内存，那么们单击右上角的 堆 Dump ： 在这个界面，单击 类 选项卡，会出现当前 Java 进程中用到的所有的类，我们已经知道我们要查找的类的对象只创建了一个，因此我们根据右上角的 实例数 来进行排除：我们成功的找到了我们创建的对象！而这样也意味着当我们在上面代码中调用 JVM 的垃圾回收动作没有回收这三个对象，这其实就是一个真真切切的内存泄露！因为我们将 main 方法中的 myComponent 引用赋值为 null，就意味着我们已经不再使用这个组件和里面的一些子组件（MyWindow 对象），即这个组件和其内部的一些组件应该被回收。但是调用 JVM 的垃圾回收却并没有将其对应的对象回收。造成这个问题的原因在哪呢？ 其实就在于我们刚刚在 MyComponent 类中定义的 clickListener 字段，我们在代码中将其定义成了 static 类型的，同时这个字段又指向了一个匿名内部类对象（在 create 方法中 创建了一个 OnClickListener 接口对象，即通过一个匿名内部类实现这个接口并创建其对象），根据 JVM 寻找和标记无用对象的规则（可达性分析算法），其会将 clickListener 字段作为一个 “root” ，并通过它来寻找还有用的对象，在这个例子中，clickListener 字段指向一个匿名内部类对象，这个匿名内部类对象有一个外部类对象（MyComponent 类型的对象）的引用，而外部类对象中又有一个 MyWindow 类型的对象引用。因此 JVM 会将这三个对象都视为有用的对象不会回收。用图来解释吧： Ok，通过这个过程，相信你已经理解了造成此次内存泄露的原因了，那么我们该如何解决呢？对于当前这个例子，我们只需要改一些代码：1、把 MyComponent 类中的 clickListener 字段前面的 static 修饰符去掉就可以了（static OnClickListener clickListener; -&gt; OnClickListener clickListener;），这样的话 clickListener 指向的对象，就作为 MyComponent 类的对象的一部分了，在 MyComponent 对象被回收时里面的子组件也会被回收。同时它们之间也只是互相引用（MyComponent 外部类对象中有一个指向 OnClickListener 内部类对象的引用，OnClickListener 内部类对象有一个指向 MyComponent 外部类对象的引用），根据 JVM 的 “可达性分析” 算法，在两个对象都不再被外部使用时，JVM 的垃圾回收机制是可以标记并回收这两个对象的。虽然不强制要求你在 MyComponent 类中的 onDestroy 方法中将其 clickListener 引用赋值为 null，但是我还是建议你这样做，因为这样更能确保你的程序的安全性（减少发生内存泄露的机率，毕竟匿名内部类对象会持有外部类对象的引用），在某个组件被销毁时将其内部的一些子组件进行合理的处理是一个很好的习惯。 2、你也可以自定义一个静态内部类或者是另外自定义一个类文件，并实现 OnClickListener 接口，之后通过这个类创建对象，这样就可以避免通过非静态内部类的形式创建 OnClickListener 对象增加内存泄露的可能性。 避免内存泄漏那么我们在日常开发中怎么合理的使用内部类来避免产生内存泄露呢？这里给出一点我个人的理解： 1、能用静态内部类就尽量使用静态内部类，从上文中我们也知道了，静态内部类的对象创建不依赖外部类对象，即静态内部对象不会持有外部类对象的引用，自然不会因为静态内部类对象而导致内存泄露，所以如果你的内部类中不需要访问外部类中的一些非 static 成员，那么请把这个内部类改造成静态内部类； 2、对于一些自定义类的对象，慎用 static 关键字修饰（除非这个类的对象的声明周期确实应该很长），我们已经知道，JVM 在进行垃圾回收时会将 static 关键字修饰的一些静态字段作为 “root” 来进行存活对象的查找，所以程序中 static 修饰的对象越多，对应的 “root” 也就越多，每一次 JVM 能回收的对象就越少。当然这并不是建议你不使用 static 关键字，只是在使用这个关键字之前可以考虑一下这个对象使用 static 关键字修饰对程序的执行确实更有利吗？ 3、为某些组件（大型）提供一个当这个大型组件需要被回收的时候用于合理处理其中的一些小组件的方法（例如上面代码中 MyComponent 的 onDestroy 方法），在这个方法中，确保正确的处理一些需要处理的对象（将某些引用置为 null、释放一些其他（CPU…）资源）。]]></content>
      <categories>
        <category>java基础</category>
        <category>java内部类</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC之一次http请求过程]]></title>
    <url>%2F2019%2F09%2F08%2FSpringMVC%E4%B9%8B%E4%B8%80%E6%AC%A1http%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[SpringMVC之一次http请求过程SpringMVC框架是一个基于请求驱动的Web框架，并且使用了‘前端控制器’模型来进行设计，再根据‘请求映射规则’分发给相应的页面控制器进行处理。 整体流程 具体步骤： 1、 首先用户发送请求到前端控制器，前端控制器根据请求信息（如 URL）来决定选择哪一个页面控制器进行处理并把请求委托给它，即以前的控制器的控制逻辑部分；图中的 1、2 步骤； 2、 页面控制器接收到请求后，进行功能处理，首先需要收集和绑定请求参数到一个对象，这个对象在 Spring Web MVC 中叫命令对象，并进行验证，然后将命令对象委托给业务对象进行处理；处理完毕后返回一个 ModelAndView（模型数据和逻辑视图名）；图中的 3、4、5 步骤； 3、 前端控制器收回控制权，然后根据返回的逻辑视图名，选择相应的视图进行渲染，并把模型数据传入以便视图渲染；图中的步骤 6、7； 4、 前端控制器再次收回控制权，将响应返回给用户，图中的步骤 8；至此整个结束。 核心流程 具体步骤： 第一步：发起请求到前端控制器(DispatcherServlet) 第二步：前端控制器请求HandlerMapping查找 Handler （可以根据xml配置、注解进行查找） 第三步：处理器映射器HandlerMapping向前端控制器返回Handler，HandlerMapping会把请求映射为HandlerExecutionChain对象（包含一个Handler处理器（页面控制器）对象，多个HandlerInterceptor拦截器对象），通过这种策略模式，很容易添加新的映射策略 第四步：前端控制器调用处理器适配器去执行Handler 第五步：处理器适配器HandlerAdapter将会根据适配的结果去执行Handler 第六步：Handler执行完成给适配器返回ModelAndView 第七步：处理器适配器向前端控制器返回ModelAndView （ModelAndView是springmvc框架的一个底层对象，包括 Model和view） 第八步：前端控制器请求视图解析器去进行视图解析 （根据逻辑视图名解析成真正的视图(jsp)），通过这种策略很容易更换其他视图技术，只需要更改视图解析器即可 第九步：视图解析器向前端控制器返回View 第十步：前端控制器进行视图渲染 （视图渲染将模型数据(在ModelAndView对象中)填充到request域） 第十一步：前端控制器向用户响应结果 总结 核心开发步骤1、 DispatcherServlet 在 web.xml 中的部署描述，从而拦截请求到 Spring Web MVC 2、 HandlerMapping 的配置，从而将请求映射到处理器 3、 HandlerAdapter 的配置，从而支持多种类型的处理器 注：处理器映射求和适配器使用纾解的话包含在了注解驱动中，不需要在单独配置 4、 ViewResolver 的配置，从而将逻辑视图名解析为具体视图技术 5、 处理器（页面控制器）的配置，从而进行功能处理 View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf…）]]></content>
      <categories>
        <category>SpringMVC</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AOP]]></title>
    <url>%2F2019%2F09%2F08%2FAOP%2F</url>
    <content type="text"><![CDATA[AOP简述AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 AOP技术恰恰相反，它利用一种称为”横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其命名为”Aspect”，即切面。所谓”切面”，简单说就是那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。 使用”横切”技术，AOP把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处基本相似，比如权限认证、日志、事物。AOP的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。 核心概念1、横切关注点 对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点 2、切面（aspect） 类是对物体特征的抽象，切面就是对横切关注点的抽象 3、连接点（joinpoint） 程序执行的某个特定位置（如：某个方法调用前、调用后，方法抛出异常后）。一个类或一段程序代码拥有一些具有边界性质的特定点，这些代码中的特定点就是连接点。Spring仅支持方法的连接点。 4、切入点（pointcut） 对连接点进行拦截的定义，如果连接点相当于数据中的记录，那么切点相当于查询条件，一个切点可以匹配多个连接点。Spring AOP的规则解析引擎负责解析切点所设定的查询条件，找到对应的连接点。 5、通知（advice） 所谓通知指的就是指拦截到连接点之后要执行的代码，通知分为前置、后置、异常、最终、环绕通知五类。Spring提供的增强接口都是带方位名的，如：BeforeAdvice、AfterReturningAdvice、ThrowsAdvice等。 6、目标对象 代理的目标对象 7、织入（weave） 织入是将增强添加到目标类具体连接点上的过程，AOP有三种织入方式：①编译期织入：需要特殊的Java编译期（例如AspectJ的ajc）；②装载期织入：要求使用特殊的类加载器，在装载类的时候对类进行增强；③运行时织入：在运行时为目标类生成代理实现增强。Spring采用了动态代理的方式实现了运行时织入，而AspectJ采用了编译期织入和装载期织入的方式。 8、引入（introduction） 在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法或字段、 9、引介（Introduction） 引介是一种特殊的增强，它为类添加一些属性和方法。这样，即使一个业务类原本没有实现某个接口，通过引介功能，可以动态的未该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。 原理AOP（Aspect Orient Programming），指面向方面（切面）编程，作为面向对象的一种补充，用于处理系统中分布于各个模块的横切关注点，比如事务管理、日志、缓存等等。AOP实现的关键在于AOP框架自动创建的AOP代理，AOP代理主要分为静态代理和动态代理，静态代理的代表为AspectJ；而动态代理则以Spring AOP为代表。通常使用AspectJ的编译时增强实现AOP，AspectJ是静态代理的增强，所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强。 Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。 如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。 Spring AOPSpring中AOP代理由Spring的IOC容器负责生成、管理，其依赖关系也由IOC容器负责管理。因此，AOP代理可以直接使用容器中的其它bean实例作为目标，这种关系可由IOC容器的依赖注入提供。Spring创建代理的规则为： 1、默认使用Java动态代理来创建AOP代理，这样就可以为任何接口实例创建代理了 2、当需要代理的类不是代理接口的时候，Spring会切换为使用CGLIB代理，也可强制使用CGLIB AOP编程其实是很简单的事情，纵观AOP编程，程序员只需要参与三个部分： 1、定义普通业务组件 2、定义切入点，一个切入点可能横切多个业务组件 3、定义增强处理，增强处理就是在AOP框架为普通业务组件织入的处理动作 所以进行AOP编程的关键就是定义切入点和定义增强处理，一旦定义了合适的切入点和增强处理，AOP框架将自动生成AOP代理，即：代理对象的方法=增强处理+被代理对象的方法。 强制使用CGLIB生成代理 前面说过Spring使用动态代理或是CGLIB生成代理是有规则的，高版本的Spring会自动选择是使用动态代理还是CGLIB生成代理内容，当然我们也可以强制使用CGLIB生成代理，那就是aop:config里面有一个”proxy-target-class”属性，这个属性值如果被设置为true，那么基于类的代理将起作用，如果proxy-target-class被设置为false或者这个属性被省略，那么基于接口的代理将起作用 AOP的应用场景Authentication 权限 ，Caching 缓存 ，Context passing 内容传递 ，Error handling 错误处理 ，Lazy loading 懒加载 ，Debugging 调试 ，logging, tracing, profiling and monitoring 记录跟踪 优化 校准，Performance optimization 性能优化 ，Persistence 持久化 ，Resource pooling 资源池 ，Synchronization 同步，Transactions 事务。]]></content>
      <categories>
        <category>AOP</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程之线程池]]></title>
    <url>%2F2019%2F09%2F08%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[多线程之线程池如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。 那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？ 所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。线程池顾名思义就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。 JAVA线程池类型1、newFixedThreadPool创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。 2、newCachedThreadPool创建一个可缓存的线程池。这种类型的线程池特点是：1).工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。2).如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。 3、newSingleThreadExecutor创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，如果这个线程异常结束，会有另一个取代它，保证顺序执行(我觉得这点是它的特色)。单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的 。 4、newScheduleThreadPool创建一个定长的线程池，而且支持定时的以及周期性的任务执行，类似于Timer。(这种线程池原理暂还没完全了解透彻) 线程池有什么优势第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能执行。 第三：提高线程的可管理性，线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。 Java中的ThreadPoolExecutor类java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下ThreadPoolExecutor类的具体实现源码。 在ThreadPoolExecutor类中提供了四个构造方法： public class ThreadPoolExecutor extends AbstractExecutorService { ..... public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); ... } 从上面的代码可以得知，ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。 下面解释下一下构造器中各个参数的含义： corePoolSize：核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程； keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性： TimeUnit.DAYS; //天 TimeUnit.HOURS; //小时 TimeUnit.MINUTES; //分钟 TimeUnit.SECONDS; //秒 TimeUnit.MILLISECONDS; //毫秒 TimeUnit.MICROSECONDS; //微妙 TimeUnit.NANOSECONDS; //纳秒 workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择： ArrayBlockingQueue; LinkedBlockingQueue; SynchronousQueue; ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。 threadFactory：线程工厂，主要用来创建线程； handler：表示当拒绝处理任务时的策略，有以下四种取值： ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 从上面给出的ThreadPoolExecutor类的代码可以知道，ThreadPoolExecutor继承了AbstractExecutorService，我们来看一下AbstractExecutorService的实现： public abstract class AbstractExecutorService implements ExecutorService { protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) { }; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) { }; public Future&lt;?&gt; submit(Runnable task) {}; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) { }; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) { }; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException { }; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException { }; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { }; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException { }; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException { }; } AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。 我们接着看ExecutorService接口的实现： public interface ExecutorService extends Executor { void shutdown(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; } 而ExecutorService又是继承了Executor接口，我们看一下Executor接口的实现： public interface Executor { void execute(Runnable command); } 到这里，大家应该明白了ThreadPoolExecutor、AbstractExecutorService、ExecutorService和Executor几个之间的关系了。 Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的； 然后ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等； 抽象类AbstractExecutorService实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法； 然后ThreadPoolExecutor继承了类AbstractExecutorService。 在ThreadPoolExecutor类中有几个非常重要的方法： execute() submit() shutdown() shutdownNow() execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果（Future相关内容将在下一篇讲述）。 shutdown()和shutdownNow()是用来关闭线程池的。 还有很多其他的方法： 比如：getQueue() 、getPoolSize() 、getActiveCount()、getCompletedTaskCount()等获取与线程池相关属性的方法，有兴趣的朋友可以自行查阅API。 深入剖析线程池实现原理在上面我们从宏观上介绍了ThreadPoolExecutor，下面我们来深入解析一下线程池的具体实现原理，将从下面几个方面讲解： 1.线程池状态 2.任务的执行 3.线程池中的线程初始化 4.任务缓存队列及排队策略 5.任务拒绝策略 6.线程池的关闭 7.线程池容量的动态调整 1.线程池状态在ThreadPoolExecutor中定义了一个volatile变量，另外定义了几个static final变量表示线程池的各个状态： volatile int runState; static final int RUNNING = 0; static final int SHUTDOWN = 1; static final int STOP = 2; static final int TERMINATED = 3; runState表示当前线程池的状态，它是一个volatile变量用来保证线程之间的可见性； 下面的几个static final变量表示runState可能的几个取值。 当创建线程池后，初始时，线程池处于RUNNING状态； 如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕； 如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务； 当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 2.任务的执行 在了解将任务提交给线程池到任务执行完毕整个过程之前，我们先来看一下ThreadPoolExecutor类中其他的一些比较重要成员变量： private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务 private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小 //、runState等）的改变都要使用这个锁 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作集 private volatile long keepAliveTime; //线程存活时间 private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间 private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列） private volatile int maximumPoolSize; //线程池最大能容忍的线程数 private volatile int poolSize; //线程池中当前的线程数 private volatile RejectedExecutionHandler handler; //任务拒绝策略 private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程 private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数 private long completedTaskCount; //用来记录已经执行完毕的任务个数 每个变量的作用都已经标明出来了，这里要重点解释一下corePoolSize、maximumPoolSize、largestPoolSize三个变量。 corePoolSize在很多地方被翻译成核心池大小，其实我的理解这个就是线程池的大小。举个简单的例子： 假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。 因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做； 当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待； 如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来； 然后就将任务也分配给这4个临时工人做； 如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。 当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。 这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。 也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。 不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。 largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系。 下面我们进入正题，看一下任务从提交到最终执行完毕经历了哪些过程。 在ThreadPoolExecutor类中，最核心的任务提交方法是execute()方法，虽然通过submit也可以提交任务，但是实际上submit方法里面最终调用的还是execute()方法，所以我们只需要研究execute()方法的实现原理即可： public void execute(Runnable command) { if (command == null) throw new NullPointerException(); if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) { if (runState == RUNNING &amp;&amp; workQueue.offer(command)) { if (runState != RUNNING || poolSize == 0) ensureQueuedTaskHandled(command); } else if (!addIfUnderMaximumPoolSize(command)) reject(command); // is shutdown or saturated } } 上面的代码可能看起来不是那么容易理解，下面我们一句一句解释： 首先，判断提交的任务command是否为null，若是null，则抛出空指针异常； 接着是这句，这句要好好理解一下： if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) 由于是或条件运算符，所以先计算前半部分的值，如果线程池中当前线程数不小于核心池大小，那么就会直接进入下面的if语句块了。 如果线程池中当前线程数小于核心池大小，则接着执行后半部分，也就是执行： addIfUnderCorePoolSize(command) 如果执行完addIfUnderCorePoolSize这个方法返回false，则继续执行下面的if语句块，否则整个方法就直接执行完毕了。 如果执行完addIfUnderCorePoolSize这个方法返回false，然后接着判断： if (runState == RUNNING &amp;&amp; workQueue.offer(command)) 如果当前线程池处于RUNNING状态，则将任务放入任务缓存队列；如果当前线程池不处于RUNNING状态或者任务放入缓存队列失败，则执行： addIfUnderMaximumPoolSize(command) 如果执行addIfUnderMaximumPoolSize方法失败，则执行reject()方法进行任务拒绝处理。 回到前面： if (runState == RUNNING &amp;&amp; workQueue.offer(command)) 这句的执行，如果说当前线程池处于RUNNING状态且将任务放入任务缓存队列成功，则继续进行判断： if (runState != RUNNING || poolSize == 0) 这句判断是为了防止在将此任务添加进任务缓存队列的同时其他线程突然调用shutdown或者shutdownNow方法关闭了线程池的一种应急措施。如果是这样就执行： ensureQueuedTaskHandled(command) 进行应急处理，从名字可以看出是保证 添加到任务缓存队列中的任务得到处理。 我们接着看2个关键方法的实现：addIfUnderCorePoolSize和addIfUnderMaximumPoolSize： private boolean addIfUnderCorePoolSize(Runnable firstTask) { Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { if (poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); //创建线程去执行firstTask任务 } finally { mainLock.unlock(); } if (t == null) return false; t.start(); return true; } 这个是addIfUnderCorePoolSize方法的具体实现，从名字可以看出它的意图就是当低于核心吃大小时执行的方法。下面看其具体实现，首先获取到锁，因为这地方涉及到线程池状态的变化，先通过if语句判断当前线程池中的线程数目是否小于核心池大小，有朋友也许会有疑问：前面在execute()方法中不是已经判断过了吗，只有线程池当前线程数目小于核心池大小才会执行addIfUnderCorePoolSize方法的，为何这地方还要继续判断？原因很简单，前面的判断过程中并没有加锁，因此可能在execute方法判断的时候poolSize小于corePoolSize，而判断完之后，在其他线程中又向线程池提交了任务，就可能导致poolSize不小于corePoolSize了，所以需要在这个地方继续判断。然后接着判断线程池的状态是否为RUNNING，原因也很简单，因为有可能在其他线程中调用了shutdown或者shutdownNow方法。然后就是执行 t = addThread(firstTask); 这个方法也非常关键，传进去的参数为提交的任务，返回值为Thread类型。然后接着在下面判断t是否为空，为空则表明创建线程失败（即poolSize&gt;=corePoolSize或者runState不等于RUNNING），否则调用t.start()方法启动线程。 我们来看一下addThread方法的实现： private Thread addThread(Runnable firstTask) { Worker w = new Worker(firstTask); Thread t = threadFactory.newThread(w); //创建一个线程，执行任务 if (t != null) { w.thread = t; //将创建的线程的引用赋值为w的成员变量 workers.add(w); int nt = ++poolSize; //当前线程数加1 if (nt &gt; largestPoolSize) largestPoolSize = nt; } return t; } 在addThread方法中，首先用提交的任务创建了一个Worker对象，然后调用线程工厂threadFactory创建了一个新的线程t，然后将线程t的引用赋值给了Worker对象的成员变量thread，接着通过workers.add(w)将Worker对象添加到工作集当中。 下面我们看一下Worker类的实现： private final class Worker implements Runnable { private final ReentrantLock runLock = new ReentrantLock(); private Runnable firstTask; volatile long completedTasks; Thread thread; Worker(Runnable firstTask) { this.firstTask = firstTask; } boolean isActive() { return runLock.isLocked(); } void interruptIfIdle() { final ReentrantLock runLock = this.runLock; if (runLock.tryLock()) { try { if (thread != Thread.currentThread()) thread.interrupt(); } finally { runLock.unlock(); } } } void interruptNow() { thread.interrupt(); } private void runTask(Runnable task) { final ReentrantLock runLock = this.runLock; runLock.lock(); try { if (runState &lt; STOP &amp;&amp; Thread.interrupted() &amp;&amp; runState &gt;= STOP) boolean ran = false; beforeExecute(thread, task); //beforeExecute方法是ThreadPoolExecutor类的一个方法，没有具体实现，用户可以根据 //自己需要重载这个方法和后面的afterExecute方法来进行一些统计信息，比如某个任务的执行时间等 try { task.run(); ran = true; afterExecute(task, null); ++completedTasks; } catch (RuntimeException ex) { if (!ran) afterExecute(task, ex); throw ex; } } finally { runLock.unlock(); } } public void run() { try { Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) { runTask(task); task = null; } } finally { workerDone(this); //当任务队列中没有任务时，进行清理工作 } } } 它实际上实现了Runnable接口，因此上面的Thread t = threadFactory.newThread(w);效果跟下面这句的效果基本一样： Thread t = new Thread(w); 相当于传进去了一个Runnable任务，在线程t中执行这个Runnable。 既然Worker实现了Runnable接口，那么自然最核心的方法便是run()方法了： public void run() { try { Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) { runTask(task); task = null; } } finally { workerDone(this); } } 从run方法的实现可以看出，它首先执行的是通过构造器传进来的任务firstTask，在调用runTask()执行完firstTask之后，在while循环里面不断通过getTask()去取新的任务来执行，那么去哪里取呢？自然是从任务缓存队列里面去取，getTask是ThreadPoolExecutor类中的方法，并不是Worker类中的方法，下面是getTask方法的实现： Runnable getTask() { for (;;) { try { int state = runState; if (state &gt; SHUTDOWN) return null; Runnable r; if (state == SHUTDOWN) // Help drain queue r = workQueue.poll(); else if (poolSize &gt; corePoolSize || allowCoreThreadTimeOut) //如果线程数大于核心池大小或者允许为核心池线程设置空闲时间， //则通过poll取任务，若等待一定的时间取不到任务，则返回null r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS); else r = workQueue.take(); if (r != null) return r; if (workerCanExit()) { //如果没取到任务，即r为null，则判断当前的worker是否可以退出 if (runState &gt;= SHUTDOWN) // Wake up others interruptIdleWorkers(); //中断处于空闲状态的worker return null; } // Else retry } catch (InterruptedException ie) { // On interruption, re-check runState } } } 在getTask中，先判断当前线程池状态，如果runState大于SHUTDOWN（即为STOP或者TERMINATED），则直接返回null。 如果runState为SHUTDOWN或者RUNNING，则从任务缓存队列取任务。 如果当前线程池的线程数大于核心池大小corePoolSize或者允许为核心池中的线程设置空闲存活时间，则调用poll(time,timeUnit)来取任务，这个方法会等待一定的时间，如果取不到任务就返回null。 然后判断取到的任务r是否为null，为null则通过调用workerCanExit()方法来判断当前worker是否可以退出，我们看一下workerCanExit()的实现： private boolean workerCanExit() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); boolean canExit; //如果runState大于等于STOP，或者任务缓存队列为空了 //或者 允许为核心池线程设置空闲存活时间并且线程池中的线程数目大于1 try { canExit = runState &gt;= STOP || workQueue.isEmpty() || (allowCoreThreadTimeOut &amp;&amp; poolSize &gt; Math.max(1, corePoolSize)); } finally { mainLock.unlock(); } return canExit; } 也就是说如果线程池处于STOP状态、或者任务队列已为空或者允许为核心池线程设置空闲存活时间并且线程数大于1时，允许worker退出。如果允许worker退出，则调用interruptIdleWorkers()中断处于空闲状态的worker，我们看一下interruptIdleWorkers()的实现： void interruptIdleWorkers() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) //实际上调用的是worker的interruptIfIdle()方法 w.interruptIfIdle(); } finally { mainLock.unlock(); } } 从实现可以看出，它实际上调用的是worker的interruptIfIdle()方法，在worker的interruptIfIdle()方法中： void interruptIfIdle() { final ReentrantLock runLock = this.runLock; if (runLock.tryLock()) { //注意这里，是调用tryLock()来获取锁的，因为如果当前worker正在执行任务，锁已经被获取了，是无法获取到锁的 //如果成功获取了锁，说明当前worker处于空闲状态 try { if (thread != Thread.currentThread()) thread.interrupt(); } finally { runLock.unlock(); } } } 这里有一个非常巧妙的设计方式，假如我们来设计线程池，可能会有一个任务分派线程，当发现有线程空闲时，就从任务缓存队列中取一个任务交给空闲线程执行。但是在这里，并没有采用这样的方式，因为这样会要额外地对任务分派线程进行管理，无形地会增加难度和复杂度，这里直接让执行完任务的线程去任务缓存队列里面取任务来执行。 我们再看addIfUnderMaximumPoolSize方法的实现，这个方法的实现思想和addIfUnderCorePoolSize方法的实现思想非常相似，唯一的区别在于addIfUnderMaximumPoolSize方法是在线程池中的线程数达到了核心池大小并且往任务队列中添加任务失败的情况下执行的： private boolean addIfUnderMaximumPoolSize(Runnable firstTask) { Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { if (poolSize &lt; maximumPoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); } finally { mainLock.unlock(); } if (t == null) return false; t.start(); return true; } 看到没有，其实它和addIfUnderCorePoolSize方法的实现基本一模一样，只是if语句判断条件中的poolSize &lt; maximumPoolSize不同而已。 到这里，大部分朋友应该对任务提交给线程池之后到被执行的整个过程有了一个基本的了解，下面总结一下： 1）首先，要清楚corePoolSize和maximumPoolSize的含义； 2）其次，要知道Worker是用来起到什么作用的； 3）要知道任务提交给线程池之后的处理策略，这里总结一下主要有4点： 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务； 如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务； 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理； 如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。 3.线程池中的线程初始化默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。 在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程； prestartAllCoreThreads()：初始化所有核心线程 下面是这2个方法的实现： public boolean prestartCoreThread() { return addIfUnderCorePoolSize(null); //注意传进去的参数是null } public int prestartAllCoreThreads() { int n = 0; while (addIfUnderCorePoolSize(null))//注意传进去的参数是null ++n; return n; } 注意上面传进去的参数是null，根据第2小节的分析可知如果传进去的参数为null，则最后执行线程会阻塞在getTask方法中的 r = workQueue.take(); 即等待任务队列中有任务。 4.任务缓存队列及排队策略在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。 workQueue的类型为BlockingQueue，通常可以取下面三种类型： 1）ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小； 2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE； 3）synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。 5.任务拒绝策略当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略： ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 6.线程池的关闭ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 7.线程池容量的动态调整ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()， setCorePoolSize：设置核心池大小setMaximumPoolSize：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构之各种树]]></title>
    <url>%2F2019%2F09%2F03%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%90%84%E7%A7%8D%E6%A0%91%2F</url>
    <content type="text"><![CDATA[数据结构之各种树数据结构中有很多树的结构，其中包括二叉树、二叉搜索树、2-3树、红黑树等等。本文中对数据结构中常见的几种树的概念和用途进行了汇总，不求严格精准，但求简单易懂。 二叉树二叉树是数据结构中一种重要的数据结构，也是树表家族最为基础的结构。 二叉树的定义：二叉树的每个结点至多只有二棵子树(不存在度大于2的结点)，二叉树的子树有左右之分，次序不能颠倒。二叉树的第i层至多有2^(i-1)个结点；深度为k的二叉树至多有2^(k-1)个结点；对任何一棵二叉树T，如果其终端结点数为n0，度为2的结点数为n2，则n0=n2+1。 二叉树示例： 满二叉树和完全二叉树满二叉树：除最后一层无任何子节点外，每一层上的所有结点都有两个子结点。也可以这样理解，除叶子结点外的所有结点均有两个子结点。节点数达到最大值，所有叶子结点必须在同一层上。 满二叉树的性质： 1) 一颗树深度为h，最大层数为k，深度与最大层数相同，k=h; 2) 叶子数为2^h; 3) 第k层的结点数是：2^(k-1); 4) 总结点数是：2^k-1，且总节点数一定是奇数。 完全二叉树：若设二叉树的深度为h，除第 h 层外，其它各层 (1～(h-1)层) 的结点数都达到最大个数，第h层所有的结点都连续集中在最左边，这就是完全二叉树。 注：完全二叉树是效率很高的数据结构，堆是一种完全二叉树或者近似完全二叉树，所以效率极高，像十分常用的排序算法、Dijkstra算法、Prim算法等都要用堆才能优化，二叉排序树的效率也要借助平衡性来提高，而平衡性基于完全二叉树。 二叉查找树二叉查找树定义：又称为是二叉排序树（Binary Sort Tree）或二叉搜索树。二叉排序树或者是一棵空树，或者是具有下列性质的二叉树： 1) 若左子树不空，则左子树上所有结点的值均小于它的根结点的值； 2) 若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值； 3) 左、右子树也分别为二叉排序树； 4) 没有键值相等的节点。 二叉查找树的性质：对二叉查找树进行中序遍历，即可得到有序的数列。 二叉查找树的时间复杂度：它和二分查找一样，插入和查找的时间复杂度均为O(logn)，但是在最坏的情况下仍然会有O(n)的时间复杂度。原因在于插入和删除元素的时候，树没有保持平衡（比如，我们查找上图（b）中的“93”，我们需要进行n次查找操作）。我们追求的是在最坏的情况下仍然有较好的时间复杂度，这就是平衡查找树设计的初衷。 二叉查找树的高度决定了二叉查找树的查找效率。二叉查找树的插入过程如下： 1) 若当前的二叉查找树为空，则插入的元素为根节点; 2) 若插入的元素值小于根节点值，则将元素插入到左子树中; 3) 若插入的元素值不小于根节点值，则将元素插入到右子树中。 二叉查找树的删除，分三种情况进行处理： 1) p为叶子节点，直接删除该节点，再修改其父节点的指针（注意分是根节点和不是根节点），如图a; 2) p为单支节点（即只有左子树或右子树）。让p的子树与p的父亲节点相连，删除p即可（注意分是根节点和不是根节点），如图b; 3) p的左子树和右子树均不空。找到p的后继y，因为y一定没有左子树，所以可以删除y，并让y的父亲节点成为y的右子树的父亲节点，并用y的值代替p的值；或者方法二是找到p的前驱x，x一定没有右子树，所以可以删除x，并让x的父亲节点成为y的左子树的父亲节点。如图c。 平衡二叉树我们知道，对于一般的二叉搜索树（Binary Search Tree），其期望高度（即为一棵平衡树时）为log2n，其各操作的时间复杂度O(log2n)同时也由此而决定。但是，在某些极端的情况下（如在插入的序列是有序的时），二叉搜索树将退化成近似链或链，此时，其操作的时间复杂度将退化成线性的，即O(n)。我们可以通过随机化建立二叉搜索树来尽量的避免这种情况，但是在进行了多次的操作之后，由于在删除时，我们总是选择将待删除节点的后继代替它本身，这样就会造成总是右边的节点数目减少，以至于树向左偏沉。这同时也会造成树的平衡性受到破坏，提高它的操作的时间复杂度。于是就有了我们下边介绍的平衡二叉树。 平衡二叉树定义：平衡二叉树（Balanced Binary Tree）又被称为AVL树（有别于AVL算法），且具有以下性质： 它是一 棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用算法有红黑树、AVL树等。在平衡二叉搜索树中，我们可以看到，其高度一般都良好地维持在O(log2n)，大大降低了操作的时间复杂度。 最小二叉平衡树的节点的公式如下： F(n)=F(n-1)+F(n-2)+1 这个类似于一个递归的数列，可以参考Fibonacci数列，1是根节点，F(n-1)是左子树的节点数量，F(n-2)是右子树的节点数量。 平衡查找树之AVL树AVL树定义：AVL树是最先发明的自平衡二叉查找树。AVL树得名于它的发明者 G.M. Adelson-Velsky 和 E.M. Landis，他们在 1962 年的论文 “An algorithm for the organization of information” 中发表了它。在AVL中任何节点的两个儿子子树的高度最大差别为1，所以它也被称为高度平衡树，n个结点的AVL树最大深度约1.44log2n。查找、插入和删除在平均和最坏情况下都是O(logn)。增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。这个方案很好的解决了二叉查找树退化成链表的问题，把插入，查找，删除的时间复杂度最好情况和最坏情况都维持在O(logN)。但是频繁旋转会使插入和删除牺牲掉O(logN)左右的时间，不过相对二叉查找树来说，时间上稳定了很多。 AVL树的自平衡操作——旋转： AVL树最关键的也是最难的一步操作就是旋转。旋转主要是为了实现AVL树在实施了插入和删除操作以后，树重新回到平衡的方法。下面我们重点研究一下AVL树的旋转。 对于一个平衡的节点，由于任意节点最多有两个儿子，因此高度不平衡时，此节点的两颗子树的高度差2.容易看出，这种不平衡出现在下面四种情况： 1) 6节点的左子树3节点高度比右子树7节点大2，左子树3节点的左子树1节点高度大于右子树4节点，这种情况成为左左。 2) 6节点的左子树2节点高度比右子树7节点大2，左子树2节点的左子树1节点高度小于右子树4节点，这种情况成为左右。 3) 2节点的左子树1节点高度比右子树5节点小2，右子树5节点的左子树3节点高度大于右子树6节点，这种情况成为右左。 4) 2节点的左子树1节点高度比右子树4节点小2，右子树4节点的左子树3节点高度小于右子树6节点，这种情况成为右右。 从图2中可以可以看出，1和4两种情况是对称的，这两种情况的旋转算法是一致的，只需要经过一次旋转就可以达到目标，我们称之为单旋转。2和3两种情况也是对称的，这两种情况的旋转算法也是一致的，需要进行两次旋转，我们称之为双旋转。 单旋转单旋转是针对于左左和右右这两种情况的解决方案，这两种情况是对称的，只要解决了左左这种情况，右右就很好办了。图3是左左情况的解决方案，节点k2不满足平衡特性，因为它的左子树k1比右子树Z深2层，而且k1子树中，更深的一层的是k1的左子树X子树，所以属于左左情况。 为使树恢复平衡，我们把k1变成这棵树的根节点，因为k2大于k1，把k2置于k1的右子树上，而原本在k1右子树的Y大于k1，小于k2，就把Y置于k2的左子树上，这样既满足了二叉查找树的性质，又满足了平衡二叉树的性质。 这样的操作只需要一部分指针改变，结果我们得到另外一颗二叉查找树，它是一棵AVL树，因为X向上一移动了一层，Y还停留在原来的层面上，Z向下移动了一层。整棵树的新高度和之前没有在左子树上插入的高度相同，插入操作使得X高度长高了。因此，由于这颗子树高度没有变化，所以通往根节点的路径就不需要继续旋转了。 双旋转对于左右和右左这两种情况，单旋转不能使它达到一个平衡状态，要经过两次旋转。双旋转是针对于这两种情况的解决方案，同样的，这样两种情况也是对称的，只要解决了左右这种情况，右左就很好办了。图4是左右情况的解决方案，节点k3不满足平衡特性，因为它的左子树k1比右子树D深2层，而且k1子树中，更深的一层的是k1的右子树k2子树，所以属于左右情况。 为使树恢复平衡，我们需要进行两步，第一步，把k1作为根，进行一次右右旋转，旋转之后就变成了左左情况，所以第二步再进行一次左左旋转，最后得到了一棵以k2为根的平衡二叉树。 平衡二叉树之红黑树红黑树的定义：红黑树是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。它是在1972年由鲁道夫·贝尔发明的，称之为”对称二叉B树”，它现代的名字是在 Leo J. Guibas 和 Robert Sedgewick 于1978年写的一篇论文中获得的。它是复杂的，但它的操作有着良好的最坏情况运行时间，并且在实践中是高效的: 它可以在O(logn)时间内做查找，插入和删除，这里的n是树中元素的数目。 红黑树和AVL树一样都对插入时间、删除时间和查找时间提供了最好可能的最坏情况担保。这不只是使它们在时间敏感的应用如实时应用（real time application）中有价值，而且使它们有在提供最坏情况担保的其他数据结构中作为建造板块的价值；例如，在计算几何中使用的很多数据结构都可以基于红黑树。此外，红黑树还是2-3-4树的一种等同，它们的思想是一样的，只不过红黑树是2-3-4树用二叉树的形式表示的。 红黑树的性质： 红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制的一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求: 性质1. 节点是红色或黑色。 性质2. 根是黑色。 性质3. 所有叶子都是黑色（叶子是NIL节点）。 性质4. 每个红色节点必须有两个黑色的子节点。(从每个叶子到根的所有路径上不能有两个连续的红色节点。) 性质5. 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 下面是一个具体的红黑树的图例： 这些约束确保了红黑树的关键特性: 从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限允许红黑树在最坏情况下都是高效的，而不同于普通的二叉查找树。 要知道为什么这些性质确保了这个结果，注意到性质4导致了路径不能有两个毗连的红色节点就足够了。最短的可能路径都是黑色节点，最长的可能路径有交替的红色和黑色节点。因为根据性质5所有最长的路径都有相同数目的黑色节点，这就表明了没有路径能多于任何其他路径的两倍长。 B树B树也是一种用于查找的平衡树，但是它不是二叉树。 B树的定义：B树（B-tree）是一种树状数据结构，能够用来存储排序后的数据。这种数据结构能够让查找数据、循序存取、插入数据及删除的动作，都在对数时间内完成。B树，概括来说是一个一般化的二叉查找树，可以拥有多于2个子节点。与自平衡二叉查找树不同，B-树为系统最优化大块数据的读和写操作。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。这种数据结构常被应用在数据库和文件系统的实作上。 在B树中查找给定关键字的方法是，首先把根结点取来，在根结点所包含的关键字K1,…,Kn查找给定的关键字（可用顺序查找或二分查找法），若找到等于给定值的关键字，则查找成功；否则，一定可以确定要查找的关键字在Ki与Ki+1之间，Pi为指向子树根节点的指针，此时取指针Pi所指的结点继续查找，直至找到，或指针Pi为空时查找失败。 B树作为一种多路搜索树（并不是二叉的）： 1) 定义任意非叶子结点最多只有M个儿子；且M&gt;2； 2) 根结点的儿子数为[2, M]； 3) 除根结点以外的非叶子结点的儿子数为[M/2, M]； 4) 每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字） 5) 非叶子结点的关键字个数=指向儿子的指针个数-1； 6) 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]； 7) 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 8) 所有叶子结点位于同一层； 如下图为一个M=3的B树示例： B+树B+树是B树的变体，也是一种多路搜索树： 1) 其定义基本与B-树相同，除了： 2) 非叶子结点的子树指针与关键字个数相同； 3) 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）； 4) 为所有叶子结点增加一个链指针； 5) 所有关键字都在叶子结点出现； B+树的搜索与B树也基本相同，区别是B+树只有达到叶子结点才命中（B树可以在非叶子结点命中），其性能也等价于在关键字全集做一次二分查找； B+的性质： 1.所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的； 2.不可能在非叶子结点命中； 3.非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层； 4.更适合文件索引系统。 下面为一个B+树创建的示意图： B*树B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针，将结点的最低利用率从1/2提高到2/3。 B树定义了非叶子结点关键字个数至少为(2/3)M，即块的最低使用率为2/3（代替B+树的1/2）； B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针； B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针； 所以，B*树分配新结点的概率比B+树要低，空间使用率更高。 Trie树Tire树称为字典树，又称单词查找树，Trie树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。 Tire树的三个基本性质： 1) 根节点不包含字符，除根节点外每一个节点都只包含一个字符； 2) 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串； 3) 每个节点的所有子节点包含的字符都不相同。 Tire树的应用： 1) 串的快速检索 给出N个单词组成的熟词表，以及一篇全用小写英文书写的文章，请你按最早出现的顺序写出所有不在熟词表中的生词。 在这道题中，我们可以用数组枚举，用哈希，用字典树，先把熟词建一棵树，然后读入文章进行比较，这种方法效率是比较高的。 2) “串”排序 给定N个互不相同的仅由一个单词构成的英文名，让你将他们按字典序从小到大输出。用字典树进行排序，采用数组的方式创建字典树，这棵树的每个结点的所有儿子很显然地按照其字母大小排序。对这棵树进行先序遍历即可。 3) 最长公共前缀 对所有串建立字典树，对于两个串的最长公共前缀的长度即他们所在的结点的公共祖先个数，于是，问题就转化为求公共祖先的问题。]]></content>
      <categories>
        <category>数据结构</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>tag 数据结构</tag>
        <tag>tag 树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM堆内存参数设置]]></title>
    <url>%2F2019%2F09%2F03%2FJVM%E5%A0%86%E5%86%85%E5%AD%98%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[JVM堆内存参数设置堆内存设置原理JVM堆内存分为2块： Permanent Space 和 Heap Space。 Permanent 即 持久代（Permanent Generation），主要存放的是Java类定义信息，与垃圾收集器要收集的Java对象关系不大。 Heap = { Old + NEW = {Eden, from, to} }，Old 即 年老代（Old Generation），New 即 年轻代（Young Generation）。年老代和年轻代的划分对垃圾收集影响比较大。 年轻代所有新生成的对象首先都是放在年轻代。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。年轻代一般分3个区，1个Eden区，2个Survivor区（from 和 to）。 大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当一个Survivor区满时，此区的存活对象将被复制到另外一个Survivor区，当另一个Survivor区也满了的时候，从前一个Survivor区复制过来的并且此时还存活的对象，将可能被复制到年老代。 2个Survivor区是对称的，没有先后关系，所以同一个Survivor区中可能同时存在从Eden区复制过来对象，和从另一个Survivor区复制过来的对象；而复制到年老区的只有从另一个Survivor区过来的对象。而且，因为需要交换的原因，Survivor区至少有一个是空的。特殊的情况下，根据程序需要，Survivor区是可以配置为多个的（多于2个），这样可以增加对象在年轻代中的存在时间，减少被放到年老代的可能。 针对年轻代的垃圾回收即 Young GC。 年老代在年轻代中经历了N次（可配置）垃圾回收后仍然存活的对象，就会被复制到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 针对年老代的垃圾回收即 Full GC。 持久代用于存放静态类型数据，如 Java Class, Method 等。持久代对垃圾回收没有显著影响。但是有些应用可能动态生成或调用一些Class，例如 Hibernate CGLib 等，在这种时候往往需要设置一个比较大的持久代空间来存放这些运行过程中动态增加的类型。 内存申请过程所以，当一组对象生成时，内存申请过程如下： 1、JVM会试图为相关Java对象在年轻代的Eden区中初始化一块内存区域。 2、当Eden区空间足够时，内存申请结束。否则执行下一步。 3、JVM试图释放在Eden区中所有不活跃的对象（Young GC）。释放后若Eden空间仍然不足以放入新对象，JVM则试图将部分Eden区中活跃对象放入Survivor区。 4、Survivor区被用来作为Eden区及年老代的中间交换区域。当年老代空间足够时，Survivor区中存活了一定次数的对象会被移到年老代。 5、当年老代空间不够时，JVM会在年老代进行完全的垃圾回收（Full GC）。 6、 Full GC后，若Survivor区及年老代仍然无法存放从Eden区复制过来的对象，则会导致JVM无法在Eden区为新生成的对象申请内存，即出现“Out of Memory”。 OOM（“Out of Memory”）异常原因OOM（“Out of Memory”）异常一般主要有如下2种原因： 年老代溢出，表现为：java.lang.OutOfMemoryError:Javaheapspace这是最常见的情况，产生的原因可能是：设置的内存参数Xmx过小或程序的内存泄露及使用不当问题。例如循环上万次的字符串处理、创建上千万个对象、在一段代码内申请上百M甚至上G的内存。还有的时候虽然不会报内存溢出，却会使系统不间断的垃圾回收，也无法处理其它请求。这种情况下除了检查程序、打印堆内存等方法排查，还可以借助一些内存分析工具，比如MAT就很不错。 持久代溢出，表现为：java.lang.OutOfMemoryError:PermGenspace通常由于持久代设置过小，动态加载了大量Java类而导致溢出，解决办法唯有将参数 -XX:MaxPermSize 调大（一般256m能满足绝大多数应用程序需求）。将部分Java类放到容器共享区（例如Tomcat share lib）去加载的办法也是一个思路，但前提是容器里部署了多个应用，且这些应用有大量的共享类库。 参数说明-Xmx3550m：设置JVM最大堆内存为3550M。 -Xms3550m：设置JVM初始堆内存为3550M。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 -Xss128k：设置每个线程的栈大小。JDK5.0以后每个线程栈大小为1M，之前每个线程栈大小为256K。应当根据应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。需要注意的是：当这个值被设置的较大（例如&gt;2MB）时将会在很大程度上降低系统的性能。 -Xmn2g：设置年轻代大小为2G。在整个堆内存大小确定的情况下，增大年轻代将会减小年老代，反之亦然。此值关系到JVM垃圾回收，对系统性能影响较大，官方推荐配置为整个堆大小的3/8。 -XX:NewSize=1024m：设置年轻代初始值为1024M。 -XX:MaxNewSize=1024m：设置年轻代最大值为1024M。 -XX:PermSize=256m：设置持久代初始值为256M。 -XX:MaxPermSize=256m：设置持久代最大值为256M。 -XX:NewRatio=4：设置年轻代（包括1个Eden和2个Survivor区）与年老代的比值。表示年轻代比年老代为1:4。 -XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的比值。表示2个Survivor区（JVM堆内存年轻代中默认有2个大小相等的Survivor区）与1个Eden区的比值为2:4，即1个Survivor区占整个年轻代大小的1/6。 -XX:MaxTenuringThreshold=7：表示一个对象如果在Survivor区（救助空间）移动了7次还没有被垃圾回收就进入年老代。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代，对于需要大量常驻内存的应用，这样做可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象在年轻代存活时间，增加对象在年轻代被垃圾回收的概率，减少Full GC的频率，这样做可以在某种程度上提高服务稳定性。 疑问解答-Xmn，-XX:NewSize/-XX:MaxNewSize，-XX:NewRatio 3组参数都可以影响年轻代的大小，混合使用的情况下，优先级是什么？ 如下： 高优先级：-XX:NewSize/-XX:MaxNewSize 中优先级：-Xmn（默认等效 -Xmn=-XX:NewSize=-XX:MaxNewSize=?） 低优先级：-XX:NewRatio 推荐使用-Xmn参数，原因是这个参数简洁，相当于一次设定 NewSize/MaxNewSIze，而且两者相等，适用于生产环境。-Xmn 配合 -Xms/-Xmx，即可将堆内存布局完成。 -Xmn参数是在JDK 1.4 开始支持。 垃圾回收器选择JVM给出了3种选择：串行收集器、并行收集器、并发收集器。串行收集器只适用于小数据量的情况，所以生产环境的选择主要是并行收集器和并发收集器。 默认情况下JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行智能判断。 串行收集器-XX:+UseSerialGC：设置串行收集器。 并行收集器（吞吐量优先）-XX:+UseParallelGC：设置为并行收集器。此配置仅对年轻代有效。即年轻代使用并行收集，而年老代仍使用串行收集。 -XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时有多少个线程一起进行垃圾回收。此值建议配置与CPU数目相等。 -XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0开始支持对年老代并行收集。 -XX:MaxGCPauseMillis=100：设置每次年轻代垃圾回收的最长时间（单位毫秒）。如果无法满足此时间，JVM会自动调整年轻代大小，以满足此时间。 -XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动调整年轻代Eden区大小和Survivor区大小的比例，以达成目标系统规定的最低响应时间或者收集频率等指标。此参数建议在使用并行收集器时，一直打开。 并发收集器（响应时间优先）-XX:+UseConcMarkSweepGC：即CMS收集，设置年老代为并发收集。CMS收集是JDK1.4后期版本开始引入的新GC算法。它的主要适合场景是对响应时间的重要性需求大于对吞吐量的需求，能够承受垃圾回收线程和应用线程共享CPU资源，并且应用中存在比较多的长生命周期对象。CMS收集的目标是尽量减少应用的暂停时间，减少Full GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存。 -XX:+UseParNewGC：设置年轻代为并发收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此参数。 -XX:CMSFullGCsBeforeCompaction=0：由于并发收集器不对内存空间进行压缩和整理，所以运行一段时间并行收集以后会产生内存碎片，内存使用效率降低。此参数设置运行0次Full GC后对内存空间进行压缩和整理，即每次Full GC后立刻开始压缩和整理内存。 -XX:+UseCMSCompactAtFullCollection：打开内存空间的压缩和整理，在Full GC后执行。可能会影响性能，但可以消除内存碎片。 -XX:+CMSIncrementalMode：设置为增量收集模式。一般适用于单CPU情况。 -XX:CMSInitiatingOccupancyFraction=70：表示年老代内存空间使用到70%时就开始执行CMS收集，以确保年老代有足够的空间接纳来自年轻代的对象，避免Full GC的发生。 其它垃圾回收参数-XX:+ScavengeBeforeFullGC：年轻代GC优于Full GC执行。 -XX:-DisableExplicitGC：不响应 System.gc() 代码。 -XX:+UseThreadPriorities：启用本地线程优先级API。即使 java.lang.Thread.setPriority() 生效，不启用则无效。 -XX:SoftRefLRUPolicyMSPerMB=0：软引用对象在最后一次被访问后能存活0毫秒（JVM默认为1000毫秒）。 -XX:TargetSurvivorRatio=90：允许90%的Survivor区被占用（JVM默认为50%）。提高对于Survivor区的使用率。 辅助信息参数设置-XX:-CITime：打印消耗在JIT编译的时间。 -XX:ErrorFile=./hs_err_pid.log：保存错误日志或数据到指定文件中。 -XX:HeapDumpPath=./java_pid.hprof：指定Dump堆内存时的路径。 -XX:-HeapDumpOnOutOfMemoryError：当首次遭遇内存溢出时Dump出此时的堆内存。 -XX:OnError=”;”：出现致命ERROR后运行自定义命令。 -XX:OnOutOfMemoryError=”;”：当首次遭遇内存溢出时执行自定义命令。-XX:-PrintClassHistogram：按下 Ctrl+Break 后打印堆内存中类实例的柱状信息，同JDK的 jmap -histo 命令。 -XX:-PrintConcurrentLocks：按下 Ctrl+Break 后打印线程栈中并发锁的相关信息，同JDK的 jstack -l 命令。 -XX:-PrintCompilation：当一个方法被编译时打印相关信息。-XX:-PrintGC：每次GC时打印相关信息。 -XX:-PrintGCDetails：每次GC时打印详细信息。 -XX:-PrintGCTimeStamps：打印每次GC的时间戳。 -XX:-TraceClassLoading：跟踪类的加载信息。 -XX:-TraceClassLoadingPreorder：跟踪被引用到的所有类的加载信息。-XX:-TraceClassResolution：跟踪常量池。 -XX:-TraceClassUnloading：跟踪类的卸载信息。 关于参数名称等标准参数（-），所有JVM都必须支持这些参数的功能，而且向后兼容；例如： -client——设置JVM使用Client模式，特点是启动速度比较快，但运行时性能和内存管理效率不高，通常用于客户端应用程序或开发调试；在32位环境下直接运行Java程序默认启用该模式。 -server——设置JVM使Server模式，特点是启动速度比较慢，但运行时性能和内存管理效率很高，适用于生产环境。在具有64位能力的JDK环境下默认启用该模式。 非标准参数（-X），默认JVM实现这些参数的功能，但是并不保证所有JVM实现都满足，且不保证向后兼容； 非稳定参数（-XX），此类参数各个JVM实现会有所不同，将来可能会不被支持，需要慎重使用； JVM服务参数调优实战大型网站服务器案例承受海量访问的动态Web应用 服务器配置：8 CPU, 8G MEM, JDK 1.6.X 参数方案： -server -Xmx3550m -Xms3550m -Xmn1256m -Xss128k -XX:SurvivorRatio=6 -XX:MaxPermSize=256m -XX:ParallelGCThreads=8 -XX:MaxTenuringThreshold=0 -XX:+UseConcMarkSweepGC 调优说明： -Xmx 与 -Xms 相同以避免JVM反复重新申请内存。-Xmx 的大小约等于系统内存大小的一半，即充分利用系统资源，又给予系统安全运行的空间。-Xmn1256m 设置年轻代大小为1256MB。此值对系统性能影响较大，Sun官方推荐配置年轻代大小为整个堆的3/8。 -Xss128k 设置较小的线程栈以支持创建更多的线程，支持海量访问，并提升系统性能。 -XX:SurvivorRatio=6 设置年轻代中Eden区与Survivor区的比值。系统默认是8，根据经验设置为6，则2个Survivor区与1个Eden区的比值为2:6，一个Survivor区占整个年轻代的1/8。 -XX:ParallelGCThreads=8 配置并行收集器的线程数，即同时8个线程一起进行垃圾回收。此值一般配置为与CPU数目相等。 -XX:MaxTenuringThreshold=0 设置垃圾最大年龄（在年轻代的存活次数）。如果设置为0的话，则年轻代对象不经过Survivor区直接进入年老代。对于年老代比较多的应用，可以提高效率；如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概率。根据被海量访问的动态Web应用之特点，其内存要么被缓存起来以减少直接访问DB，要么被快速回收以支持高并发海量请求，因此其内存对象在年轻代存活多次意义不大，可以直接进入年老代，根据实际应用效果，在这里设置此值为0。 -XX:+UseConcMarkSweepGC 设置年老代为并发收集。CMS（ConcMarkSweepGC）收集的目标是尽量减少应用的暂停时间，减少Full GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存，适用于应用中存在比较多的长生命周期对象的情况。 内部集成构建服务器案例高性能数据处理的工具应用 服务器配置：1 CPU, 4G MEM, JDK 1.6.X 参数方案： -server -XX:PermSize=196m -XX:MaxPermSize=196m -Xmn320m -Xms768m -Xmx1024m 调优说明： -XX:PermSize=196m -XX:MaxPermSize=196m 根据集成构建的特点，大规模的系统编译可能需要加载大量的Java类到内存中，所以预先分配好大量的持久代内存是高效和必要的。 -Xmn320m 遵循年轻代大小为整个堆的3/8原则。 -Xms768m -Xmx1024m 根据系统大致能够承受的堆内存大小设置即可。 在64位服务器上运行应用程序，构建执行时，用 jmap -heap 11540 命令观察JVM堆内存状况如下： Attaching to process ID 11540, please wait... Debugger attached successfully. Server compiler detected. JVM version is 20.12-b01 using thread-local object allocation. Parallel GC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 1073741824 (1024.0MB) NewSize = 335544320 (320.0MB) MaxNewSize = 335544320 (320.0MB) OldSize = 5439488 (5.1875MB) NewRatio = 2 SurvivorRatio = 8 PermSize = 205520896 (196.0MB) MaxPermSize = 205520896 (196.0MB) Heap Usage: PS Young Generation Eden Space: capacity = 255852544 (244.0MB) used = 101395504 (96.69828796386719MB) free = 154457040 (147.3017120361328MB) 39.63044588683081% used From Space: capacity = 34144256 (32.5625MB) used = 33993968 (32.41917419433594MB) free = 150288 (0.1433258056640625MB) 99.55984397492803% used To Space: capacity = 39845888 (38.0MB) used = 0 (0.0MB) free = 39845888 (38.0MB) 0.0% used PS Old Generation capacity = 469762048 (448.0MB) used = 44347696 (42.29325866699219MB) free = 425414352 (405.7067413330078MB) 9.440459523882184% used PS Perm Generation capacity = 205520896 (196.0MB) used = 85169496 (81.22396087646484MB) free = 120351400 (114.77603912353516MB) 41.440796365543285% used 结果是比较健康的。]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库的依赖以及范式]]></title>
    <url>%2F2019%2F08%2F24%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%BE%9D%E8%B5%96%E4%BB%A5%E5%8F%8A%E8%8C%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[数据库的依赖以及范式三种依赖1.部分依赖设X,Y是关系R的两个属性集合，存在X→Y，若X’是X的真子集，存在X’→Y，则称Y部分函数依赖于X。 举个例子：通过AB能得出C，通过A也能得出C，通过B也能得出C，那么说C部分依赖于AB。 2.完全依赖设X,Y是关系R的两个属性集合，X’是X的真子集，存在X→Y，但对每一个X’都有X’!→Y，则称Y完全函数依赖于X。 举个例子：通过AB能得出C，但是AB单独得不出C，那么说C完全依赖于AB. 3.传递依赖设X,Y,Z是关系R中互不相同的属性集合，存在X→Y(Y !→X),Y→Z，则称Z传递函数依赖于X。 举个例子：通过A得到B，通过B得到C，但是C得不到B，B得不到A，那么成C传递依赖于A 5种范式第一范式（1NF）在任何一个关系数据库中，第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库。所谓第一范式（1NF）是指数据库表的每一列(即每个属性)都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。简而言之，第一范式就是无重复的列。 每个关系r的属性值为不可分的原子值 当赵同学有两个手机号时，他不能将两个手机号存储在一个属性框中，需要分开存放，如下表所示。 错误 正确一 正确二 第二范式（2NF）第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。第二范式（2NF）要求数据库表中的每个实例或行必须可以被唯一地区分。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。员工信息表中加上了员工编号（emp_id）列，因为每个员工的员工编号是唯一的，因此每个员工可以被唯一区分。这个唯一属性列被称为主关键字或主键、主码。 第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。简而言之，第二范式就是非主属性依赖于主关键字。 满足1NF，非主属性完全函数依赖于候选键(左部不可约) 若一张表的数据包括：“学号、姓名、课程号、授课老师”中，设“学号、课程号”为主键，其中，一门课程可以有多个老师进行授课。会存在如下关系： (学号、课程号)→姓名 学号→姓名 ---------为局部依赖，即候选键的一部分可以推出非主属性系名 可分解为两个表，达到完全依赖：“学号、姓名”与“学号、课程号、授课老师” 第三范式（3NF）满足第三范式（3NF）必须先满足第二范式（2NF）。在满足第二范式的基础上，切不存在传递函数依赖，那么就是第三范式。简而言之，第三范式就是属性不依赖于其它非主属性。 满足2NF，消除非主属性对候选键的传递依赖 若一张表的数据包括：“学号、系名、系主任”，其中“学号”为主键，存在如下关系： 学号→系名→系主任 学号→系主任 ---------为传递依赖 同样可分解为两张表：“学号、系名”和“系名、系主任” 对于第三范式，我们反过来理解也是可以的，在表1（学号、系名），表2（系名、系主任）中，学号和系名都是各自表中的主键，所以系名依赖于学号，系主任依赖于系名。当三个数据放置在一张表中时，学号是可以推出系主任的。你可以理解为通过看学生张小二的学号，是可以推理出他的系主任是谁的。 BCNF满足3NF，消除每一属性对候选键的传递依赖 若一张表的数据包括：“书号、书名、作者”其中，书号是唯一的，书名允许相同，一个书号对应一本书。一本书的作者可以多个，但是同一个作者所参与编著的书名应该是不同，希望没有说晕，看图看图。 存在关系： 书号→书名 (书名、作者)→书号 其中，每一个属性都为主属性，但是上述关系存在传递依赖，不能是BCNF。即： (书名、作者)→书号→书名 (书名、作者)→书名 我们可以通过分解为两张表，实现BCNF。 4NF非形式说：只要两个独立的1：N联系出现在一个关系中，那么就可能出现多只依赖。举例说明。 一个表中存在三个数据：“课程、学生、先修课”。假设2017级的计算机专业学生想要学习JAVA课程，那么他们需要先学习VB、C#、BS三门课，才可以选择进行JAVA课程。存在关系： 课程→学生 课程→先修课 两个均是1：N的关系，当出现在一张表的时候，会出现大量的冗余。所以就我们需要分解它，减少冗余。(Ps：该例子主要是为了说明概念帮助理解，具体应用中不会只是这样的简单粗暴的。)]]></content>
      <categories>
        <category>数据库</category>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>tag 数据库依赖</tag>
        <tag>tag 数据库范式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库索引及查询优化]]></title>
    <url>%2F2019%2F08%2F23%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E5%8F%8A%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[数据库索引及查询优化索引的作用一般的应用系统，读写比例在10:1左右，而且插入操作和一般的更新操作很少出现性能问题，在生产环境中，我们遇到最多的，也是最容易出问题的，还是一些复杂的查询操作，因此对查询语句的优化显然是重中之重。说起加速查询，就不得不提到索引了。 索引在MySQL中也叫做“键”，是存储引擎用于快速找到记录的一种数据结构。索引对于良好的性能非常关键，尤其是当表中的数据量越来越大时，索引对于性能的影响愈发重要。 索引优化应该是对查询性能优化最有效的手段了。索引能够轻易将查询性能提高好几个数量级。索引相当于字典的音序表，如果要查某个字，如果不使用音序表，则需要从几百页中逐页去查。 索引原理索引原理目的 提高查询效率 本质 通过不断地缩小想要获取数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件， 有了这种索引机制，可以总是用同一种查找方式来锁定数据。 磁盘IO与预读磁盘IO和预读，磁盘读取数据靠的是机械运动，每次读取数据花费的时间可以分为寻道时间、旋转延迟、传输时间三个部分， 寻道时间 指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下； 旋转延迟 就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2 = 4.17ms； 传输时间 指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。 一次磁盘的时间，即一次磁盘IO的时间约等于5+4.17 = 9ms左右，听起来还挺不错的，但 一台500 -MIPS（Million Instructions Per Second）的机器每秒可以执行5亿条指令， 磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据而是把相邻的数据也都读取到内存缓冲区内，因为 局部预读性原理 告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，对索引的数据结构设计非常有帮助。 索引的数据结构任何一种数据结构都不是凭空产生的，一定会有它的背景和使用场景，要每次查找数据时把磁盘IO次数控制在一个很小的数量级， 最好是常数数量级。多路搜索树， b+树 应运而生。 索引 === 平衡树 —btree(树的平衡—高度) ====== 减少IO 磁盘块(数据项+指针) 磁盘块(数据项+指针) 磁盘块(数据项+指针) 真实的数据项 真实的数据项 真实的数据项 真实的数据项 真实的数据项 (叶子节点) 浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。 b+树的查找过程如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。 b+树性质索引字段要尽量的小：通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。 索引的最左匹配特性：当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 MySQL索引1 功能 索引的功能就是加速查找 mysql中的 primary key，unique，联合唯一也都是索引，这些索引除了加速查找以外，还有约束的功能 2 MySQL常用的索引 普通索引INDEX：加速查找 唯一索引： -主键索引PRIMARY KEY：加速查找+约束（不为空、不能重复） -唯一索引UNIQUE:加速查找+约束（不能重复） 联合索引： -PRIMARY KEY(id,name):联合主键索引 -UNIQUE(id,name):联合唯一索引 -INDEX(id,name):联合普通索引 3 索引的两大类型hash与btree 索引类型，分两类 hash类型的索引：查询单条快，范围查询慢 btree类型的索引：b+树，层数越多，数据量指数级增长（我们就用它，因为innodb默认支持它） 不同的存储引擎支持的索引类型也不一样 InnoDB 支持事务，支持行级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引； MyISAM 不支持事务，支持表级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引； Memory 不支持事务，支持表级别锁定，支持 B-tree、Hash 等索引，不支持 Full-text 索引； NDB 支持事务，支持行级别锁定，支持 Hash 索引，不支持 B-tree、Full-text 等索引； Archive 不支持事务，支持表级别锁定，不支持 B-tree、Hash、Full-text 等索引； 4 创建/删除索引的语法 1 ：创建表时 CREATE TABLE 表名 ( 字段名1 数据类型 [完整性约束条件…], 字段名2 数据类型 [完整性约束条件…], [UNIQUE | FULLTEXT | SPATIAL ] INDEX | KEY [索引名] (字段名[(长度)] [ASC |DESC]) ); 2 ： CREATE在已存在的表上创建索引 CREATE [UNIQUE | FULLTEXT | SPATIAL ] INDEX 索引名 ON 表名 (字段名[(长度)] [ASC |DESC]) ; 3 ：ALTER TABLE在已存在的表上创建索引 ALTER TABLE 表名 ADD [UNIQUE | FULLTEXT | SPATIAL ] INDEX 索引名 (字段名[(长度)] [ASC |DESC]) ; 删除索引：DROP INDEX 索引名 ON 表名字; 5 创建索引时需要注意： === 1 选择区分度高的字段作为 索引 字段 === 2 范围 ，条件不明确的 有索引 速度也会很慢 === 3 索引字段 不能 通过 *10 avg() 查询 === 4 最左前缀 --联合索引 (a,b,c,d) 重复性高的 字段( name ,gender )不要加索引 范围大的 索引 速度 会很慢 like &apos;%xx&apos; % 在左边 索引会很慢 要从头到尾先查询一遍 用 name, id 字段 作为 索引的 只能 用 本来的字段进行查询 (不能用 id*10, avg(id) 等来查询) and 左右条件 会先找 有索引的 查 or 会按顺序找 a,b,c,d ==== 联合索引 (a=1,b=1,d=2,c&gt;3) 范围放到最后---最左前缀匹配 select * from s1 where a=3,b=5,c&gt;3,d=6 (先找 区分度高的 索引) 一定是为搜索条件的字段创建索引，比如select * from s1 where id = 333; 就需要为id加上索引 在表中已经有大量数据的情况下，建索引会很慢，且占用硬盘空间，建完后查询速度加快比如create index idx on s1(id);会扫描表中所有的数据，然后以id为数据项，创建索引结构，存放于硬盘的表中。建完以后，再查询就会很快了。 innodb表的索引 会存放于s1.ibd文件中，而 myisam表的索引 则会有单独的索引文件table1.MYIinnodb 引擎 — frm + idb(数据+索引)myisam 引擎 —- frm + myd + myi (数据与索引分离)MySAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在innodb中，表数据文件本身就是按照B+Tree（BTree即Balance True）组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此innodb表数据文件本身就是主索引。 因为inndob的数据文件要按照主键聚集，所以innodb要求表必须要有主键（Myisam可以没有），如果没有显式定义，则mysql系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则mysql会自动为innodb表生成一个隐含字段作为主键，这字段的长度为6个字节，类型为长整型. 正确使用索引一 索引未命中 并不是说我们创建了索引就一定会加快查询速度，若想利用索引达到预想的提高查询速度的效果，我们在添加索引时，必须遵循以下问题 1 范围问题，或者说条件不明确，条件中出现这些符号或关键字：&gt;、&gt;=、&lt;、&lt;=、!= 、between…and…、like、 大于号、小于号 不等于！= between …and… like 2 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录 3 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 4 索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’) 5 and/or #注意：条件1 and 条件2:查询原理是：首先条件1与条件2都成立的前提下，才算匹配成功一条记录；其次mysql会按先优先判断索引字段的条件,如果按照该条件为真，但锁定的范围很小，或者干脆为假，那我们即便是没有为其他条件的字段添加索引，最终的结果仍然很快 #例如：若条件1的字段有索引，而条件2的字段没有索引，那么如果在按照条件1查出的结果很少的情况下，即便我们没有为条件2创建索引，最终的查询速度依然很快 若条件1的字段没有索引，而条件2的字段有索引，那么如果在按照条件2查出的结果很少的情况下，即便我们没有为条件1创建索引，最终的查询速度依然很快 在左边条件成立但是索引字段的区分度低的情况下（name与gender均属于这种情况），会依次往右找到一个区分度高的索引字段，加速查询 经过分析，在条件为name=’egon’ and gender=’male’ and id&gt;333 and email=’xxx’的情况下，我们完全没必要为前三个条件的字段加索引，因为只能用上email字段的索引，前三个字段的索引反而会降低我们的查询效率 6 最左前缀匹配原则，非常重要的原则，对于组合索引mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配(指的是范围大了，有索引速度也慢)，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 7 其他情况 复制代码 使用函数 select * from tb1 where reverse(email) = ‘egon’; 类型不一致 如果列是字符串类型，传入条件是必须用引号引起来，不然… select * from tb1 where email = 999; #排序条件为索引，则select字段必须也是索引字段，否则无法命中 order by select name from s1 order by email desc; 当根据索引排序时候，select查询的字段如果不是索引，则速度仍然很慢 select email from s1 order by email desc; 特别的：如果对主键排序，则还是速度很快： select * from tb1 order by nid desc; 组合索引最左前缀 如果组合索引为：(name,email) name and email – 命中索引 name – 命中索引 email – 未命中索引 count(1)或count(列)代替count(*)在mysql中没有差别了 create index xxxx on tb(title(19)) #text类型，必须制定长度 其他注意事项 避免使用select * count(1)或count(列) 代替 count(*) 创建表时尽量时 char 代替 varchar 表的字段顺序固定长度的字段优先 组合索引代替多个单列索引（经常使用多个条件查询时） 尽量使用短索引 使用连接（JOIN）来代替子查询(Sub-Queries) 连表时注意条件类型需一致 索引散列值（重复少）不适合建索引，例：性别不适合 覆盖索引与索引合并覆盖索引 所有字段（条件的，查询结果的等）都是索引字段 分析 select age from s1 where id=123 and name = ‘egon’; #id字段有索引，但是name字段没有索引 该sql命中了索引，但未覆盖全部。 利用id=123到索引的数据结构中定位到了id字段，但是仍要判断name字段，但是name字段没有索引，而且查询结果的字段age也没有索引最牛逼的情况是，索引字段覆盖了所有，那全程通过索引来加速查询以及获取结果就ok了 #索引合并：把多个单列索引合并使用 #分析：组合索引能做到的事情，我们都可以用索引合并去解决，比如create index ne on s1(name,email); 组合索引 我们完全可以单独为name和email创建索引，然后按照where name=’xxx’ and email=’xxx’使用 #索引合并 组合索引可以命中： select * from s1 where name=&apos;egon&apos; ; select * from s1 where name=&apos;egon&apos; and email=&apos;adf&apos;; 索引合并可以命中： select * from s1 where name=&apos;egon&apos; ; select * from s1 where email=&apos;adf&apos;; select * from s1 where name=&apos;egon&apos; and email=&apos;adf&apos;; 乍一看好像索引合并更好了：可以命中更多的情况，但其实要分情况去看，如果是name=’egon’ and email=’adf’,那么组合索引的效率要高于索引合并，如果是单条件查，那么还是用索引合并比较合理 查询优化神器-explain关于explain命令相信大家并不陌生，具体用法和字段含义可以参考官网explain-output，这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。 执行计划：让mysql预估执行操作(一般正确) all &lt; index &lt; range &lt; index_merge &lt; ref_or_null &lt; ref &lt; eq_ref &lt; system/const id,email 慢： select * from userinfo3 where name=&apos;alex&apos; explain select * from userinfo3 where name=&apos;alex&apos; type: ALL(全表扫描) select * from userinfo3 limit 1; 快： select * from userinfo3 where email=&apos;alex&apos; type: const(走索引) 慢查询优化的基本步骤0.先运行看看是否真的很慢，注意设置SQL_NO_CACHE 1.where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高 2.explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询） 3.order by limit 形式的sql语句让排序的表优先查 4.了解业务方使用场景 5.加索引时参照建索引的几大原则 6.观察结果，不符合预期继续从0分析 慢日志管理慢日志 - 执行时间 &gt; 10 - 未命中索引 - 日志文件路径 配置： - 内存 show variables like &apos;%query%&apos;; show variables like &apos;%queries%&apos;; set global 变量名 = 值 - 配置文件 mysqld --defaults-file=&apos;E:\wupeiqi\mysql-5.7.16-winx64\mysql-5.7.16-winx64\my-default.ini&apos; my.conf内容： slow_query_log = ON slow_query_log_file = D:/.... 注意：修改配置文件之后，需要重启服务]]></content>
      <categories>
        <category>数据库</category>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>tag 数据库索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA静态变量那些事儿]]></title>
    <url>%2F2019%2F08%2F23%2FJAVA%E9%9D%99%E6%80%81%E5%8F%98%E9%87%8F%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%2F</url>
    <content type="text"><![CDATA[JAVA静态变量那些事儿类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载七个阶段。 类初始化是类加载过程的最后一个阶段，到初始化阶段，才真正开始执行类中的Java程序代码。虚拟机规范严格规定了有且只有5种情况必须立即对类进行初始化： 第一种：遇到new、getstatic、putstatic、invokestatic这四条字节码指令时，如果类还没有进行过初始化，则需要先触发其初始化。生成这四条指令最常见的Java代码场景是：使用new关键字实例化对象时、读取或设置一个类的静态字段（static）时（被static修饰又被final修饰的，已在编译期把结果放入常量池的静态字段除外）、以及调用一个类的静态方法时。 第二种：使用Java.lang.refect包的方法对类进行反射调用时，如果类还没有进行过初始化，则需要先触发其初始化。 第三种：当初始化一个类的时候，如果发现其父类还没有进行初始化，则需要先触发其父类的初始化。 第四种：当虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先执行该主类。 第五种：当使用JDK1.5支持时，如果一个java.langl.incoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始 例子说明情况一变量是 static final 修饰的“编译期常量”,如 public static final String a = “JD”; public class Test { public static void main(String[] args) { System.out.println(Test2.a); } } class Test2 { public static final String a = &quot;JD&quot;; static { System.out.print(&quot;OK&quot;); } } 情况二变量是 static final 修饰的“非编译期常量”,如 public static final String a = new String(“JD”); public class Test { public static void main(String[] args) { System.out.println(Test2.a); } } class Test2 { public static final String a = new String(&quot;JD&quot;); static { System.out.print(&quot;OK&quot;); } } 情况三static 变量域不是 final,如 public static String a = “JD”; public class Test { public static void main(String[] args) { System.out.println(Test2.a); } } class Test2 { public static String a = &quot;JD&quot;; static { System.out.print(&quot;OK&quot;); } } 情况四继承是JAVA语言的一个特性，针对类的继承，虚拟机会如何进行父类和子类的初始化加载呢？1. public class Test { public static void main(String[] args) { System.out.print(B.c); } } class A { static { System.out.print(&quot;A&quot;); } } class B extends A { static { System.out.print(&quot;B&quot;); } public static final String c = &quot;C&quot;; } 2. public class Test { public static void main(String[] args) { System.out.print(B.c); } } class A { static { System.out.print(&quot;A&quot;); } } class B extends A { static { System.out.print(&quot;B&quot;); } public static String c = &quot;C&quot;; } 3. public class Test { public static void main(String[] args) { System.out.print(B.c); } } class A { static { System.out.print(&quot;A&quot;); } } class B extends A { static { System.out.print(&quot;B&quot;); } public static String c = new String(&quot;C&quot;); } 4. public class Test { public static void main(String[] args) { System.out.print(B.c); } } class A { static { System.out.print(&quot;A&quot;); } // 测试：只能选择其中一种一条语句 // public static final String c = &quot;C&quot;; // public static String c = &quot;C&quot;; // public static final String c = new String(&quot;C&quot;); public static String c = new String(&quot;C&quot;); } class B extends A { static { System.out.print(&quot;B&quot;); } } 总结如果一个static final值是“编译期常量”，就像static final int numB = 2;那样，那么这个值不需要对B类进行初始化就可以读取。但是，如果只是将一个域设置为static和final的，那不一足以确保这种行为，例如，对static final int numA = Main.rand.nextInt(100);的访问将强制进行类的初始化，因为它不是一个编译期常量。如果一个static 域不是final，那么在对它访问时，总是要求在它被读取之前，要先进行链接(为这个域分配存储空间)和初始化(初始化该存储空间)就像static int numC = 3;那样！！！]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>静态变量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux硬链接与软链接]]></title>
    <url>%2F2019%2F08%2F23%2FLinux%E7%A1%AC%E9%93%BE%E6%8E%A5%E4%B8%8E%E8%BD%AF%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[Linux硬链接与软链接Linux 系统中有软链接和硬链接两种特殊的“文件”。 软链接可以看作是Windows中的快捷方式，可以让你快速链接到目标档案或目录。 硬链接则透过文件系统的inode来产生新档名，而不是产生新档案。 创建方法都很简单： 软链接（符号链接） ln -s source target 硬链接 （实体链接）ln source target Inode要解释清楚两者的区别和联系需要先说清楚 linux 文件系统中的 inode 这个东西。当划分磁盘分区并格式化的时候，整个分区会被划分为两个部分，即inode区和data block(实际数据放置在数据区域中）这个inode即是（目录、档案）文件在一个文件系统中的唯一标识，需要访问这个文件的时候必须先找到并读取这个 文件的 inode。 Inode 里面存储了文件的很多重要参数，其中唯一标识称作 Inumber, 其他信息还有创建时间（ctime）、修改时间(mtime) 、文件大小、属主、归属的用户组、读写权限、数据所在block号等信息。 通常会根据分区的用途来安排inode的数量（这是另外一个话题了），比如文件数量很多而文件都很小，则需要调增inode较大，以便能索引全部文件。否则将会出现这个分区并没有写满而无法写入任何文件的情况。 目录文件与档案文件 目录文件：记录该目录下的文件名 档案文件：记录实际文件数据 inode本身并不记录文件名，文件名记录在目录文件的block当中，所以新增、删除、更改文件名与目录的W权限有关。因此当我们要读某个档案时，就务必经过其目录的inode和block，然后才能够找到待读取档案的inode号，最终才会读到正确的档案block内的数据。系统是通过索引节点(而不是文件名)来定位每一个文件。 目录inode（满足权限？） =&gt; 目录block =&gt; 档案inode（满足权限？） =&gt; 档案block 硬链接 多个档名对应同一个inode，硬链接只是在某个目录下新增一笔档名链 接到某个inode号码的关联记录而已。如果将上图中任何一个档名删除，档案的inode与block都还存在，依然还可以通过另一个档名来读取正确的档 案数据。此外，不论用哪一个档名来编辑，最终的结果都会写入相同的inode和block中，因此均能进行数据的修改。 软连接 软连接就是建立一个独立的文件，而这个文件会让数据的读取指向它link的那个档案的档名，由于只是作为指向的动作，所以当来源档案被删除之后，软连接的档案无法开启，因为找不到原始档名。连结档的内容只有档名，根据档名链接到正确的目录进一步取得目标档案的inode，最终就能够读取到正确的数据。如果目标档案的原始档名被删除了那么整个环节就进行不下去了。 下面用一个实例来说明硬链接和软链接现在目录下有两个文件，一个名为AAA，一个名为BBB。 引用 $ ls -il 963922 -rw-r--r-- 1 ocean ocean 92 2007-05-18 15:46 AAA 963923 -rw-r--r-- 1 ocean ocean 95 2007-05-18 15:46 BBB 首先先做一个AAA的硬链接。 引用 $ ln AAA AAAhard $ls -il 963922 -rw-r--r-- 2 ocean ocean 92 2007-05-18 15:46 AAA 963922 -rw-r--r-- 2 ocean ocean 92 2007-05-18 15:46 AAAhard 963923 -rw-r--r-- 1 ocean ocean 95 2007-05-18 15:46 BBB 这里我们注意在创建链接前，AAA显示的链接数目为1，创建链接后 1.AAA和AAAhard的链接数目都变为2。 2.AAA和AAAhard的inode号是一样的，都是963922。 3.AAA和AAAhard显示的文件大小也是一样，都是92B。 可见进行了ln命令的操作结果：AAA和AAAhard是同一个文件的两个名字， 它们具有同样的索引节点号和文件属性，建立文件AAA的硬链接，就是为 AAA的文件索引节点在当前目录上建立一个新指针。你可以删除其中任何一个，如rm AAA，每次只会删除一个指针，链接数同时减一，只有将所有指向文件内容的指针，也即链接数减为0时，内核才会把文件内容从磁盘上删除。 尽管硬链接节省空间，也是Linux系统整合文件系统的传统方式，但是存在一些不足之处： 1.不允许给目录创建硬链接。 2.不可以在不同文件系统的文件间建立链接。因为 inode 是这个文件在当前分区中的索引值，是相对于这个分区的，当然不能跨越文件系统了。 接着我们做一个指向BBB的软链接，软链接克服了硬链接的不足，没有任何文件系统的限制，任何用户可以创建指向目录的符号链接。因而现在更为广泛使用，它具有更大的灵活性，甚至可以跨越不同机器、不同网络对文件进行链接。 引用 $ ln -s BBB BBBsoft $ ls -il 总用量 0 963922 -rw-r--r-- 2 ocean ocean 92 2007-05-18 15:46 AAA 963922 -rw-r--r-- 2 ocean ocean 92 2007-05-18 15:46 AAAhard 963923 -rw-r--r-- 1 ocean ocean 95 2007-05-18 15:46 BBB 963924 lrwxrwxrwx 1 ocean ocean 3 2007-05-18 15:47 BBBsoft -&gt; BBB 从上面链接后的结果可以看出来软链接与硬链接，区别不仅仅是在概念上，在实现上也是完全不同的。 区别1.硬链接原文件/链接文件公用一个inode号，说明他们是同一个文件，而软链接原文件/链接文件拥有不同的inode号，表明他们是两个不同的文件； 2.在文件属性上软链接明确写出了是链接文件，而硬链接没有写出来，因为在本质上硬链接文件和原文件是完全平等关系； 3.链接数目是不一样的，软链接的链接数目不会增加； 4.文件大小是不一样的，硬链接文件显示的大小是跟原文件是一样的。而这里软链接显示的大小与原文件就不同了，BBB大小是95B，而BBBsoft是3B。因为BBB共有3个字符 5.软链接没有任何文件系统的限制，任何用户可以创建指向目录的符号链接 总之，建立软链接就是建立了一个新文件。当访问链接文件时，系统就会发现他是个链接文件，它读取链接文件找到真正要访问的文件。 当然软链接也有硬链接没有的缺点：因为链接文件包含有原文件的路径信息，所以当原文件从一个目录下移到其他目录中，再访问链接文件，系统就找不到了，而硬链接就没有这个缺陷，你想怎么移就怎么移；还有它要系统分配额外的空间用于建立新的索引节点和保存原文件的路径。]]></content>
      <categories>
        <category>Linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>软硬链接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP拥塞控制、网络各层协议]]></title>
    <url>%2F2019%2F08%2F23%2FTCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E3%80%81%E7%BD%91%E7%BB%9C%E5%90%84%E5%B1%82%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[TCP拥塞控制、网络各层协议我们知道TCP和UDP都是传输层的协议，最大的区别UDP无连接是面向报文的，不保证可靠传输，无拥塞控制，就是TCP是面向连接的协议，能提供安全，可靠，有序的数据传输，保证数据无差错，不丢失，不重复按序到达 那么TCP是如何保证可靠传输的？（1）校验和如果接受到的段检验和有差错，TCP将丢弃这个段，且不会确认收到 （2）流量控制流量控制的目的是防止数据丢失，如果发送方发送的太快，接收方来不及接受处理那么数据就会丢失，所以流量控制是控制发送方的发送速度的。 流量控制采用滑动窗口在实现，在接收端有自己的缓存大小，接收方只允许发送方发送的数据大小就是目前自己的缓存还能接受多少数据，这个大小也就是滑动窗口的大小。接收方在返回确认信息的时候就会返回自己滑动窗口的大小， （3）拥塞控制拥塞控制是作用于网络的，防止过多的数据出现在网络中，导致网络负载过大，主要通过慢开始，快重传，快恢复和避免拥塞来实现的。 慢开始（1）发送方维护一个拥塞窗口cwnd，这个窗口有一个慢开始ssthresh，发送方一开始传输的时候采用慢开始，也就是不会一下子发送大小为ssthresh的数据量，而是按照指数的增长速度来慢慢加大cwnd的大小，如下图。 当cwnd&gt;ssthresh时就开始采用拥塞避免算法 拥塞避免拥塞避免算法就是让cwnd的大小线性增长，一个轮次只增加1，这样不会那么快使得网络拥塞。 不论是在慢开始阶段还是拥塞避免阶段，如果出现网络拥塞，ssthresh的大小变为拥塞发生时cwnd值的一半，然后cwnd变为1，在开始慢开始算法 快重传快重传是指当接收方收到一个失序的数据，可以立刻向发送方发送重复确认信息，而不会等到发送下一个确认时捎带发送，发送方只要接收三个连续的重复确认，就会立刻重复发送刚才没有收到确认的数据 快恢复与快重传配合使用，当发送方接收到连续三个重复确认请求，为了避免网络拥塞，就会把ssthresh的值减少为当然拥塞窗口的一半，但是发送方认为当前网络并没有发生拥塞，因为还可以接收到三个确认请求，所以不会去执行慢开始算法，而是执行拥塞避免算法 （4）停止等待协议发送方没发送一个数据就会等待接收方的确认，超过时间没有收到，就会重传 网络各层协议]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>TCP</tag>
        <tag>拥塞控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL家的引擎]]></title>
    <url>%2F2019%2F08%2F20%2FMySQL%E5%AE%B6%E7%9A%84%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[MySQL数据库引擎数据库引擎数据库引擎是用于存储、处理和保护数据的核心服务。利用数据库引擎可控制访问权限并快速处理事务，从而满足企业内大多数需要处理大量数据的应用程序的要求。使用数据库引擎创建用于联机事务处理或者联机分析处理数据的关系数据库。这包括创建用于存储数据的表和用于查看、管理和保护数据安全的数据库对象（如索引、视图、存储过程）。 MySQL数据库引擎取决于MySQL安装时是如何被编译的。要添加新引擎，就必须重新编译。缺省情况下，MySQL支持三个引擎，ISAM,MYISAM和HEAP。另外两种类型，INNODB和BERKLEY也常常使用。 数据库引擎任务在数据库引擎文档中，各主题的顺序遵循用于实现使用数据库引擎进行数据存储的系统的任务的主要顺序 设计并创建数据库以保持系统所需的关系或XML文档 实现系统以访问和更改数据库中存储的数据。包括实现网站或者使用数据的应用程序性，还包括生成SQL Server工具和使用工具以使用数据的过程 为单位或客户部署实现的系统 提供日常管理以优化数据库性能 查看存储引擎MySQL给开发者提供了查询存储引擎的功能，我这里使用的是MySQL5.1，可以使用： SHOW ENGINES 如果要想查看数据库默认使用哪个引擎，可以通过使用命令： SHOW VARIABLES LIKE ‘storage_engine’; 在MySQL中，不需要在整个服务器中使用同一种存储引擎，针对具体的要求，可以对每一个表使用不同的存储引擎。Support列的值表示某种引擎是否能使用：YES表示可以使用、NO表示不能使用、DEFAULT表示该引擎为当前默认的存储引擎 。下面来看一下其中几种常用的引擎。 修改数据库引擎1、更改方式1：修改配置文件my.ini 将my-small.ini另存为my.ini，在[mysqld]后面添加default-storage-engine=InnoDB，重启服务，数据库默认的引擎修改为InnoDB 2、更改方式2:在建表的时候指定 建表时指定： create table mytbl( id int primary key, name varchar(50) )type=MyISAM; 3、更改方式3：建表后更改 alter table mytbl2 type = InnoDB; MySQL数据库引擎们ISAMISAM是一个定义明确且历经时间考验的数据表格管理方法，它在设计之时就考虑到数据库被查询的次数远大于更新的次数。因此，ISAM执行读取的操作速度很快，而且不占用大量的内存和存储资源。ISAM的两个主要不足之处在于，它不支持事务处理，也不能够容错。如果那你的硬盘崩溃了，那么数据文件无法恢复。如果你正在把ISAM用在关键应用程序里，那就必须经常备份你所有的实时数据。通过其复制性，MYSQL能够支持这样的备份应用程序。 MYISAMMyISAM基于ISAM存储引擎，并对其进行扩展。它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。MyISAM拥有较高的插入、查询速度，但不支持事物。MyISAM主要特性有： 1、大文件（达到63位文件长度）在支持大文件的文件系统和操作系统上被支持 2、当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块，以及若下一个块被删除，就扩展到下一块自动完成 3、每个MyISAM表最大索引数是64，这可以通过重新编译来改变。每个索引最大的列数是16 4、最大的键长度是1000字节，这也可以通过编译来改变，对于键长度超过250字节的情况，一个超过1024字节的键将被用上 5、BLOB和TEXT列可以被索引 6、NULL被允许在索引的列中，这个值占每个键的0~1个字节 7、所有数字键值以高字节优先被存储以允许一个更高的索引压缩 8、每个MyISAM类型的表都有一个AUTO_INCREMENT的内部列，当INSERT和UPDATE操作的时候该列被更新，同时AUTO_INCREMENT列将被刷新。所以说，MyISAM类型表的AUTO_INCREMENT列更新比InnoDB类型的AUTO_INCREMENT更快 9、可以把数据文件和索引文件放在不同目录 10、每个字符列可以有不同的字符集 11、有VARCHAR的表可以固定或动态记录长度 12、VARCHAR和CHAR列可以多达64KB使用MyISAM引擎创建数据库，将产生3个文件。文件的名字以表名字开始，扩展名之处文件类型：frm文件存储表定义、数据文件的扩展名为.MYD（MYData）、索引文件的扩展名时.MYI（MYIndex） InnoDB存储引擎InnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，上图也看到了，InnoDB是默认的MySQL引擎。InnoDB主要特性有： 1、InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事物安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合 2、InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系型数据库引擎锁不能匹敌的 3、InnoDB存储引擎完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上 4、InnoDB支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键 5、InnoDB被用在众多需要高性能的大型数据库站点上InnoDB不创建目录，使用InnoDB时，MySQL将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件 MEMORY存储引擎MEMORY存储引擎将表中的数据存储到内存中，未查询和引用其他表数据提供快速访问。MEMORY主要特性有： 1、MEMORY表的每个表可以有多达32个索引，每个索引16列，以及500字节的最大键长度 2、MEMORY存储引擎执行HASH和BTREE缩影 3、可以在一个MEMORY表中有非唯一键值 4、MEMORY表使用一个固定的记录长度格式 5、MEMORY不支持BLOB或TEXT列 6、MEMORY支持AUTO_INCREMENT列和对可包含NULL值的列的索引 7、MEMORY表在所由客户端之间共享（就像其他任何非TEMPORARY表） 8、MEMORY表内存被存储在内存中，内存是MEMORY表和服务器在查询处理时的空闲中，创建的内部表共享 9、当不再需要MEMORY表的内容时，要释放被MEMORY表使用的内存，应该执行DELETE FROM或TRUNCATE TABLE，或者删除整个表（使用DROP TABLE） 存储引擎的选择 如果要提供提交、回滚、崩溃恢复能力的事物安全（ACID兼容）能力，并要求实现并发控制，InnoDB是一个好的选择 如果数据表主要用来插入和查询记录，则MyISAM引擎能提供较高的处理效率如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存中的Memory引擎，MySQL中使用该引擎作为临时表，存放查询的中间结果 如果只有INSERT和SELECT操作，可以选择Archive，Archive支持高并发的插入操作，但是本身不是事务安全的。Archive非常适合存储归档数据，如记录日志信息可以使用Archive 使用哪一种引擎需要灵活选择，一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求，使用合适的存储引擎，将会提高整个数据库的性能 MyIASM 和 Innodb引擎详解Innodb引擎 Innodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别，关于数据库事务与其隔离级别的内容请见数据库事务与其隔离级别这篇文章。该引擎还提供了行级锁和外键约束，它的设计目标是处理大容量数据库系统，它本身其实就是基于MySQL后台的完整数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引。但是该引擎不支持FULLTEXT类型的索引，而且它没有保存表的行数，当SELECT COUNT(*) FROM TABLE时需要扫描全表。当需要使用数据库事务时，该引擎当然是首选。由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率。但是使用行级锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表。 名词解析：ACID A 事务的原子性(Atomicity)：指一个事务要么全部执行,要么不执行.也就是说一个事务不可能只执行了一半就停止了.比如你从取款机取钱,这个事务可以分成两个步骤:1划卡,2出钱.不可能划了卡,而钱却没出来.这两步必须同时完成.要么就不完成. C 事务的一致性(Consistency)：指事务的运行并不改变数据库中数据的一致性.例如,完整性约束了a+b=10,一个事务改变了a,那么b也应该随之改变. I 独立性(Isolation）:事务的独立性也有称作隔离性,是指两个以上的事务不会出现交错执行的状态.因为这样可能会导致数据不一致. D 持久性(Durability）:事务的持久性是指事务执行成功以后,该事务所对数据库所作的更改便是持久的保存在数据库之中，不会无缘无故的回滚. MyIASM引擎MyIASM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT(插入)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。不过和Innodb不同，MyIASM中存储了表的行数，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描。如果表的读操作远远多于写操作且不需要数据库事务的支持，那么MyIASM也是很好的选择。 两种引擎的选择大尺寸的数据集趋向于选择InnoDB引擎，因为它支持事务处理和故障恢复。数据库的大小决定了故障恢复的时间长短，InnoDB可以利用事务日志进行数据恢复，这会比较快。主键查询在InnoDB引擎下也会相当快，不过需要注意的是如果主键太长也会导致性能问题，关于这个问题我会在下文中讲到。大批的INSERT语句(在每个INSERT语句中写入多行，批量插入)在MyISAM下会快一些，但是UPDATE语句在InnoDB下则会更快一些，尤其是在并发量大的时候。 Index——索引索引（Index）是帮助MySQL高效获取数据的数据结构。MyIASM和Innodb都使用了树这种数据结构做为索引。下面我接着讲这两种引擎使用的索引结构，讲到这里，首先应该谈一下B-Tree和B+Tree。 B-Tree和B+TreeB+Tree是B-Tree的变种，那么我就先讲B-Tree吧，相信大家都知道红黑树，这是我前段时间学《算法》一书时，实现的一颗红黑树，大家可以参考。其实红黑树类似2,3-查找树，这种树既有2叉结点又有3叉结点。B-Tree也与之类似，它的每个结点做多可以有d个分支（叉），d称为B-Tree的度，如下图所示，它的每个结点可以有4个元素，5个分支，于是它的度为5。B-Tree中的元素是有序的，比如图中元素7左边的指针指向的结点中的元素都小于7，而元素7和16之间的指针指向的结点中的元素都处于7和16之间，正是满足这样的关系，才能高效的查找：首先从根节点进行二分查找，找到就返回对应的值，否则就进入相应的区间结点递归的查找，直到找到对应的元素或找到null指针，找到null指针则表示查找失败。这个查找是十分高效的，其时间复杂度为O(logN)（以d为底，当d很大时，树的高度就很低），因为每次检索最多只需要检索树高h个结点。 接下来就该讲B+Tree了，它是B-Tree的变种，如下面两张图所示： MyIASM引擎的索引结构MyISAM引擎的索引结构为B+Tree，其中B+Tree的数据域存储的内容为实际数据的地址，也就是说它的索引和实际的数据是分开的，只不过是用索引指向了实际的数据，这种索引就是所谓的非聚集索引。如下图所示： 这里设表一共有三列，假设我们以Col1为主键，则上图是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示： 同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。 Innodb引擎的索引结构与MyISAM引擎的索引结构同样也是B+Tree，但是Innodb的索引文件本身就是数据文件，即B+Tree的数据域存储的就是实际的数据，这种索引就是聚集索引。这个索引的key就是数据表的主键，因此InnoDB表数据文件本身就是主索引。 并且和MyISAM不同，InnoDB的辅助索引数据域存储的也是相应记录主键的值而不是地址，所以当以辅助索引查找时，会先根据辅助索引找到主键，再根据主键索引找到实际的数据。所以Innodb不建议使用过长的主键，否则会使辅助索引变得过大。建议使用自增的字段作为主键，这样B+Tree的每一个结点都会被顺序的填满，而不会频繁的分裂调整，会有效的提升插入数据的效率。 两者区别： 第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 上图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。 第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，下图为定义在Col3上的一个辅助索引： 这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调(可能是指“非递增”的意思)的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调(可能是指“非递增”的意思)的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。 MyISAM与InnoDB的抉择1、首先我目前平台上承载的大部分项目是读多写少的项目，而MyISAM的读性能是比Innodb强不少的。 2、MyISAM的索引和数据是分开的，并且索引是有压缩的，内存使用率就对应提高了不少。能加载更多索引，而Innodb是索引和数据是紧密捆绑的，没有使用压缩从而会造成Innodb比MyISAM体积庞大不小。 3、从平台角度来说，经常隔1，2个月就会发生应用开发人员不小心update一个表where写的范围不对，导致这个表没法正常用了，这个时候MyISAM的优越性就体现出来了，随便从当天拷贝的压缩包取出对应表的文件，随便放到一个数据库目录下，然后dump成sql再导回到主库，并把对应的binlog补上。如果是Innodb，恐怕不可能有这么快速度，别和我说让Innodb定期用导出xxx.sql机制备份，因为我平台上最小的一个数据库实例的数据量基本都是几十G大小。 4、从我接触的应用逻辑来说，select count(*) 和order by是最频繁的，大概能占了整个sql总语句的60%以上的操作，而这种操作Innodb其实也是会锁表的，很多人以为Innodb是行级锁，那个只是where对它主键是有效，非主键的都会锁全表的。 5、还有就是经常有很多应用部门需要我给他们定期某些表的数据，MyISAM的话很方便，只要发给他们对应那表的frm.MYD,MYI的文件，让他们自己在对应版本的数据库启动就行，而Innodb就需要导出xxx.sql了，因为光给别人文件，受字典数据文件的影响，对方是无法使用的。 6、如果和MyISAM比insert写操作的话，Innodb还达不到MyISAM的写性能，如果是针对基于索引的update操作，虽然MyISAM可能会逊色Innodb,但是那么高并发的写，从库能否追的上也是一个问题，还不如通过多实例分库分表架构来解决。 7、如果是用MyISAM的话，merge引擎可以大大加快应用部门的开发速度，他们只要对这个merge表做一些selectcount(*)操作，非常适合大项目总量约几亿的rows某一类型(如日志，调查统计)的业务表。当然Innodb也不是绝对不用，用事务的项目如模拟炒股项目，我就是用Innodb的，活跃用户20多万时候，也是很轻松应付了，因此我个人也是很喜欢Innodb的，只是如果从数据库平台应用出发，我还是会首MyISAM。另外，可能有人会说你MyISAM无法抗太多写操作，但是我可以通过架构来弥补，说个我现有用的数据库平台容量：主从数据总量在几百T以上，每天十多亿pv的动态页面，还有几个大项目是通过数据接口方式调用未算进pv总数，(其中包括一个大项目因为初期memcached没部署,导致单台数据库每天处理9千万的查询)。而我的整体数据库服务器平均负载都在0.5-1左右。 一般来说，MyISAM适合： (1)做很多count 的计算； (2)插入不频繁，查询非常频繁； (3)没有事务。 InnoDB适合： (1)可靠性要求比较高，或者要求事务； (2)表更新和查询都相当的频繁，并且表锁定的机会比较大的情况指定数据引擎的创建 让所有的灵活性成为可能的开关是提供给ANSI SQL的MySQL扩展——TYPE参数。MySQL能够让你在表格这一层指定数据库引擎，所以它们有时候也指的是table formats。下面的示例代码表明了如何创建分别使用MyISAM、ISAM和HEAP引擎的表格。要注意，创建每个表格的代码是相同的，除了最后的 TYPE参数，这一参数用来指定数据引擎。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>数据库引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈设计模式们]]></title>
    <url>%2F2019%2F08%2F18%2F%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BB%AC%2F</url>
    <content type="text"><![CDATA[JAVA开发中的23种设计模式设计模式(Design Patterns)设计模式是一套被反复使用，多数人知晓的，经过分类编目的，代码设计经验的总结。使用设计模式是为了可重用代码，让代码更容易被他们理解，保证代码可靠性。设计模式使代码编写真正工程化，合理的运用设计模式可以完美解决很多问题，每种模式都有相应的原理与之对应，每一个模式描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案。 分类总体来说，设计模式分为三大类： 创建型模式,5种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式,7种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为模式,11种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介模式、解释器模式 其实还有两类：并发型模式和线程池模式 如图所示: 设计模式的六大原则1、开闭原则（Open Close Principle）开闭原则即 对拓展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。一句话，为了使程序的拓展性好，易于维护和升级。为达到这种效果，我们需要使用接口和抽象类。 2、里氏代换原则（Liskov Substitution Principle LSP)里氏代换原则是面向对象设计的基本原则之一。里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受影响，基类才能真正被复用，而衍生类也能在基类的基础上增加新的行为。里氏代换原则是对‘开闭原则’的补充。实现开闭原则的关键步骤是抽象化。而基类与子类的继承关系就是抽象化的具体实现。所以里氏代换原则就是对实现抽象化的具体步骤规范。 3、依赖倒转原则（Dependence Inversion Principle）这个是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。 4、接口隔离原则（Interface Segregation Principle）使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的意思。 5、迪米特法则（最少知道原则）（Demeter Principle）最少知道原则，就是说：一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 6、合成复用原则（Composite Reuse Principle）原则是尽量使用合成/聚合的方式，而不是使用继承 JAVA中的23种设计模式1、工厂方法模式（Factory Method）工厂方法模式有3种: 普通工厂模式就是建立一个工厂类，对实现了同一接口的一些类进行实例的创建。举个例子 public interface Sender {//通用接口 void send(); } public class MailSender implements Sender{//具体实现1 @Override public void send() { } } public class SmsSender implements Sender {//具体实现2 @Override public void send() { } } public class SendFactory {//工厂类 public Sender produce(String type){ if (&quot;mail&quot;.equals(type)) { return new MailSender(); } else if (&quot;sms&quot;.equals(type)) { return new SmsSender(); } else { System.out.println(&quot;请输入正确的类型!&quot;); return null; } } } 综上，对于实现了同一Sender接口的实现类来说，工厂类利用多态返回一个Sender对象引用，根据传入的参数决定对象具体是哪种实现。 多个工厂方法模式是对普通工厂方法模式的改进，在普通工厂方法模式中，如果传递的字符串出错，则不能正确创建对象，而多个工厂方法模式是提供多个工厂方法，分别创建对象 对上面的代码简单改动，改动SendFactory类即可 public Sender produceMail(){ public Sender produceMail(){ //返回一个Mail实现对象 return new MailSender(); } public Sender produceSms(){ 返回一个Sms实现对象 return new SmsSender(); } } 综上，多个工厂方法模式即生成的具体对象实现，有方法指定，而不是传入参数。 静态工厂方法模式将上面的多个工厂方法模式里的方法置为静态的，不需要创建实例，直接调用即可。 public class SendFactory { public static Sender produceMail(){ return new MailSender(); } public static Sender produceSms(){ return new SmsSender(); } } 综上：静态工厂方法即将工厂类的工厂方法设置为静态的，在调用时可以直接通过类名.方法名直接调用。 抽象工厂模式（Abstract Factory）工厂方法模式有一个问题，就是类的创建依赖于工厂类。也就是说，如果想要拓展程序，就必须对工厂类进行修改，这违背了闭包原则。抽象工厂模式，创建多个工厂类，这样一旦需要增加新功能，直接添加新的工厂类就可以了，不需要修改之前的代码。 public interface Sender { //功能接口 public void Send(); } public class MailSender implements Sender { @Override public void Send() { //实现类1 System.out.println(&quot;this is mailsender!&quot;); } } public class SmsSender implements Sender { @Override public void Send() { //实现类2 System.out.println(&quot;this is sms sender!&quot;); } } public class SendMailFactory implements Provider { @Override public Sender produce(){ //专门生产Mail实现的工厂类 return new MailSender(); } } public class SendSmsFactory implements Provider{ @Override public Sender produce() { //专门生产Sms实现的工厂类 return new SmsSender(); } } public interface Provider { //通用接口 public Sender produce(); } 综上:如果你现在想增加一个功能：发及时信息，则只需做一个实现类，实现Sender接口，同时做一个工厂类，实现Provider接口，就OK了，无需去改动现成的代码。这样做，拓展性较好！ 单例模式（Singleton）单例对象是一种常用的设计模式。在java应用中，单例对象能保证在一个JVM中，该对象只有一个实例存在。这样的模式有几个好处: 1.某些类创建频繁，对于一些大型的对象，这是一笔很大的系统开销 2.省去了new操作符，降低了系统内存的使用频率，减少GC压力 3.有些类如交易所的核心交易引擎，控制着交易流程，如果出现多个对象系统就出现混乱。 public class Singleton { /* 持有私有静态实例，防止被引用，此处赋值为null，目的是实现延迟加载 */ private static Singleton instance = null; /* 私有构造方法，防止被实例化 */ private Singleton() { } /* 静态工程方法，创建实例 */ public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } /* 如果该对象被用于序列化，可以保证对象在序列化前后保持一致 */ public Object readResolve() { return instance; } } 这个类可以满足基本要求，但是，像这样毫无线程安全保护的类，如果我们把它放入多线程的环境下，肯定就会出现问题了，如何解决？我们首先会想到对getInstance方法加synchronized关键字，如下： public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } 但是，synchronized关键字锁住的是这个对象，这样的用法，在性能上会有所下降，因为每次调用getInstance()，都要对对象上锁，事实上，只有在第一次创建对象的时候需要加锁，之后就不需要了，所以，这个地方需要改进。我们改成下面这个： public static Singleton getInstance() { if (instance == null) { synchronized (instance) { if (instance == null) { instance = new Singleton(); } } } return instance; } 似乎解决了之前提到的问题，将synchronized关键字加在了内部，也就是说当调用的时候是不需要加锁的，只有在instance为null，并创建对象的时候才需要加锁，性能有一定的提升。但是，这样的情况，还是有可能有问题的。 看下面的情况：在Java指令中创建对象和赋值操作是分开进行的，也就是说instance = new Singleton();语句是分两步执行的。但是JVM并不保证这两个操作的先后顺序，也就是说有可能JVM会为新的Singleton实例分配空间，然后直接赋值给instance成员，然后再去初始化这个Singleton实例。这样就可能出错了，我们以A、B两个线程为例： a&gt;A、B线程同时进入了第一个if判断 b&gt;A首先进入synchronized块，由于instance为null，所以它执行instance = new Singleton(); c&gt;由于JVM内部的优化机制，JVM先画出了一些分配给Singleton实例的空白内存，并赋值给instance成员（注意此时JVM没有开始初始化这个实例），然后A离开了synchronized块。 d&gt;B进入synchronized块，由于instance此时不是null，因此它马上离开了synchronized块并将结果返回给调用该方法的程序。 e&gt;此时B线程打算使用Singleton实例，却发现它没有被初始化，于是错误发生了。 所以程序还是有可能发生错误，其实程序在运行过程是很复杂的，从这点我们就可以看出，尤其是在写多线程环境下的程序更有难度，有挑战性。我们对该程序做进一步优化： private static class SingletonFactory{ private static Singleton instance = new Singleton(); } public static Singleton getInstance(){ return SingletonFactory.instance; } 实际情况是，单例模式使用内部类来维护单例的实现，JVM内部的机制能够保证当一个类被加载的时候，这个类的加载过程是线程互斥的。这样当我们第一次调用getInstance的时候，JVM能够帮我们保证instance只被创建一次，并且会保证把赋值给instance的内存初始化完毕，这样我们就不用担心上面的问题。同时该方法也只会在第一次调用的时候使用互斥机制，这样就解决了低性能问题。这样我们暂时总结一个完美的单例模式： public class Singleton { /* 私有构造方法，防止被实例化 */ private Singleton() { } /* 此处使用一个内部类来维护单例 */ private static class SingletonFactory { private static Singleton instance = new Singleton(); } /* 获取实例 */ public static Singleton getInstance() { return SingletonFactory.instance; } /* 如果该对象被用于序列化，可以保证对象在序列化前后保持一致 */ public Object readResolve() { return getInstance(); } } 其实说它完美，也不一定，如果在构造函数中抛出异常，实例将永远得不到创建，也会出错。所以说，十分完美的东西是没有的，我们只能根据实际情况，选择最适合自己应用场景的实现方法。也有人这样实现：因为我们只需要在创建类的时候进行同步，所以只要将创建和getInstance()分开，单独为创建加synchronized关键字，也是可以的： public class SingletonTest { private static SingletonTest instance = null; private SingletonTest() { } private static synchronized void syncInit() { if (instance == null) { instance = new SingletonTest(); } } public static SingletonTest getInstance() { if (instance == null) { syncInit(); } return instance; } } 补充：采用”影子实例”的办法为单例对象的属性同步更新 public class SingletonTest { private static SingletonTest instance = null; private Vector properties = null; public Vector getProperties() { return properties; } private SingletonTest() { } private static synchronized void syncInit() { if (instance == null) { instance = new SingletonTest(); } } public static SingletonTest getInstance() { if (instance == null) { syncInit(); } return instance; } public void updateProperties() { SingletonTest shadow = new SingletonTest(); properties = shadow.getProperties(); } } 综上: 1、单例模式理解起来简单，但是具体实现起来还是有一定的难度。 2、synchronized关键字锁定的是对象，在用的时候，一定要在恰当的地方使用（注意需要使用锁的对象和过程，可能有的时候并不是整个对象及整个过程都需要锁）。 到这儿，单例模式基本已经讲完了，结尾处，笔者突然想到另一个问题，就是采用类的静态方法，实现单例模式的效果，也是可行的，此处二者有什么不同？ 首先，静态类不能实现接口。（从类的角度说是可以的，但是那样就破坏了静态了。因为接口中不允许有static修饰的方法，所以即使实现了也是非静态的） 其次，单例可以被延迟初始化，静态类一般在第一次加载是初始化。之所以延迟加载，是因为有些类比较庞大，所以延迟加载有助于提升性能。 再次，单例类可以被继承，他的方法可以被覆写。但是静态类内部方法都是static，无法被覆写。 最后一点，单例类比较灵活，毕竟从实现上只是一个普通的Java类，只要满足单例的基本需求，你可以在里面随心所欲的实现一些其它功能，但是静态类不行。从上面这些概括中，基本可以看出二者的区别，但是，从另一方面讲，我们上面最后实现的那个单例模式，内部就是用一个静态类来实现的，所以，二者有很大的关联，只是我们考虑问题的层面不同罢了。两种思想的结合，才能造就出完美的解决方案，就像HashMap采用数组+链表来实现一样，其实生活中很多事情都是这样，单用不同的方法来处理问题，总是有优点也有缺点，最完美的方法是，结合各个方法的优点，才能最好的解决问题 建造者模式（Builder）工厂类模式提供的是创建单个类的模式，而建造者模式是将各种产品集中起来进行管理，用来创建复合对象，所谓复合对象就是某个类具有不同的属性，其实建造者模式就是前面抽象工厂模式和最后的Test结合起来的。 还和前面一样，一个Sender接口，两个实现类MailSender和SmsSender。最后，建造者类如下 public class Builder { private List&lt;Sender&gt; list = new ArrayList&lt;Sender&gt;(); public void produceMailSender(int count){ for(int i=0; i&lt;count; i++){ list.add(new MailSender()); } } public void produceSmsSender(int count){ for(int i=0; i&lt;count; i++){ list.add(new SmsSender()); } } } 从这点看出，建造者模式将很多功能集成到一个类里，这个类可以创造出比较复杂的东西。所以与工厂模式的区别就是：工厂模式关注的是创建单个产品，而建造者模式则关注创建符合对象，多个部分。因此，是选择工厂模式还是建造者模式，依实际情况而定。 原型模式原型模式虽然是创建型的模式，但是与工厂模式没有关系，该模式的思想就是将一个对象作为模型，对其复制、克隆，产生一个和原对象类似的新对象。 public class Prototype implements Cloneable { public Object clone() throws CloneNotSupportedException { Prototype proto = (Prototype) super.clone(); return proto; } }很简单，一个原型类，只需要实现Cloneable接口，覆写clone方法，此处clone方法可以改成任意的名称，因为Cloneable接口是个空接口，你可以任意定义实现类的方法名，如cloneA或者cloneB，因为此处的重点是super.clone()这句话，super.clone()调用的是Object的clone()方法，而在Object类中，clone()是native的。 在这儿，我将结合对象的浅复制和深复制来说一下，首先需要了解对象深、浅复制的概念： 浅复制：将一个对象复制后，基本数据类型的变量都会重新创建，而引用类型，指向的还是原对象所指向的。 深复制：将一个对象复制后，不论是基本数据类型还有引用类型，都是重新创建的。简单来说，就是深复制进行了完全彻底的复制，而浅复制不彻底。 public class Prototype implements Cloneable, Serializable { private static final long serialVersionUID = 1L; private String string; private SerializableObject obj; /* 浅复制 */ public Object clone() throws CloneNotSupportedException { Prototype proto = (Prototype) super.clone(); return proto; } /* 深复制 */ public Object deepClone() throws IOException, ClassNotFoundException { /* 写入当前对象的二进制流 */ ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(this); /* 读出二进制流产生的新对象 */ ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); return ois.readObject(); } public String getString() { return string; } public void setString(String string) { this.string = string; } public SerializableObject getObj() { return obj; } public void setObj(SerializableObject obj) { this.obj = obj; } } class SerializableObject implements Serializable { private static final long serialVersionUID = 1L; } 要实现深复制，需要采用流的形式读入当前对象的二进制输入，再写出二进制数据对应的对象。 7种结构型模式适配器模式、装饰模式、代理模式、外观模式、桥接模式、组合模式、享元模式。其中对象的适配器模式是各种模式的起源，我们看下面的图： 适配器模式将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。主要分为三类：类的适配器模式、对象的适配器模式、接口的适配器模式。 类的适配器模式核心思想就是：有一个Source类，拥有一个方法，待适配，目标接口时Targetable，通过Adapter类，将Source的功能扩展到Targetable里，看代码： public class Source { public void method1() { System.out.println(&quot;this is original method!&quot;); } } public interface Targetable { /* 与原类中的方法相同 */ public void method1(); /* 新类的方法 */ public void method2(); } public class Adapter extends Source implements Targetable { @Override public void method2() { System.out.println(&quot;this is the targetable method!&quot;); } } Adapter类继承Source类，实现Targetable接口，这样Targetable接口的实现类就具有了Source类的功能 对象的适配器模式基本思路和类的适配器模式相同，只是将Adapter类作修改，这次不继承Source类，而是持有Source类的实例，以达到解决兼容性的问题。看图只需要修改Adapter类的源码即可： public class Wrapper implements Targetable { private Source source; public Wrapper(Source source){ super(); this.source = source; } @Override public void method2() { System.out.println(&quot;this is the targetable method!&quot;); } @Override public void method1() { source.method1(); } } 接口的适配器模式接口的适配器是这样的：有时我们写的一个接口中有多个抽象方法，当我们写该接口的实现类时，必须实现该接口的所有方法，这明显有时比较浪费，因为并不是所有的方法都是我们需要的，有时只需要某一些，此处为了解决这个问题，我们引入了接口的适配器模式，借助于一个抽象类，该抽象类实现了该接口，实现了所有的方法，而我们不和原始的接口打交道，只和该抽象类取得联系，所以我们写一个类，继承该抽象类，重写我们需要的方法就行。这个很好理解，在实际开发中，我们也常会遇到这种接口中定义了太多的方法，以致于有时我们在一些实现类中并不是都需要。 public interface Sourceable { public void method1(); public void method2(); } public abstract class Wrapper2 implements Sourceable{ public void method1(){} public void method2(){} } public class SourceSub1 extends Wrapper2 { public void method1(){ System.out.println(&quot;the sourceable interface&apos;s first Sub1!&quot;); } } public class SourceSub2 extends Wrapper2 { public void method2(){ System.out.println(&quot;the sourceable interface&apos;s second Sub2!&quot;); } } 讲了这么多，总结一下三种适配器模式的应用场景： 类的适配器模式：当希望将一个类转换成满足另一个新接口的类时，可以使用类的适配器模式，创建一个新类，继承原有的类，实现新的接口即可。 对象的适配器模式：当希望将一个对象转换成满足另一个新接口的对象时，可以创建一个Wrapper类，持有原类的一个实例，在Wrapper类的方法中，调用实例的方法就行。 接口的适配器模式：当不希望实现一个接口中所有的方法时，可以创建一个抽象类Wrapper，实现所有方法，我们写别的类的时候，继承抽象类即可。 装饰模式（Decorator)顾名思义，装饰模式就是给一个对象增加一些新的功能，而且是动态的，要求装饰对象和被装饰对象实现同一个接口，装饰对象持有被装饰对象的实例，关系图如下： Source类是被装饰类，Decorator类是一个装饰类，可以为Source类动态的添加一些功能 public interface Sourceable { public void method(); } public class Source implements Sourceable { @Override public void method() { System.out.println(&quot;the original method!&quot;); } } public class Decorator implements Sourceable { private Sourceable source; public Decorator(Sourceable source){ super(); this.source = source; } @Override public void method() { System.out.println(&quot;before decorator!&quot;); source.method(); System.out.println(&quot;after decorator!&quot;); } } 装饰器模式的应用场景： 1、需要扩展一个类的功能。 2、动态的为一个对象增加功能，而且还能动态撤销。（继承不能做到这一点，继承的功能是静态的，不能动态增删。） 缺点：产生过多相似的对象，不易排错 代理模式（Proxy）其实每个模式名称就表明了该模式的作用，代理模式就是多一个代理类出来，替原对象进行一些操作，比如我们在租房子的时候回去找中介，为什么呢？因为你对该地区房屋的信息掌握的不够全面，希望找一个更熟悉的人去帮你做，此处的代理就是这个意思。再如我们有的时候打官司，我们需要请律师，因为律师在法律方面有专长，可以替我们进行操作，表达我们的想法。先来看看关系图： public interface Sourceable { public void method(); } public class Source implements Sourceable { @Override public void method() { System.out.println(&quot;the original method!&quot;); } } public class Proxy implements Sourceable { private Source source; public Proxy(){ super(); this.source = new Source(); } @Override public void method() { before(); source.method(); atfer(); } private void atfer() { System.out.println(&quot;after proxy!&quot;); } private void before() { System.out.println(&quot;before proxy!&quot;); } } 代理模式的应用场景： 如果已有的方法在使用的时候需要对原有的方法进行改进，此时有两种办法： 1、修改原有的方法来适应。这样违反了“对扩展开放，对修改关闭”的原则。 2、就是采用一个代理类调用原有的方法，且对产生的结果进行控制。这种方法就是代理模式。 使用代理模式，可以将功能划分的更加清晰，有助于后期维护！ 外观模式（Facade）外观模式是为了解决类与类之家的依赖关系的，像spring一样，可以将类和类之间的关系配置到配置文件中，而外观模式就是将他们的关系放在一个Facade类中，降低了类类之间的耦合度，该模式中没有涉及到接口，看下类图：（我们以一个计算机的启动过程为例） public class CPU { public void startup(){ System.out.println(&quot;cpu startup!&quot;); } public void shutdown(){ System.out.println(&quot;cpu shutdown!&quot;); } } public class Memory { public void startup(){ System.out.println(&quot;memory startup!&quot;); } public void shutdown(){ System.out.println(&quot;memory shutdown!&quot;); } } public class Disk { public void startup(){ System.out.println(&quot;disk startup!&quot;); } public void shutdown(){ System.out.println(&quot;disk shutdown!&quot;); } } public class Computer { private CPU cpu; private Memory memory; private Disk disk; public Computer(){ cpu = new CPU(); memory = new Memory(); disk = new Disk(); } public void startup(){ System.out.println(&quot;start the computer!&quot;); cpu.startup(); memory.startup(); disk.startup(); System.out.println(&quot;start computer finished!&quot;); } public void shutdown(){ System.out.println(&quot;begin to close the computer!&quot;); cpu.shutdown(); memory.shutdown(); disk.shutdown(); System.out.println(&quot;computer closed!&quot;); } 如果我们没有Computer类，那么，CPU、Memory、Disk他们之间将会相互持有实例，产生关系，这样会造成严重的依赖，修改一个类，可能会带来其他类的修改，这不是我们想要看到的，有了Computer类，他们之间的关系被放在了Computer类里，这样就起到了解耦的作用，这，就是外观模式！ 桥接模式（Bridge）桥接模式就是把事物和其具体实现分开，使他们可以各自独立的变化。桥接的用意是：将抽象化与实现化解耦，使得二者可以独立变化，像我们常用的JDBC桥DriverManager一样，JDBC进行连接数据库的时候，在各个数据库之间进行切换，基本不需要动太多的代码，甚至丝毫不用动，原因就是JDBC提供统一接口，每个数据库提供各自的实现，用一个叫做数据库驱动的程序来桥接就行了。我们来看看关系图： 先定义接口： public interface Sourceable { public void method(); } 分别定义两个实现类 public class SourceSub1 implements Sourceable { @Override public void method() { System.out.println(&quot;this is the first sub!&quot;); } } public class SourceSub2 implements Sourceable { @Override public void method() { System.out.println(&quot;this is the second sub!&quot;); } } 定义一个桥，持有Sourceable的一个实例： public abstract class Bridge { private Sourceable source; public void method(){ source.method(); } public Sourceable getSource() { return source; } public void setSource(Sourceable source) { this.source = source; } } public class MyBridge extends Bridge { public void method(){ getSource().method(); } } 这样，就通过对Bridge类的调用，实现了对接口Sourceable的实现类SourceSub1和SourceSub2的调用。接下来我再画个图，大家就应该明白了，因为这个图是我们JDBC连接的原理，有数据库学习基础的，一结合就都懂了。 组合模式（Composite）组合模式有时又叫部分-整体模式在处理类似树形结构的问题时比较方便，看看关系图： public class TreeNode { private String name; private TreeNode parent; private Vector children = new Vector(); public TreeNode(String name){ this.name = name; } public String getName() { return name; } public void setName(String name) { this.name = name; } public TreeNode getParent() { return parent; } public void setParent(TreeNode parent) { this.parent = parent; } //添加孩子节点 public void add(TreeNode node){ children.add(node); } //删除孩子节点 public void remove(TreeNode node){ children.remove(node); } //取得孩子节点 public Enumeration&lt;TreeNode&gt; getChildren(){ return children.elements(); } } public class Tree { TreeNode root = null; public Tree(String name) { root = new TreeNode(name); } public static void main(String[] args) { Tree tree = new Tree(&quot;A&quot;); TreeNode nodeB = new TreeNode(&quot;B&quot;); TreeNode nodeC = new TreeNode(&quot;C&quot;); nodeB.add(nodeC); tree.root.add(nodeB); System.out.println(&quot;build the tree finished!&quot;); } } 使用场景：将多个对象组合在一起进行操作，常用于表示树形结构中，例如二叉树，数等 享元模式（Flyweight）享元模式的主要目的是实现对象的共享，即共享池，当系统中对象多的时候可以减少内存的开销，通常与工厂模式一起使用。FlyWeightFactory负责创建和管理享元单元，当一个客户端请求时，工厂需要检查当前对象池中是否有符合条件的对象，如果有，就返回已经存在的对象，如果没有，则创建一个新对象，FlyWeight是超类。一提到共享池，我们很容易联想到Java里面的JDBC连接池，想想每个连接的特点，我们不难总结出：适用于作共享的一些个对象，他们有一些共有的属性，就拿数据库连接池来说，url、driverClassName、username、password及dbname，这些属性对于每个连接来说都是一样的，所以就适合用享元模式来处理，建一个工厂类，将上述类似属性作为内部数据，其它的作为外部数据，在方法调用时，当做参数传进来，这样就节省了空间，减少了实例的数量。 public class ConnectionPool { private Vector&lt;Connection&gt; pool; /*公有属性*/ private String url = &quot;jdbc:mysql://localhost:3306/test&quot;; private String username = &quot;root&quot;; private String password = &quot;root&quot;; private String driverClassName = &quot;com.mysql.jdbc.Driver&quot;; private int poolSize = 100; private static ConnectionPool instance = null; Connection conn = null; /*构造方法，做一些初始化工作*/ private ConnectionPool() { pool = new Vector&lt;Connection&gt;(poolSize); for (int i = 0; i &lt; poolSize; i++) { try { Class.forName(driverClassName); conn = DriverManager.getConnection(url, username, password); pool.add(conn); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); } } } /* 返回连接到连接池 */ public synchronized void release() { pool.add(conn); } /* 返回连接池中的一个数据库连接 */ public synchronized Connection getConnection() { if (pool.size() &gt; 0) { Connection conn = pool.get(0); pool.remove(conn); return conn; } else { return null; } } } 通过连接池的管理，实现了数据库连接的共享，不需要每一次都重新创建连接，节省了数据库重新创建的开销，提升了系统的性能！ 11种行为型模式策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 先来张图，看看这11中模式的关系： 第一类：通过父类与子类的关系进行实现。第二类：两个类之间。第三类：类的状态。第四类：通过中间类 策略模式（strategy）策略模式定义了一系列算法，并将每个算法封装起来，使他们可以相互替换，且算法的变化不会影响到使用算法的客户。需要设计一个接口，为一系列实现类提供统一的方法，多个实现类实现该接口，设计一个抽象类（可有可无，属于辅助类），提供辅助函数，关系图如下： 图中ICalculator提供同意的方法，AbstractCalculator是辅助类，提供辅助方法，接下来，依次实现下每个类： public interface ICalculator { public int calculate(String exp); } public abstract class AbstractCalculator { public int[] split(String exp,String opt){ String array[] = exp.split(opt); int arrayInt[] = new int[2]; arrayInt[0] = Integer.parseInt(array[0]); arrayInt[1] = Integer.parseInt(array[1]); return arrayInt; } } 三个实现类 public class Plus extends AbstractCalculator implements ICalculator { @Override public int calculate(String exp) { int arrayInt[] = split(exp,&quot;\\+&quot;); return arrayInt[0]+arrayInt[1]; } } public class Minus extends AbstractCalculator implements ICalculator { @Override public int calculate(String exp) { int arrayInt[] = split(exp,&quot;-&quot;); return arrayInt[0]-arrayInt[1]; } } public class Multiply extends AbstractCalculator implements ICalculator { @Override public int calculate(String exp) { int arrayInt[] = split(exp,&quot;\\*&quot;); return arrayInt[0]*arrayInt[1]; } } 策略模式的决定权在用户，系统本身提供不同算法的实现，新增或者删除算法，对各种算法做封装。因此，策略模式多用在算法决策系统中，外部用户只需要决定用哪个算法即可。 模板方法模式（Template Method）解释一下模板方法模式，就是指：一个抽象类中，有一个主方法，再定义1…n个方法，可以是抽象的，也可以是实际的方法，定义一个类，继承该抽象类，重写抽象方法，通过调用抽象类，实现对子类的调用，先看个关系图： 就是在AbstractCalculator类中定义一个主方法calculate，calculate()调用spilt()等，Plus和Minus分别继承AbstractCalculator类，通过对AbstractCalculator的调用实现对子类的调用，看下面的例子： public abstract class AbstractCalculator { /*主方法，实现对本类其它方法的调用*/ public final int calculate(String exp,String opt){ int array[] = split(exp,opt); return calculate(array[0],array[1]); } /*被子类重写的方法*/ abstract public int calculate(int num1,int num2); public int[] split(String exp,String opt){ String array[] = exp.split(opt); int arrayInt[] = new int[2]; arrayInt[0] = Integer.parseInt(array[0]); arrayInt[1] = Integer.parseInt(array[1]); return arrayInt; } } public class Plus extends AbstractCalculator { @Override public int calculate(int num1,int num2) { return num1 + num2; } } public class StrategyTest { public static void main(String[] args) { String exp = &quot;8+8&quot;; AbstractCalculator cal = new Plus(); int result = cal.calculate(exp, &quot;\\+&quot;); System.out.println(result); } } 我跟踪下这个小程序的执行过程：首先将exp和”\+”做参数，调用AbstractCalculator类里的calculate(String,String)方法，在calculate(String,String)里调用同类的split()，之后再调用calculate(int ,int)方法，从这个方法进入到子类中，执行完return num1 + num2后，将值返回到AbstractCalculator类，赋给result，打印出来。正好验证了我们开头的思路。 观察者模式（Observer）包括这个模式在内的接下来的四个模式，都是类和类之间的关系，不涉及到继承.观察者模式很好理解，类似于邮件订阅和RSS订阅，当我们浏览一些博客或wiki时，经常会看到RSS图标，就这的意思是，当你订阅了该文章，如果后续有更新，会及时通知你。其实，简单来讲就一句话：当一个对象变化时，其它依赖该对象的对象都会收到通知，并且随着变化！对象之间是一种一对多的关系。先来看看关系图： MySubject类就是我们的主对象，Observer1和Observer2是依赖于MySubject的对象，当MySubject变化时，Observer1和Observer2必然变化。AbstractSubject类中定义着需要监控的对象列表，可以对其进行修改：增加或删除被监控对象，且当MySubject变化时，负责通知在列表内存在的对象。我们看实现代码： 一个Observer接口： public interface Observer { public void update(); } 两个实现类 public class Observer1 implements Observer { @Override public void update() { System.out.println(&quot;observer1 has received!&quot;); } } public class Observer2 implements Observer { @Override public void update() { System.out.println(&quot;observer2 has received!&quot;); } } Subject接口及实现类： public interface Subject { /*增加观察者*/ public void add(Observer observer); /*删除观察者*/ public void del(Observer observer); /*通知所有的观察者*/ public void notifyObservers(); /*自身的操作*/ public void operation(); } public abstract class AbstractSubject implements Subject { private Vector&lt;Observer&gt; vector = new Vector&lt;Observer&gt;(); @Override public void add(Observer observer) { vector.add(observer); } @Override public void del(Observer observer) { vector.remove(observer); } @Override public void notifyObservers() { Enumeration&lt;Observer&gt; enumo = vector.elements(); while(enumo.hasMoreElements()){ enumo.nextElement().update(); } } } public class MySubject extends AbstractSubject { @Override public void operation() { System.out.println(&quot;update self!&quot;); notifyObservers(); } } public class ObserverTest { public static void main(String[] args) { Subject sub = new MySubject(); sub.add(new Observer1()); sub.add(new Observer2()); sub.operation(); } } 迭代子模式（Iterator）顾名思义，迭代器模式就是顺序访问聚集中的对象，一般来说，集合中非常常见，如果对集合类比较熟悉的话，理解本模式会十分轻松。这句话包含两层意思：一是需要遍历的对象，即聚集对象，二是迭代器对象，用于对聚集对象进行遍历访问。我们看下关系图： 这个思路和我们常用的一模一样，MyCollection中定义了集合的一些操作，MyIterator中定义了一系列迭代操作，且持有Collection实例，我们来看看实现代码： public interface Collection { public Iterator iterator(); /*取得集合元素*/ public Object get(int i); /*取得集合大小*/ public int size(); } public interface Iterator { //前移 public Object previous(); //后移 public Object next(); public boolean hasNext(); //取得第一个元素 public Object first(); } 两个实现： public class MyCollection implements Collection { public String string[] = {&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;}; @Override public Iterator iterator() { return new MyIterator(this); } @Override public Object get(int i) { return string[i]; } @Override public int size() { return string.length; } } public class MyIterator implements Iterator { private Collection collection; private int pos = -1; public MyIterator(Collection collection){ this.collection = collection; } @Override public Object previous() { if(pos &gt; 0){ pos--; } return collection.get(pos); } @Override public Object next() { if(pos&lt;collection.size()-1){ pos++; } return collection.get(pos); } @Override public boolean hasNext() { if(pos&lt;collection.size()-1){ return true; }else{ return false; } } @Override public Object first() { pos = 0; return collection.get(pos); } } 此处我们貌似模拟了一个集合类的过程 责任链模式（Chain of Responsibility）有多个对象，每个对象持有对下一个对象的引用，这样就会形成一条链，请求在这条链上传递，直到某一对象决定处理该请求。但是发出者并不清楚到底最终那个对象会处理该请求，所以，责任链模式可以实现，在隐瞒客户端的情况下，对系统进行动态的调整。先看看关系图： Abstracthandler类提供了get和set方法，方便MyHandle类设置和修改引用对象，MyHandle类是核心，实例化后生成一系列相互持有的对象，构成一条链。 public interface Handler { public void operator(); } public abstract class AbstractHandler { private Handler handler; public Handler getHandler() { return handler; } public void setHandler(Handler handler) { this.handler = handler; } } public class MyHandler extends AbstractHandler implements Handler { private String name; public MyHandler(String name) { this.name = name; } @Override public void operator() { System.out.println(name+&quot;deal!&quot;); if(getHandler()!=null){ getHandler().operator(); } } } public class Test { public static void main(String[] args) { MyHandler h1 = new MyHandler(&quot;h1&quot;); MyHandler h2 = new MyHandler(&quot;h2&quot;); MyHandler h3 = new MyHandler(&quot;h3&quot;); h1.setHandler(h2); h2.setHandler(h3); h1.operator(); } } 链接上的请求可以是一条链，可以是一个树，还可以是一个环，模式本身不约束这个，需要我们自己去实现，同时，在一个时刻，命令只允许由一个对象传给另一个对象，而不允许传给多个对象。 命令模式（Command）命令模式很好理解，举个例子，司令员下令让士兵去干件事情，从整个事情的角度来考虑，司令员的作用是，发出口令，口令经过传递，传到了士兵耳朵里，士兵去执行。这个过程好在，三者相互解耦，任何一方都不用去依赖其他人，只需要做好自己的事儿就行，司令员要的是结果，不会去关注到底士兵是怎么实现的。我们看看关系图：Invoker是调用者（司令员），Receiver是被调用者（士兵），MyCommand是命令，实现了Command接口，持有接收对象，看实现代码： public interface Command { public void exe(); } public class MyCommand implements Command { private Receiver receiver; public MyCommand(Receiver receiver) { this.receiver = receiver; } @Override public void exe() { receiver.action(); } } public class Receiver { public void action(){ System.out.println(&quot;command received!&quot;); } } public class Invoker { private Command command; public Invoker(Command command) { this.command = command; } public void action(){ command.exe(); } } 命令模式的目的就是达到命令的发出者和执行者之间解耦，实现请求和执行分开，熟悉Struts的同学应该知道，Struts其实就是一种将请求和呈现分离的技术，其中必然涉及命令模式的思想！ 备忘录模式（Memento)主要目的是保存一个对象的某个状态，以便在适当的时候恢复对象，个人觉得叫备份模式更形象些，通俗的讲下：假设有原始类A，A中有各种属性，A可以决定需要备份的属性，备忘录类B是用来存储A的一些内部状态，类C呢，就是一个用来存储备忘录的，且只能存储，不能修改等操作。做个图来分析一下： Original类是原始类，里面有需要保存的属性value及创建一个备忘录类，用来保存value值。Memento类是备忘录类，Storage类是存储备忘录的类，持有Memento类的实例，该模式很好理解。 public class Original { private String value; public String getValue() { return value; } public void setValue(String value) { this.value = value; } public Original(String value) { this.value = value; } public Memento createMemento(){ return new Memento(value); } public void restoreMemento(Memento memento){ this.value = memento.getValue(); } } public class Memento { private String value; public Memento(String value) { this.value = value; } public String getValue() { return value; } public void setValue(String value) { this.value = value; } } public class Storage { private Memento memento; public Storage(Memento memento) { this.memento = memento; } public Memento getMemento() { return memento; } public void setMemento(Memento memento) { this.memento = memento; } } public class Test { public static void main(String[] args) { // 创建原始类 Original origi = new Original(&quot;egg&quot;); // 创建备忘录 Storage storage = new Storage(origi.createMemento()); // 修改原始类的状态 System.out.println(&quot;初始化状态为：&quot; + origi.getValue()); origi.setValue(&quot;niu&quot;); System.out.println(&quot;修改后的状态为：&quot; + origi.getValue()); // 回复原始类的状态 origi.restoreMemento(storage.getMemento()); System.out.println(&quot;恢复后的状态为：&quot; + origi.getValue()); } } 新建原始类时，value被初始化为egg，后经过修改，将value的值置为niu，最后倒数第二行进行恢复状态，结果成功恢复了。其实我觉得这个模式叫“备份-恢复”模式最形象。 状态模式（State）核心思想就是：当对象的状态改变时，同时改变其行为，很好理解！就拿QQ来说，有几种状态，在线、隐身、忙碌等，每个状态对应不同的操作，而且你的好友也能看到你的状态，所以，状态模式就两点：1、可以通过改变状态来获得不同的行为。2、你的好友能同时看到你的变化。看图： State类是个状态类，Context类可以实现切换，我们来看看代码： public class State { private String value; public String getValue() { return value; } public void setValue(String value) { this.value = value; } public void method1(){ System.out.println(&quot;execute the first opt!&quot;); } public void method2(){ System.out.println(&quot;execute the second opt!&quot;); } } public class Context { private State state; public Context(State state) { this.state = state; } public State getState() { return state; } public void setState(State state) { this.state = state; } public void method() { if (state.getValue().equals(&quot;state1&quot;)) { state.method1(); } else if (state.getValue().equals(&quot;state2&quot;)) { state.method2(); } } } 根据这个特性，状态模式在日常开发中用的挺多的，尤其是做网站的时候，我们有时希望根据对象的某一属性，区别开他们的一些功能，比如说简单的权限控制等。 访问者模式（Visitor）访问者模式把数据结构和作用于结构上的操作解耦合，使得操作集合可相对自由地演化。访问者模式适用于数据结构相对稳定算法又易变化的系统。因为访问者模式使得算法操作增加变得容易。若系统数据结构对象易于变化，经常有新的数据对象增加进来，则不适合使用访问者模式。访问者模式的优点是增加操作很容易，因为增加操作意味着增加新的访问者。访问者模式将有关行为集中到一个访问者对象中，其改变不影响系统数据结构。其缺点就是增加新的数据结构很困难。 简单来说，访问者模式就是一种分离对象数据结构与行为的方法，通过这种分离，可达到为一个被访问者动态添加新的操作而无需做其它的修改的效果。简单关系图： 一个Visitor类，存放要访问的对象， public interface Visitor { public void visit(Subject sub); } public class MyVisitor implements Visitor { @Override public void visit(Subject sub) { System.out.println(&quot;visit the subject：&quot;+sub.getSubject()); } } Subject类，accept方法，接受将要访问它的对象，getSubject()获取将要被访问的属性， public interface Subject { public void accept(Visitor visitor); public String getSubject(); } public class MySubject implements Subject { @Override public void accept(Visitor visitor) { visitor.visit(this); } @Override public String getSubject() { return &quot;love&quot;; } } 该模式适用场景：如果我们想为一个现有的类增加新功能，不得不考虑几个事情：1、新功能会不会与现有功能出现兼容性问题？2、以后会不会再需要添加？3、如果类不允许修改代码怎么办？面对这些问题，最好的解决方法就是使用访问者模式，访问者模式适用于数据结构相对稳定的系统，把数据结构和算法解耦， 中介者模式（Mediator）中介者模式也是用来降低类类之间的耦合的，因为如果类类之间有依赖关系的话，不利于功能的拓展和维护，因为只要修改一个对象，其它关联的对象都得进行修改。如果使用中介者模式，只需关心和Mediator类的关系，具体类类之间的关系及调度交给Mediator就行，这有点像spring容器的作用。先看看图： User类统一接口，User1和User2分别是不同的对象，二者之间有关联，如果不采用中介者模式，则需要二者相互持有引用，这样二者的耦合度很高，为了解耦，引入了Mediator类，提供统一接口，MyMediator为其实现类，里面持有User1和User2的实例，用来实现对User1和User2的控制。这样User1和User2两个对象相互独立，他们只需要保持好和Mediator之间的关系就行，剩下的全由MyMediator类来维护！基本实现 public interface Mediator { public void createMediator(); public void workAll(); } public class MyMediator implements Mediator { private User user1; private User user2; public User getUser1() { return user1; } public User getUser2() { return user2; } @Override public void createMediator() { user1 = new User1(this); user2 = new User2(this); } @Override public void workAll() { user1.work(); user2.work(); } } public abstract class User { private Mediator mediator; public Mediator getMediator(){ return mediator; } public User(Mediator mediator) { this.mediator = mediator; } public abstract void work(); } public class User1 extends User { public User1(Mediator mediator){ super(mediator); } @Override public void work() { System.out.println(&quot;user1 exe!&quot;); } } public class User2 extends User { public User2(Mediator mediator){ super(mediator); } @Override public void work() { System.out.println(&quot;user2 exe!&quot;); } } 解释器模式（Interpreter）一般主要应用在OOP开发中的编译器的开发中，所以适用面比较窄。 Context类是一个上下文环境类，Plus和Minus分别是用来计算的实现，代码如下： public interface Expression { public int interpret(Context context); } public class Plus implements Expression { @Override public int interpret(Context context) { return context.getNum1()+context.getNum2(); } } public class Minus implements Expression { @Override public int interpret(Context context) { return context.getNum1()-context.getNum2(); } } public class Context { private int num1; private int num2; public Context(int num1, int num2) { this.num1 = num1; this.num2 = num2; } public int getNum1() { return num1; } public void setNum1(int num1) { this.num1 = num1; } public int getNum2() { return num2; } public void setNum2(int num2) { this.num2 = num2; } } public class Test { public static void main(String[] args) { // 计算9+2-8的值 int result = new Minus().interpret((new Context(new Plus().interpret(new Context(9, 2)), 8))); System.out.println(result); } } 解释器模式用来做各种各样的解释器，如正则表达式等的解释器等等！]]></content>
      <categories>
        <category>设计理论</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建高可用高并发系统]]></title>
    <url>%2F2019%2F08%2F18%2F%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[高可用高并发系统设计架构设计三大定律墨菲定律 任何事没有表面看起来那么简单所有的事都会比预计的时间长 - 可能出错的事情总会出错 - 担心某种事情发生，那么它就更有可能发生 康威定律 系统架构师公司组织架构的反映按照业务闭环进行系统拆分/组织架构划分，实现闭环、高内聚、低耦合，减少沟通成本如果沟通出现问题，应该考虑进行系统和组织架构的调整 适合时机进行系统拆分。不要一开始就吧系统、服务拆分拆的非常细，虽然闭环，但是每个人维护的系统多，维护成本高 - 微服务架构的理论基础 - 康威定律 二八定律 80%的结果取决于20%的原因 高可用所谓高可用，即要保证系统在几乎任何时候都能正常运行，功能正常，保证系统不出问题，“永不宕机”。 1.单机系统下的可用性问题，从Nginx-&gt;Tomcat-&gt;db/soa来看，单点问题会影响系统的高可用。比如要是这个链路上其中一个单点挂了，整个系统就不可以用了。（Nginx负载均衡等，Tomcat提供服务，db存储数据）。所以引申出来主备/集群模式，防止单点问题。2.高并发场景下，请求过多也会因为后端瓶颈点引起整个系统down掉，如周杰伦演唱会抢票，高铁抢票，所以一般情况下对并发场景我们会限流，采用mq等消息队列形式削峰，保证后端系统不会down掉。 设计建议1.减少单点去去单点首先要识别出整个系统所有主链路的单点，如机房（同城异地双机房）、应用服务器、DNS服务器、SFTP服务器、LBS（基于位置服务）缓存服务器、数据库、消息服务器、代理服务器和专线等。如系统通过专线调用对方服务，需要考虑同时拉联通和电信的专线，联通或电信的专线还是有一定效率出现问题但是同时出现问题的概率就会小很多。优先使用软负载（负载软件如Nginx），使用硬负载（外部网络和服务器间的硬件设备如F5）兜底。 2.减少依赖减少DNS依赖，减少远程服务依赖。DNS依赖可以尝试设置本地host，用工具给所有服务器推送最新的域名映射关系，通过本地缓存或者近端服务减少RPC（远程过程调用）调用。 3.限制循环避免无限死循环，导致CPU利用率百分百，可以设置for循环的最大循环次数，如最大1000次 4.增加限流对外服务增加限流，注意限流的值最好是压测过的，如果没有压测过，只能设置成平时的峰值流量，否则可能增加一点流量就不能提供服务了。 5.控制流量避免异常流量对应用服务器产生影响，可以对指定指定服务设置流量限制，如QPS(每秒查询率),TPS(每秒处理事务数),QPH(每小时总请求量),QPD(每天总请求量) 6.精准监控对CPU利用率，load，内存，带框，系统调用量，应用错误量，PV(页面浏览量),UV(独立访客量，以cookie为主)和业务进行监控，避免内存泄露和异常代码对系统产生影响，配置一定要精准，如平时设置内存利用率是50%，监控可以配置成60%进行报警，这样可以提前感知内存泄露问题，避免应用无响应。 7.无状态服务器不能保存用户状态数据，如在集群下不能用static保存用户数据，不能长时间把用户文件存放在服务器本地。服务器有状态会难以扩容，出现单点问题。 8.容量规划定期对容量进行评估，如大促前进行压测和容量预估，根据需要进行扩容。如双11进行扩容。 9.功能开关打开和关闭某些功能，如消息量过大，系统处理不了，把开关打开后直接丢弃信息不处理。上线新功能增加开关，如果出现问题就关闭新功能。 10.设置超时设置连接超时和读超时设置，不应该太大，如果是内部调用连接超时可以设置成1秒，读超时3秒，外部系统调用连接超时可以设置成3秒，读超时设置20秒。 11.重试策略当调用外部服务异常时可以设置重试策略，每次重试时间递增，但需要设置最大重试次数和重试开关，避免对下游系统产生影响。 12.隔离应用隔离，模块隔离，机房隔离，线程池隔离。按照优先级，不变和变几个维度来隔离应用和模块，如抽象和不变的代码放在一个模块，这个模块的代码几乎不会修改，可用性高，经常变的业务逻辑放在一个模块里，这样就算出现问题，也只影响某一业务。不同业务使用不同的线程池，避免低先级任务阻塞高优先级，或者高优先级任务过多影响低优先级任务永不执行。 13.异步调用同步调用变成异步调用，解决远程调用障碍或者调用超时对系统的影响。 14.热点缓存对热点数据进行缓存，降低RPC调用。如B系统提供名单服务，B系统可以提供一个client SDK提供近端缓存服务，定期去服务器读取数据，减少RPC调用。 15.缓存容灾当数据库不可用时可以使用缓存的数据。并设置分级缓存，如优先读取本地缓存，其次分布式缓存。 16.分级缓存优先读取本地缓存，其次读取分布式缓存。通过推模式更新本地缓存。 17.系统分级对系统进行分级，如ABC三个等级，高级别系统不依赖与低级别系统，并且高级别系统比低级别系统高可用虑高 18.服务降级如果系统出现响应缓慢等状况，可以关闭部分功能，从而释放系统资源，保证核心服务的正常运行。需要识别哪些服务可以降级，比如突然有大量消息流入，导致服务不可用，我们会直接把消息丢掉。或者设置流控，拒绝为低级别系统提供服务。 19.流量蓄洪当流量陡增时，可以将请求进行蓄洪，如把请求保存在数据库中，再按照指定的QPS进行泄洪，有效保护下游系统，也保证了服务的可用性。调用对方系统，对方系统缓慢或者无响应时，可采取自动蓄洪。 20.服务权重在集群环境中，可自动识别高性能服务，拒绝调用性能低的服务，如在集群环境中，对调用超时的服务器进行权重降低，优先调用权重高的服务器。 21.依赖简化减少系统间的依赖，如使用消息驱动。A和B系统通过消息服务器传递数据，A和B系统使用数据库进行读写分离，A系统负责往数据库写数据，B系统负责读数据，因为数据存放在数据库中，当A不可用时，短时间不影响B系统提供服务。 22.弹性扩容根据资源的使用率自动或者手动进行扩容。如带宽不够用，快速增加带宽。 23.灰度和回滚发布新功能只让部分服务器生效，且观察几天逐渐切流，如果出现问题只影响部分客户。出现问题快速回滚，或者直接下线灰度的机器。 24.减少远程调用优先调用本地JVM内服务，其次是同机房服务，然后是同城服务，最后是跨城服务。如A调用B，B调用互联网C的系统获取数据，B系统可以把数据缓存起来，并设置数据的保鲜度，减少B对C的依赖。配置中心把注册服务的地址推送到调用服务的系统本地。参数中心把参数配置信息推送到系统的本地内存，而不是让系统去远程服务器获取参数信息。 25.熔断机制增加熔断机制，当监控出现数据大幅涨跌时，及时中断，避免对业务产生更大影响。如我们做指标计算时，指标可以计算慢，但不能算错，如果发现某个用户的指标环比或同比增长一倍或跌零，会考虑保存所有信息，并终止该用户的指标计算。 26.运行时加载模块我们会把经常变的业务代码变成一个个业务模块，使用JAVA的ClassLoader在运行时动态加载和卸载模块，当模块有问题时，可以快速修复。 27.代码扫描#使用IDEA代码分析等工具进行代码扫描，识别出程序中的BUG,如空指针异常，循环依赖。 28.自动备份程序，系统配置和数据定期进行备份。可以使用Linux命令和shell脚本定时执行备份策略，自动进行本地或者异地备份。出现问题时能快速重新部署。 29.线上测压系统的对外服务需要进行压测，知道该服务承受的QPS和TPS,从而做出相对精准的限流。 高并发所谓高并发，即能够同时接受处理千万级乃至亿万级的并发访问。 高并发又分为cpu密集型和io密集型。前者要求网站的计算能力要高，后者要求网站的吞吐能力要高。 高并发设计有几个原则如下:1.无状态无状态应用，便于水平扩展 有状态配置可通过配置中心实现无状态 实践: Disconf、Yaconf、Zookpeer、Consul、Confd、Diamond、Xdiamond等 2.拆分系统维度：按照系统功能、业务拆分，如购物车，结算，订单等 功能维度：对系统功能在做细粒度拆分 读写维度：根据读写比例特征拆分；读多，可考虑多级缓存；写多，可考虑分库分表 AOP维度： 根据访问特征，按照AOP进行拆分，比如商品详情页可分为CDN、页面渲染系统，CDN就是一个AOP系统 模块维度：对整体代码结构划分Web、Service、DAO 3.服务化服务化演进: 进程内服务-单机远程服务-集群手动注册服务-自动注册和发现服务-服务的分组、隔离、路由-服务治理 考虑服务分组、隔离、限流、黑白名单、超时、重试机制、路由、故障补偿等 实践：利用Nginx、HaProxy、LVS等实现负载均衡，ZooKeeper、Consul等实现自动注册和发现服 4.消息队列目的: 服务解耦(一对多消费)、异步处理、流量削峰缓冲等 大流量缓冲： 牺牲强一致性，保证最终一致性 (案例：库存扣减，现在Redis中做扣减，记录扣减日志，通过后台进程将扣减日志应用到DB) 数据校对: 解决异步消息机制下消息丢失问题 5.数据异构数据异构: 通过消息队列机制接收数据变更，原子化存储 数据闭环: 屏蔽多从数据来源，将数据异构存储，形成闭环 6.缓存用户层: DNS缓存 浏览器DNS缓存 操作系统DNS缓存 本地DNS服务商缓存 DNS服务器缓存 客户端缓存 浏览器缓存(Expires、Cache-Control、Last-Modified、Etag) App客户缓存(js/css/image...) 代理层： CDN缓存(一般基于ATS、Varnish、Nginx、Squid等构建,边缘节点-二级节点-中心节点-源站) 接入层： Opcache： 缓存PHP的Opcodes Proxy_cache： 代理缓存,可以存储到/dev/shm或者SSD FastCGI Cache Nginx+Lua+Redis: 业务数据缓存 应用层： 页面静态化 业务数据缓存(Redis/Memcached/本地文件等) 消息队列 数据层： NoSQL： Redis、Memcache、SSDB等 MySQL： Innodb/MyISAM等Query Cache、Key Cache、Innodb Buffer Size等 系统层： CPU : L1/L2/L3 Cache/NUMA 内存 磁盘：磁盘本身缓存、dirtyratio/dirtybackground_ratio、阵列卡本身缓存]]></content>
      <categories>
        <category>设计理论</category>
      </categories>
      <tags>
        <tag>系统设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA中的相等比较]]></title>
    <url>%2F2019%2F08%2F16%2FJAVA%E4%B8%AD%E7%9A%84%E7%9B%B8%E7%AD%89%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[1、 == java中的数据类型，可分为两类: 1.基本数据类型，也称原始数据类型 byte、short、char、int、long、float、double、boolean，他们之间的比较 使用==时，比较的是他们的值 2.引用类型（类、接口、数组） 当他们使用==比较的时候，比较的是内存中存放的地址，所以，除非是同一个new出来的对象，他们比较结果为true，否则为false 当基本数据类型与其对应的对象比较时如，int和Integer进行比较时，Integer会自动拆箱为int，进行值的比较。 对象存放在堆中，栈中存放着对象的引用（地址）。由此可见，== 比较的是栈中的值进行比较。如果要比较两个对象的内容是否相等，那么就要重写equal方法了。 public static void main(String[] args) { int int1 = 12; int int2 = 12; Integer Integer1 = new Integer(12); Integer Integer2 = new Integer(12); Integer Integer3 = new Integer(127); Integer a1 = 127; Integer b1 = 127; Integer a = 128; Integer b = 128; String s1 = &quot;str&quot;; String s2 = &quot;str&quot;; String str1 = new String(&quot;str&quot;); String str2 = new String(&quot;str&quot;); System.out.println(&quot;int1==int2:&quot; + (int1 == int2)); System.out.println(&quot;int1==Integer1:&quot; + (int1 == Integer1)); System.out.println(&quot;Integer1==Integer2:&quot; + (Integer1 == Integer2)); System.out.println(&quot;Integer3==b1:&quot; + (Integer3 == b1)); System.out.println(&quot;a1==b1:&quot; + (a1 == b1)); System.out.println(&quot;a==b:&quot; + (a == b)); System.out.println(&quot;s1==s2:&quot; + (s1 == s2)); System.out.println(&quot;s1==str1:&quot; + (s1 == str1)); System.out.println(&quot;str1==str2:&quot; + (str1 == str2)); } 输出结果： int1==int2:true int1==Integer1:true //Integer会自动拆箱为int，所以为true Integer1==Integer2:false//不同对象，在内存存放地址不同，所以为false Integer3==b1:false//Integer3指向new的对象地址，b1指向缓存中127地址，地址不同，所以为false a1==b1:true a==b:false s1==s2:true s1==str1:false str1==str2:false ！！！敲黑板 Integer b1 = 127;java在编译的时候,被翻译成-&gt; Integer b1 = Integer.valueOf(127); 而该方法源码: public static Integer valueOf(int i) { assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } 所以，对应-128-127之间的数，会进行缓存，Integer b1 = 127时，会将127进行缓存，下次再写Integer i6 = 127时，就会直接从缓存中取，就不会new了。而b的值是128，因此不会有缓存。所以a1==b1:true a==b:false 2、 equals 1.默认情况下（即equals方法未被覆盖）equals方法都是调用Object类的equals方法，，而Object的equals方法主要用于判断对象的内存地址引用是不是同一个地址（是不是同一个对象）。下面是Object类中equals方法： public boolean equals(Object obj) { return (this == obj); } 所以此时，equals方法与==本质上是一样的 2.若类的equals方法被覆盖，则比较时根据代码实现的规则比较，一般都是比较对象内容是否相等。下面是String类equals方法的覆盖: public boolean equals(Object anObject) { if (this == anObject) { return true; } if (anObject instanceof String) { String anotherString = (String)anObject; int n = count; if (n == anotherString.count) { char v1[] = value; char v2[] = anotherString.value; int i = offset; int j = anotherString.offset; while (n– != 0) { if (v1[i++] != v2[j++]) return false; } return true; } } return false; } 即String中equals方法判断相等的步骤是： 1.若A==B 即是同一个String对象 返回true 2.若对比对象是String类型则继续，否则返回false 3.判断A、B长度是否一样，不一样的话返回false 4。逐个字符比较，若有不相等字符，返回false ！！！敲黑板 equals方法的覆盖需要注意5点 1 自反性：对任意引用值X，x.equals(x)的返回值一定为true. 2 对称性：对于任何引用值x,y,当且仅当y.equals(x)返回值为true时，x.equals(y)的返回值一定为true; 3 传递性：如果x.equals(y)=true, y.equals(z)=true,则x.equals(z)=true 4 一致性：如果参与比较的对象没任何改变，则对象比较的结果也不应该有任何改变 5 非空性：任何非空的引用值X，x.equals(null)的返回值一定为false 参照5个注意点，写出高质量的equals方法可以参考以下方式: 1.使用==符号检查“参数是否为这个对象的引用”。如果是，则返回true。这只不过是一种性能优化，如果比较操作有可能很昂贵，就值得这么做。 2.使用instanceof操作符检查“参数是否为正确的类型”。如果不是，则返回false。一般来说，所谓“正确的类型”是指equals方法所在的那个类。 3.把参数转换成正确的类型。因为转换之前进行过instanceof测试，所以确保会成功。 4.对于该类中的每个“关键”域，检查参数中的域是否与该对象中对应的域相匹配。如果这些测试全部成功，则返回true;否则返回false。 5.当编写完成了equals方法之后，检查“对称性”、“传递性”、“一致性”。 3、hashcode hashCode()方法返回的是一个数值，即hash码。它的主要用途是在对象进行散列的时候作为key输入。Object类提供的默认实现确保每个对象的hash码不同(在对象的内存地址基础上用特殊算法得出). 所有散列函数都有一个基本特征: 1.如果a=b，则h(a)=h(b) 2.如果a！=b 则h(a)和h(b)有可能得到相同的散列值 Object 的hashCode方法：返回一个int类型 哈希值的作用 举例来说,java集合中Set无序不重复，那么就存在一个问题，如何保证元素不重复。调用Obejct.equals方法可以判断两个元素是否相等。但是，如果使用顺序查找，当元素很多时，查找的复杂度就会变大。如，set已有1000元素，新增元素时最坏需要调用1000次equal方法确定是否已经存在。但是，当使用哈希表的时候，新增元素，计算该元素的hash值，从哈希表中看以该值为下标是否存在元素，即可判断重复与否。当然也存在哈希冲突解决问题。但大大减少了equal调用次数 4、equals和hashCode的关系 Java对于eqauls方法和hashCode方法是这样规定的： (1)同一对象上多次调用hashCode()方法，总是返回相同的整型值。 (2)如果a.equals(b)，则一定有a.hashCode() 一定等于 b.hashCode()。 (3)如果!a.equals(b)，则a.hashCode() 不一定等于 b.hashCode()。此时如果a.hashCode() 总是不等于 b.hashCode()，会提高hashtables的性能。 (4)a.hashCode()==b.hashCode() 则 a.equals(b)可真可假 (5)a.hashCode()！= b.hashCode() 则 a.equals(b)为假。 简而言之就是: 1、两个对象equal，java环境会认为hashcode一定相等 2、两个对象不equal，二者hashcode可能相等 反过来说 1、两个对象hashcode相等，不一定equal 2、两个对象hashcode不等，一等不equal ！！！敲黑板 关于这两个方法的重要规范： 规范1：若重写equals(Object obj)方法，有必要重写hashcode()方法，确保通过equals(Object obj)方法判断结果为true的两个对象具备相等的hashcode()返回值。说得简单点就是：“如果两个对象相同，那么他们的hashcode应该相等”。不过请注意：这个只是规范，如果你非要写一个类让equals(Object obj)返回true而hashcode()返回两个不相等的值，编译和运行都是不会报错的。不过这样违反了Java规范，程序也就埋下了BUG。 规范2：如果equals(Object obj)返回false，即两个对象“不相同”，并不要求对这两个对象调用hashcode()方法得到两个不相同的数。说的简单点就是：“如果两个对象不相同，他们的hashcode可能相同”。 5、为什么覆盖equals方法时总要覆盖hashCode 一个很常见的错误根源在于没有覆盖hashCode方法。在每个覆盖了equals方法的类中，也必须覆盖hashCode方法。如果不这样做的话，就会违反Object.hashCode的通用约定，从而导致该类无法结合所有基于散列的集合一起正常运作，这样的集合包括HashMap、HashSet和Hashtable。 1.在应用程序的执行期间，只要对象的equals方法的比较操作所用到的信息没有被修改，那么对这同一个对象调用多次，hashCode方法都必须始终如一地返回同一个整数。在同一个应用程序的多次执行过程中，每次执行所返回的整数可以不一致。 2.如果两个对象根据equals()方法比较是相等的，那么调用这两个对象中任意一个对象的hashCode方法都必须产生同样的整数结果。 3.如果两个对象根据equals()方法比较是不相等的，那么调用这两个对象中任意一个对象的hashCode方法，则不一定要产生相同的整数结果。但是程序员应该知道，给不相等的对象产生截然不同的整数结果，有可能提高散列表的性能。]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java常见集合系列]]></title>
    <url>%2F2019%2F03%2F07%2Fjava%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[1.java集合框架体系图 2.常见Map家族2.1 HashMap&nbsp;&nbsp;&nbsp;&nbsp;HashMap 是基于哈希表的 Map 接口的非同步实现。此实现提供所有可选的映射操作，HashMap最多只允许一条记录的键为null，允许多条记录的值为null。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。&nbsp;&nbsp;&nbsp;&nbsp;HashMap的底层数据结构是数组+链表。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法。其put方法的实现过程是，首先根据key的hashcode，进行高位运算，取模运算，并将结果作为数组下标，如果该位置已有值，则通过equals方法比较二者是否相等，如果相等则用新值覆盖旧值，如若不等，则将新建链表节点并插在已存节点的前面。同理，get方法的实现首先计算key的hashcode找到数组下标，通过equals方法比较链表中相等的键，然后返回该节点的value。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，put方法实现时可能存在扩容过程。因为Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。为了解resize机制，先看构造函数参数源码：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int threshold; //所能容纳的key-value对极限&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;final float loadFactor; // 负载因子&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int modCount;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int size;&nbsp;&nbsp;&nbsp;&nbsp;首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。&nbsp;&nbsp;&nbsp;&nbsp;结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择。&nbsp;&nbsp;&nbsp;&nbsp;size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。&nbsp;&nbsp;&nbsp;&nbsp;这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。 2.2 LinkedHashMap&nbsp;&nbsp;&nbsp;&nbsp;LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。在LinkedHashMap中，是通过双联表的结构来维护节点的顺序的，其他处理逻辑与HashMap一致，同样也没有锁保护，多线程使用存在风险。 2.3 TreeMap&nbsp;&nbsp;&nbsp;&nbsp;TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。底层是红黑树。 2.4 HashTable&nbsp;&nbsp;&nbsp;&nbsp;Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 3.常见List家族3.1 ArrayList&nbsp;&nbsp;&nbsp;&nbsp;ArrayList实现了可变大小的数组。它允许所有元素，包括null。ArrayList是基于数组实现的，是一个动态数组，其容量能自动增长，类似于C语言中的动态申请内存，动态增长内存。size，isEmpty，get，set方法运行时间为常数。但是add方法开销为分摊的常数，添加n个元素需要O(n)的时间。其他的方法运行时间为线性。&nbsp;&nbsp;&nbsp;&nbsp;每个ArrayList实例都有一个容量（Capacity），即用于存储元素的数组的大小。这个容量可随着不断添加新元素而自动增加，但是增长算法并 没有定义。当需要插入大量元素时，在插入前可以调用ensureCapacity方法来增加ArrayList的容量以提高插入效率。ArrayList是非同步的（unsynchronized）。特点是：寻址容易，插入和删除困难； 3.2 LinkedList&nbsp;&nbsp;&nbsp;&nbsp;LinkedList实现了List接口，允许null元素，底层是一个链表。此外LinkedList提供额外的get，remove，insert方法在 LinkedList的首部或尾部。这些操作使LinkedList可被用作堆栈（stack），队列（queue）或双向队列（deque）。它也是非同步的。 3.3 Vector&nbsp;&nbsp;&nbsp;&nbsp;Vector非常类似ArrayList，但是Vector是同步的。由Vector创建的Iterator，虽然和ArrayList创建的 Iterator是同一接口，但是，因为Vector是同步的，当一个Iterator被创建而且正在被使用，另一个线程改变了Vector的状态（例 如，添加或删除了一些元素），这时调用Iterator的方法时将抛出ConcurrentModificationException，因此必须捕获该 异常。 3.4 Stack&nbsp;&nbsp;&nbsp;&nbsp;Stack继承自Vector，实现一个后进先出的堆栈。Stack提供5个额外的方法使得 Vector得以被当作堆栈使用。基本的push和pop 方法，还有peek方法得到栈顶的元素，empty方法测试堆栈是否为空，search方法检测一个元素在堆栈中的位置。Stack刚创建后是空栈。 3.常见Set家族4.1 HashSet&nbsp;&nbsp;&nbsp;&nbsp;它不允许出现重复元素(根据hashCode比较)；&nbsp;&nbsp;&nbsp;&nbsp;不保证集合中元素的顺序&nbsp;&nbsp;&nbsp;&nbsp;允许包含值为null的元素，但最多只能有一个null元素。&nbsp;&nbsp;&nbsp;&nbsp;HashSet的实现是不同步的。&nbsp;&nbsp;&nbsp;&nbsp;HashSet的底层通过HashMap实现的。而HashMap在1.7之前使用的是数组+链表实现，在1.8+使用的数组+链表+红黑树实现。其实也可以这样理解，HashSet的底层实现和HashMap使用的是相同的方式，因为Map是无序的，因此HashSet也无法保证顺序。&nbsp;&nbsp;&nbsp;&nbsp;HashSet的方法，也是借助HashMap的方法来实现的。HashSet中的元素都存放在HashMap的key上面，而value中的值都是统一的一个private static final Object PRESENT = new Object();。 4.2 LinkedHashSet&nbsp;&nbsp;&nbsp;&nbsp;对于LinkedHashSet而言，它继承于HashSet、又基于LinkedHashMap来实现的。LinkedHashSet底层使用LinkedHashMap来保存所有元素，它继承于HashSet，其所有的方法操作上又与HashSet相同。&nbsp;&nbsp;&nbsp;&nbsp;LinkedHashSet是具有可预知迭代顺序的Set接口的哈希表和链接列表实现。此实现与HashSet的不同之处在于，后者维护着一个运行于所有条目的双重链接列表。此链接列表定义了迭代顺序，该迭代顺序可为插入顺序或是访问顺序。此实现不是同步的。 4.3 TreeSet&nbsp;&nbsp;&nbsp;&nbsp;TreeSet类实现 Set 接口，该接口由 TreeMap 实例支持。此类保证排序后的 set 按照升序排列元素，根据使用的构造方法不同，可能会按照元素的自然顺序 进行排序，或按照在创建 set 时所提供的比较器进行排序。&nbsp;&nbsp;&nbsp;&nbsp;TreeSet描述的是Set的一种变体——可以实现排序等功能的集合，它在将对象元素添加到集合中时会自动按照某种比较规则将其插入到有序的对象序列中.&nbsp;&nbsp;&nbsp;&nbsp;HashSet是基于Hash算法实现的,其性能通常优于TreeSet,我们通常都应该使用HashSet,在我们需要排序的功能时,我门才使用TreeSet;TreeSet是非同步的，线程不安全的。 4.4 HashSet，TreeSet，LinkedHashSet之间的区别&nbsp;&nbsp;&nbsp;&nbsp;HashSet只去重，TreeSet去重并排序，LinkedHashSet去重并保留插入顺序 5.List 、Set、 Map有什么区别和联系&nbsp;&nbsp;&nbsp;&nbsp;list 和set 有共同的父类 它们的用法也是一样的 唯一的不太就是set中不能有相同的元素 list中可以&nbsp;&nbsp;&nbsp;&nbsp;list和set的用途非常广泛 list可以完全代替数组来使用&nbsp;&nbsp;&nbsp;&nbsp;map 是独立的合集 它使用键值对的方式来储存数据 键不能有重复的 值可以用&nbsp;&nbsp;&nbsp;&nbsp;map不像上边两种集合那个用的广泛 不过在servlet 和jsp中map可是绝对的重中之重 页面之间传值全靠map]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典排序算法]]></title>
    <url>%2F2019%2F03%2F07%2F%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序算法是最经典的算法知识。因为其实现代码短，应该广，在面试中经常会问到排序算法及其相关的问题。一般在面试中最常考的是快速排序和归并排序等基本的排序算法，并且经常要求现场手写基本的排序算法。如果这些问题回答不好，估计面试就凉凉了。所以熟练掌握排序算法思想及其特点并能够熟练地手写代码至关重要。 下面介绍几种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、基数排序的思想，其代码均采用Java实现。 1.冒泡排序1.1.思想 冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端 1.2.算法描述比较相邻的元素。如果第一个比第二个大，就交换它们两个；对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；针对所有的元素重复以上的步骤，除了最后一个；重复步骤1~3，直到排序完成 1.3.动画演示 1.4.代码实现public static int[] bubble(int[] a){ int temp = 0; for (int i=0;i&lt;a.length;i++){//遍历整个数组 for (int j=0;j&lt;a.length-1-i;j++){//每次遍历跟相邻比较 if (a[j]&gt;a[j+1]){ //把大的值往后放 temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; } }//一次循环后就能把最大值（最小值）浮动到数组尾（头） } return a; } 2.选择排序2.1 思想选择排序是一种简单直观的排序算法，它也是一种交换排序算法，和冒泡排序有一定的相似度，可以认为选择排序是冒泡排序的一种改进。 2.2算法描述在未排序序列中找到最小（大）元素，存放到排序序列的起始位置从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。重复第二步，直到所有元素均排序完毕。 2.3.动画演示 2.4.代码实现 public static int[] select(int[] array){ int temp = 0; for (int i=0;i&lt;array.length;i++){ for (int j=i+1;j&lt;array.length;j++){//每次当前值都和后面所有值比较，找到比它小的就交换 if (array[i]&gt;array[j]){ temp = array[i]; array[i] = array[j]; array[j] = temp; } }//每次循环结束，就能找到相对最小值放在数组起那么 } return array; } //改进选择排序，记录最小值下标，只交换一次 public static int[] select2(int[] array){ int temp = 0; for (int i=0;i&lt;array.length;i++){ int minIndex = i; //记录下标值 for (int j=i+1;j&lt;array.length;j++){ if (array[minIndex]&gt;array[j]){ minIndex = j; } } temp = array[i]; array[i] = array[minIndex]; array[minIndex] = temp; } return array; } 3.插入排序3.1.思想插入排序是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。 3.2.算法描述把待排序的数组分成已排序和未排序两部分，初始的时候把第一个元素认为是已排好序的。从第二个元素开始，在已排好序的子数组中寻找到该元素合适的位置并插入该位置。重复上述过程直到最后一个元素被插入有序子数组中。 3.3.动画演示 3.4.代码实现//直插，总是假设前面是有序的，后面往前找到合适的位置插入 public static int[] insert(int[] a,int n){ int temp = 0 ; int j; for (int i=0;i&lt;n;i++){//遍历全部 temp = a[i+1]; //暂存当前的下一个 j=i; //j从当前开始 while (j&gt;-1&amp;&amp;temp&lt;a[j]){//如果后面的值小于当前值，进入循环 a[j+1] = a[j]; //temp已经存了下一个的值，可以直接覆盖 j--; } a[j+1] = temp; //恢复覆盖的值 } return a; } 4.归并排序4.1.思想归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。 4.2.算法描述迭代法（Bottom-up）原理如下（假设序列共有n个元素）： 将序列每相邻两个数字进行归并操作，形成ceil(n/2)个序列，排序后每个序列包含两/一个元素若此时序列数不是1个则将上述序列再次归并，形成ceil(n/4)个序列，每个序列包含四/三个元素重复步骤2，直到所有元素排序完毕，即序列数为1 4.3.动画演示 4.4.代码实现//归并，借助辅助交换数组,根据k长度进行归并 public static int[] merge(int[] a,int k){//k是分组的长度 int aLeft = 0; //第分组起始下标 int aRight; //a分组终止下标 int bLeft; //b分组起始下标 int bRight; //第分组终止下标 int[] swap = new int[a.length];//等长辅助数组 int m = 0; //m记录辅助数组下标位置 int i,j; //i记录a分组遍历，b记录b分组遍历 while (aLeft+k&lt;=a.length-1){//从相邻分组b起始遍历，将b往a里合并 bLeft = aLeft+k; //b分组的起始下标=第1分组起始+分组长度 aRight = bLeft-1; //a分组的终止是b分组起始往前退1 bRight = (bLeft+k&gt;a.length)? a.length-1:bLeft+k-1;//b分组=b起始+长度，但是不能超高a数组总长度 for (i=aLeft,j=bLeft;i&lt;=aRight&amp;&amp;j&lt;=bRight;m++){//从a分组开始扫描比较 if (a[j]&gt;=a[i]){//如果a分组小，放入辅助数组，a分组前进 swap[m] = a[i]; i++; }else {//如果b分组小，放入辅助数组，b分组前进 swap[m] = a[j]; j++; } } //遍历结束，一定至少有一个分组已经合并完 while (i&lt;=aRight){//如果a分组还没合并完 swap[m++] = a[i++]; //剩余数据压入辅助数组 } while (j&lt;=bRight){//如果b分组还没合并完 swap[m++] = a[j++]; } aLeft = bRight+1;//a,b合并完后下一个新a分组从旧b分组长度+1开始 } //此时所有能完整分组的已经合并完，剩下分组长度不足数的 for (i=aLeft;i&lt;a.length;i++){//从不足数分组起始遍历 swap[m++] = a[i]; //全部压入辅助数组中 } return swap; } //合并长度长1，2,2k... public static int[] mergeSort(int[] a){ int i,k=1; while (k&lt;a.length){ a = merge(a,k ); k = 2*k; } return a; } 5.快速排序5.1.思想快速排序是一个知名度极高的排序算法，其对于大数据的优秀排序性能和相同复杂度算法中相对简单的实现使它注定得到比其他算法更多的宠爱。 5.2.算法描述从数列中挑出一个元素，称为”基准”（pivot），重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任何一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。 5.3.动画演示 5.4代码实现//快排,从第一个元素开始，比他小的在左边，比他大的在右边，递归左右 public static int[] quick(int[] a,int left,int right){ int temp = a[left];//总是从最左第一个 int i = left; int j = right; while (i&lt;j){ while (i&lt;j&amp;&amp;temp&lt;=a[j]){//从右到左，找第一个比它小的 j--; } if (i&lt;j){//如果找到了 a[i] = a[j];//将比它大的值移到最右左边 i++; //左边距离前进一个单位 } while (i&lt;j&amp;&amp;a[i]&lt;temp){//从左向右，找第一个比它大的 i++; } if (i&lt;j){//如果找到了 a[j] = a[i];//将比他小的移到右边 j--; //右边距离缩短一个单位 } a[i] = temp; //找到了合适的位置放进去，左边都比它小，右边都比它大 } if (i&gt;left)quick(a,left ,i-1 );//递归左边的子集 if (i&lt;right)quick(a,j+1 ,right );//递归右边的子集 return a; } 6.堆排序6.1.思想堆排序(Heapsort)是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位指定索引的元素。堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。 6.1.1.堆概念堆是一种特殊的完全二叉树（complete binary tree）。完全二叉树的一个“优秀”的性质是，除了最底层之外，每一层都是满的，这使得堆可以利用数组来表示（普通的一般的二叉树通常用链表作为基本容器表示），每一个结点对应数组中的一个元素。如下图，是一个堆和数组的相互关系：对于给定的某个结点的下标 i，可以很容易的计算出这个结点的父结点、孩子结点的下标： Parent(i) = floor(i/2)，i 的父节点下标Left(i) = 2i，i 的左子节点下标Right(i) = 2i + 1，i 的右子节点下标二叉堆一般分为两种：最大堆和最小堆。最大堆中的最大元素值出现在根结点（堆顶）堆中每个父节点的元素值都大于等于其孩子结点（如果存在）最小堆中的最小元素值出现在根结点（堆顶）堆中每个父节点的元素值都小于等于其孩子结点（如果存在） 6.2.算法描述堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。在堆中定义以下几种操作： 最大堆调整（Max-Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点创建最大堆（Build-Max-Heap）：将堆所有数据重新排序，使其成为最大堆堆排序（Heap-Sort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算 继续进行下面的讨论前，需要注意的一个问题是：数组都是 Zero-Based，这就意味着我们的堆数据结构模型要发生改变 6.3.动画演示6.4代码实现//堆排序(最大堆) public static int[] heap(int[] a){ int temp = 0; initHeap(a,a.length ); //2.1初始化堆，将无序序列构造为堆。 for (int i=a.length-1;i&gt;0;i--){ temp = a[0]; //2.2 弹出堆顶 a[0] = a[i]; a[i] = temp; //将最大值放入数组尾 createHeap(a, 0,i );//2.3,缩小建堆范围，重新构建堆 } return a; } //从第一个非叶子节点开始建堆 public static int[] initHeap(int[] a,int n){ for (int i= (a.length-2)/2;i&gt;=0;i--){ a = createHeap(a,i,a.length); } return a; } //以h为建堆顶点,建立并调整堆 public static int[] createHeap(int[] a,int h,int n){ int i,j,tag;//tag循环结束条件（调整节点比左右都大直接出来） i = h; // i是要建堆的节点下标 j=2*i+1; //建堆节点的左孩子 int temp = a[i]; tag = 0; while (j&lt;n&amp;&amp;tag!=1){ if (j&lt;n-1&amp;&amp;a[j]&lt;a[j+1])j++;//比较左右，取大值 if (temp&gt;a[j]){ tag = 1; }else {//调整建堆顶点，向下调整 a[i] = a[j]; i = j; j = 2*i+1; } } a[i] = temp; return a; } 7.希尔排序7.1.思想在希尔排序出现之前，计算机界普遍存在“排序算法不可能突破O(n2)”的观点。希尔排序是第一个突破O(n2)的排序算法，它是简单插入排序的改进版。希尔排序的提出，主要基于以下两点：插入排序算法在数组基本有序的情况下，可以近似达到O(n)复杂度，效率极高。但插入排序每次只能将数据移动一位，在数组较大且基本无序的情况下性能会迅速恶化。 7.2.算法描述先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；按增量序列个数k，对序列进行 k 趟排序；每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 7.3.动画演示 7.4代码实现//希尔，把数组按步长分组，每组分别进行直插排序 public static int[] shell(int[]a,int[] spans){ int span; for (int i=0;i&lt;spans.length;i++){//遍历希尔步长次 span = spans[i]; for (int k=0;k&lt;span;k++){//全部数据按照步长分组 for (int j=k;j+span&lt;a.length;j+=span){//对每个分组进行直插排序 int t =j; int temp = a[j+span]; while (t&gt;-1&amp;&amp;a[t]&gt;temp){ a[t+span] = a[t]; t -= span; } a[t+span] = temp; } } } return a; } 8.基数排序8.1.思想基数排序(Radix Sort)是桶排序的扩展，它的基本思想是：将整数按位数切割成不同的数字，然后按每个位数分别比较。排序过程：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。 8.2算法描述取得数组中的最大数，并取得位数；arr为原始数组，从最低位开始取每个位组成radix数组；对radix进行计数排序（利用计数排序适用于小范围数的特点）； 8.3.动画演示 8.4代码实现基数（桶）借用链式队列数组，按位填入 public static int[] radix(int[] a,int m){//m表示最大整数有m位 LinkedBlockingQueue&lt;Integer&gt;[] bucket = new LinkedBlockingQueue[10];//因为是10进制，所以需要10个桶 for (int i=0;i&lt;bucket.length;i++){ //初始化每个队列 bucket[i] = new LinkedBlockingQueue(); } Integer pop; //保存从桶中弹出的数 for (int i=1;i&lt;=m;i++){ //根据位数遍历 for (int j=0;j&lt;a.length;j++){ //低位开始第i位，取出每个数字对应的位数作为桶下标， double val = Math.floor(a[j]/Math.pow(10,i-1))-10*Math.floor(a[j]/Math.pow(10,i));//取位公式 bucket[(int)val] .add(a[j]); //放入桶中 } int c=0; for (int k=0;k&lt;bucket.length;k++){ //遍历所有桶 while ((pop=bucket[k].poll())!=null){ //取出数据重新放入a中 a[c++] = pop; } } } return a; } 9.算法比较总结]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>tag 算法</tag>
        <tag>tag 排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git基本命令]]></title>
    <url>%2F2019%2F03%2F06%2Fgit%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[工作区-暂存区-本地仓库-远程仓库关系对于任何一个文件，在 Git 内都只有三种状态：已提交（committed），已修改（modified）和已暂存（staged）。已提交表示该文件已经被安全地保存在本地仓库中了；已修改表示修改了某个文件，但还没有提交保存；已暂存表示把已修改的文件放在下次提交时要保存的清单中。将本地仓库与远程仓库关联，然后可以将本地仓库内容推送到远程仓库中。 本地仓库基本操作创建本地仓库mkdir test #创建本地仓库工作目录 git init #初始化本地仓库 echo &quot;first file&quot; &gt;&gt; #test.txt 在工作目录test里添加文件 git add test.txt #将工作目录里的文件添加到暂存区 git commit -m &quot;first commit&quot; #将暂存区里的文件提交到版本地仓库 删除回退操作修改了文件内容并add了文件,但尚未commit,回退到修改前git reset HEAD test.txt git checkout -- test.txt 修改了文件内容并commit了文件，回退git log #拿到commit-id git reset --hard &quot;commit-id&quot; #执行回退 清空本地仓库git rm test.txt #删了文件，暂存区还有记录 git commit -m &quot;delete&quot; #提交删除，清空暂存区 远程仓库创建ssh key1.ssh-keygen -t rsa &quot;yourmail@example.com&quot; #创建ssh key 2.到用户目录下的.ssh文件夹 复制.pub到github构建ssh key 3.ssh -T git@github.com 测试是否连接成功 创建本地仓库，并提交到github远程仓库mkdir test2 echo &quot;test2&quot; &gt;&gt; README.md git init git add README.md git commit -m &quot;test2&quot; git remote add origin yourgithbub@name.git #添加一个新的远程仓库 git push -u origin master #(推送到远程仓库。-u等于关联，后面可以直接git push) 克隆远程仓库，修改文件并提交git clone yourgithub@name.git #克隆远程仓库 cd name #进入目录 echo &quot;clone add file&quot; &gt;&gt; test3.txt git add test3.txt git commit -m &quot;clone&quot; git push 标签关联git tag #列出所有标签 git tag v1.0.1 #新建标签v1.0.1 git tag -a tagName -m &quot;comment&quot; #创建tag并且添加了附注信息 git push origin --tags v1.0.1 #将tag推送到远程仓库 git tag -d tagName #删除tag 分支管理git branch #列出所有分支 git branch name #新建分支name git checkout name #切换到name分支 echo &quot;in branch&quot; &gt;&gt; branch.txt git add branch.txt git commit -m &quot;branch&quot; git push --set-upstream origin name #将name分支提交到远程仓库 check out master git merge name #合并分支 git branch -d name #删除分支 git fetch origin dev:dev #将远程的dev分支拉取到本地的dev分支 git pull origin master:brantest #pull=fetch+merge,将远程的mater分支fetch下来并和branchtest合并]]></content>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存模型]]></title>
    <url>%2F2019%2F03%2F06%2FJVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[1.首先看个整体图 2.内存模型解释2.1.程序计数器&nbsp;&nbsp;&nbsp;&nbsp;当前线程所执行字节码的行号指示器，通过改变它的值来选取下一条指令。分支、循环、异常处理、线程恢复等都需要依赖它。它也是唯一一个不会抛出OutOfMemoryError异常的区域。 2.2.虚拟机栈(java栈)&nbsp;&nbsp;&nbsp;&nbsp;java栈描述java方法执行的内存模型。一个方法的执行时，会虚拟机会创建一个栈帧，存储局部变量表，操作数栈等。方法的调用到执行结束，相当于java栈的入栈出栈。该区域可能会产生两种异常。线程请求的栈的深度大于虚拟机允许的最大深度，抛出StackOverflowError。若该栈支持动态拓展（一般都支持），扩展时无法申请到足够的内存，抛出OutOfMemoryError异常。 2.3.本地方法栈&nbsp;&nbsp;&nbsp;&nbsp;本地方法栈与java栈功能差不多，只是java栈为java程序方法服务，而它为本地方法服务。有的虚拟机（如sun HotSpot）甚至会把二者合二为一。 如java栈一样，该区域也会抛StackOverflowError、OutOfMemoryError异常。 2.4.JAVA堆&nbsp;&nbsp;&nbsp;&nbsp;对于大多数应用来说，java堆是虚拟机管理的内存中分配最大的一部分。java堆是被所有线程共享的一块内存区域。&nbsp;&nbsp;&nbsp;&nbsp;虚拟机启动时便创建。存放对象实例，几乎所有的对象实例都在这里分配内存。该区域也是垃圾收集器管理的主要区域，因此很多时候也被称为GC堆。&nbsp;&nbsp;&nbsp;&nbsp;细分出来，该区域可以分为新生代，老年代，新生代可以再分为一个Eden空间，两个Survivor空间（from survivor，to survivor）。不论如何划分，存放的始终是实例对象。进一步划分的目的是利于回收内存，或者更快的分配内存。(内存收集器基本采用分代收集的方法)&nbsp;&nbsp;&nbsp;&nbsp;java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。如果在堆中没有内存完成实例分配，且堆无法再拓展，将会抛出OutOfMemoryError异常。 2.5.方法区&nbsp;&nbsp;&nbsp;&nbsp;方法区与java堆一样，都是线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器（JIT)编译后的代码等数据。java虚拟机规范把方法区描述为java堆的一个逻辑部分，习惯在HotSpot虚拟机上开发的程序员更愿意称其为”永久代”。&nbsp;&nbsp;&nbsp;&nbsp;当方法区无法满足内存分配需求时，将会抛出OutOfMemoryError异常。 2.6.运行时常量池&nbsp;&nbsp;&nbsp;&nbsp;运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容在类加载后将进入方法区的运行时常量池中存放。&nbsp;&nbsp;&nbsp;&nbsp;作为方法区的一部分，运行时常量池受内存限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 3.一个对象的一辈子&nbsp;&nbsp;&nbsp;&nbsp;我是一个普通的java对象，我出生在Eden区，在Eden区我还看到和我长的很像的小兄弟，我们在Eden区中玩了挺长时间。有一天Eden区中的人实在是太多了，我就被迫去了Survivor区的“From”区，自从去了Survivor区，我就开始漂了，有时候在Survivor的“From”区，有时候在Survivor的“To”区，居无定所。直到我18岁的时候，爸爸说我成人了，该去社会上闯闯了。于是我就去了年老代那边，年老代里，人很多，并且年龄都挺大的，我在这里也认识了很多人。在年老代里，我生活了20年(每次GC加一岁)，然后被回收。 &nbsp;&nbsp;&nbsp;&nbsp;1、一个人（对象）出来（new 出来）后会在Eden Space（伊甸园）无忧无虑的生活，直到GC到来打破了他们平静的生活。GC会逐一问清楚每个对象的情况，有没有钱（此对象的引用）啊，因为GC想赚钱呀，有钱的才可以敲诈嘛。然后富人就会进入Survivor Space（幸存者区），穷人的就直接kill掉。&nbsp;&nbsp;&nbsp;&nbsp;2、并不是进入Survivor Space（幸存者区）后就保证人身是安全的，但至少可以活段时间。GC会定期（可以自定义）会对这些人进行敲诈，亿万富翁每次都给钱，GC很满意，就让其进入了Genured Gen(养老区)。万元户经不住几次敲诈就没钱了，GC看没有啥价值啦，就直接kill掉了。&nbsp;&nbsp;&nbsp;&nbsp;3、进入到养老区的人基本就可以保证人身安全啦，但是亿万富豪有的也会挥霍成穷光蛋，只要钱没了，GC还是kill掉。&nbsp;&nbsp;&nbsp;&nbsp;分区的目的：新生区由于对象产生的比较多并且大都是朝生夕灭的，所以直接采用标记-清理算法。而养老区生命力很强，则采用复制算法，针对不同情况使用不同算法]]></content>
      <categories>
        <category>内存模型</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jsp开发过程中的乱码问题及其解决方案]]></title>
    <url>%2F2018%2F10%2F10%2Fjsp%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[jsp开发过程中的乱码问题及其解决方案1.必须先理清的关系jsp开发过程中,我们会看到page指令里有pageEncoding，contentType里的charset（后面一律简称charset),而浏览器自己也可以设置页面的编码格式。首先，pageEncoding表明，你这个文件将以什么编码形式保存起来。charset表明，你希望这里的代码以什么编码展示在浏览器上。浏览器自己也可以设置编码方式，当你的charset与浏览器不对应时就会出现乱码。 2.常见的几种编码 ISO-8895-1编码是单字节编码，因而可以达到数据无损,但不支持中文。 UTF-8编码多字节编码，支持中文等多种语言，是很通用的编码方式 gbk2312编码是针对中文而弄的一种编码 … 3.必须要知道的一些默认编码首先，get请求和post请求携带参数的方式不同（get直接在url上) 对于post请求，中文编码方式会受到上面提到的pageEncoding，charset，以及jsp内置对象request和response的setCharacterEncoding方法影响，后面会具体说明。 对于get请求，其中文编码会受到charset以及Tomcat服务器的配置信息影响，配置的是URLEncoding，在/conf/servlet.xml的文件中。据了解，Tomcat7及以下，默认采用ISO-8895-1,Tomcat8及以上采用UTF-8。 jsp中,request对象获取参数中需要特别注意到的一点是，对于get请求，采用request.getQueryString()得到的参数和用request.getParameter()得到的参数编码是不同的，因为方法getParameter()将会采用Tomcat服务器配置的URLEncoding自动解码一次,而getQueryString()会受到charset的影响 4.正式讲讲jsp中的编码问题 首先强调一点，内置对象的setCharacterEncoding只对post请求有效 对于post请求，当发送端用了response.setCharacterEncoding(Xxx),即设置了响应的编码格式，那么在服务器端，你可以选择用request.setCharacterEncoding(Xxx),即设置请求的编码方式来解决中文乱码问题。这一Xxx是必须一致的，response对应request。又或者，你可以自己手动转码的方式，把通过request.getParameter()得到的乱码数据data采用java.net.URLDecoder.decode(data, “Xxx”)或者new String(data.getBytes(“ISO-8895-1”),”Xxx”)从而解决乱码问题。当发送端没有设置response.setCharacterEncoding，那么此时需要参照contentType里的charset,这里的charset等价于上面的Xxx,依然可以用上述两种方式解决乱码问题。举个例子,A页面charset是utf-8，response.setCharacterEncoding是gbk2312，此时打开浏览器会是乱码，可以设置浏览器的编码为gbk，编码正常，而B页面charset也是utf-8，request.setCharacterEncoding必须是gbk，打印获取到的结果，在浏览器上还是乱码，因为浏览器在上一步被你设置成了gbk，换行utf-8正常。所以尽量控制charset与setCharacterEncoding是一致的 对于get请求，发送端的中文编码取决charset设置的编码方式，假如是utf-8，到了服务端的时候，若使用request.getParameter()，而此时你的Tomcat的URLEncoding是UTF-8,那么会自动用utf-8帮你解码一次，因而是不会出现乱码的情况。此时如果调用getQueryString(),打印的结果就是用charset设置utf-8编码方式编码的结果，需要手动解码回正常中文。 有一种无法挽回的特殊情况是，对于get请求，若发送端你的charset设置的是gbk2312，到了服务器端，假如你的Tomcat的URLEncoding是UTF-8，你用request.getParameter()获取参数，整个过程就等价于数据用了gbk2312编码，却用了utf-8自动解码，这样就会造成数据无法转回来了。当然此时你通过getQueryString()得到的数据通过解gbk2312码是可以得到正常结果的。 5.建议 控制contentType里的charset与pageEncoding与setCharacterEncoding()一致 对于中文数据尽量不用get请求提交，毕竟可能会造成上述说的无法挽回的结果。 可以设置拦截器，对请求统一进行编码，就不用一个页面调用设置编码的函数了]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jsp</tag>
        <tag>中文乱码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈社团招新]]></title>
    <url>%2F2018%2F09%2F06%2F%E8%B0%88%E7%A4%BE%E5%9B%A2%E6%8B%9B%E6%96%B0%2F</url>
    <content type="text"><![CDATA[1 自从开学后，就开始准备招新事宜，我留任校团委网络中心，已经大三的我，不论当时留下来的原因是什么，如今尘埃落定，居其位,思其责，做其事。我其实很想逃避这些东西，但如今我逃避不了了。谈起招新，谈起扫楼，谈起跟其他组织竞争，可能有人会在背后说闲话，但我只能说，我只是在尽力做我能做的事情，没有恶意，我只是提供了一个选择，一个通往我部门的选择而已。但似乎，从其他人眼中，我所做的似有不妥。可能毕竟是竞争，可能我做的还不够好。 2我渐渐觉得社团是一个很迷的地方。如果一个人，坚持了一开始的想法，那么可能他就是体验社团一年，尝尝新鲜感，留下美好的回忆，然后大二离场。有的人，开始很融入这个社团，然后开始改变自己，改变想法，成功地走上了一条新的路，或者说被社团改造。我不能说这两种情况哪一个比较好，毕竟未来谁能预料地到。社团这条路，一开始，一群人挤着抢着上车，司机也各显神通地邀请，然而讽刺的是，到最后，幸运的人成功的进入了社团，可怜的人，从被抢来抢去，到被抛来抛去，最后再也鼓不起勇气去报其他。而更讽刺的是，某些幸运的人没有做出他应该做到的表现，而当时如果招入的是其他人，结局也又未可知。这时，我们往往会说，这就是命，或者说，缘分使然，感怀亦是徒然。 3不知为何，我开始会想很多东西，考虑很多东西，我开始担心自己做的不够好，我甚至害怕带不起他们。我开始为这些事操心，明明，我应该大胆放手，让他们成长。我似乎很自卑，但在一部分人眼中，我好像也很“完美”。我感觉我变了，我开始想写一些感受，我的话开始变的很多。 4我的大学只选择了一个社团，可能我是无法体会到那些报了多个社团的人的感受，我甚至都无法去评论，因为那样显得很片面。而有的人也是只选择了一个社团，但是他却也局限于只了解这一社团，似有井底之蛙之嫌。谈到社团，却又不得不提归属感一词，有的人愿意为部门付出很多，而且无怨无悔，甚至乐此不疲，而有的人唯恐避之不及。有的人只想得到什么，不打算去付出。我不知道每一个他们是怎么想的，我也不知道他们是否认真考虑过它的意义。或许是我的成长环境决定了我的所思所想，在外人看来觉得完全没有必要去做某些我认为才是真正该做该学的事。但想回来，我应该是个利己主义者，但为何偏偏去替他人担忧他的未来。是因为他们过的比我洒脱，我需要自我安慰自己？我想有部分原因是这样的。可是明明，我对自己的未来都没能把控好，但何苦去评判他人。这一点，我不知道为什么，或者说，我还没能想到这一层。 5走走停停，大学就这么过去了，可能毕业后的自己，回想如今，又是千思百绪，又或者嘲笑自己。甚至于说，多年之后，我才记起，我在大三的招新工作里，写了这么一篇文章。如果现在的我，无意间翻到了初中时的我写的东西，多么稚嫩，却也很美好。]]></content>
      <categories>
        <category>我说</category>
      </categories>
      <tags>
        <tag>生活闲谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http模拟登陆]]></title>
    <url>%2F2018%2F09%2F03%2Fhttp%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86%2F</url>
    <content type="text"><![CDATA[使用java作为后台语言，实现带验证码的模拟登陆。采用springboot快速开发。简单而言，过程分两步 一、获取验证码图片通过抓包工具如fiddler等，或者直接在浏览器控制台找到获取验证码图片的url。然后后台发起http请求，拿到图片并展示。 如下获取验证码图片函数 private void getImg(HttpServletResponse response){ HttpGet get = new HttpGet(&quot;验证码的url&quot;); try { CloseableHttpResponse res = client.execute(get); HttpEntity entity = res.getEntity(); OutputStream out = response.getOutputStream(); byte[] buffer = new byte[1024]; int end; while ((end=entity.getContent().read(buffer))!=-1){ out.write(buffer); } out.close(); response.setContentType(&quot;image/jpeg&quot;);//设置相应类型,告诉浏览器输出的内容为图片 response.setHeader(&quot;Pragma&quot;, &quot;No-cache&quot;);//设置响应头信息，告诉浏览器不要缓存此内容 response.setHeader(&quot;Cache-Control&quot;, &quot;no-cache&quot;); response.setDateHeader(&quot;Expire&quot;, 0); // 将内存中的图片通过流动形式输出到客户端 } catch (IOException e) { e.printStackTrace(); } 二、模拟登陆通过抓包工具如fiddler等，或者直接在浏览器控制台拿到模拟登陆所需要的参数的键值，后台拼接参数后向对应的路径发送请求，一般是post请求，就能正常模拟登陆成功了。 public void doLogin(@RequestParam(&quot;stuid&quot;)String stuid, @RequestParam(&quot;password&quot;)String password, @RequestParam(&quot;code&quot;) String code, HttpServletResponse response2) throws IOException { HttpPost post = new HttpPost(&quot;登陆的url&quot;); //装填参数 List&lt;NameValuePair&gt; nvps = new ArrayList&lt;NameValuePair&gt;(); nvps.add(new BasicNameValuePair(&quot;参数1&quot;,&quot;值1&quot;)); nvps.add(new BasicNameValuePair(&quot;参数1&quot;,&quot;值2&quot; )); post.setEntity(new UrlEncodedFormEntity(nvps, &quot;UTF-8&quot;)); post.setHeader(&quot;Content-type&quot;, &quot;application/x-www-form-urlencoded&quot;); post.setHeader(&quot;User-Agent&quot;, &quot;Mozilla/4.0 (compatible; MSIE 5.0; Windows NT; DigExt)&quot;); CloseableHttpResponse response = client.execute(post); response.close(); 难点模拟难点在于控制cookie的一致，或者说要保证获取验证码时的会话要跟提交参数登陆时的会话保持一致，这样保证验证码是正确的。代码中httpclicent对象最好是全局变量，这样会自动帮我们维持cookie的一致性（同一对象等价于同一个cookie)]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[First]]></title>
    <url>%2F2018%2F08%2F25%2FFirst%2F</url>
    <content type="text"><![CDATA[这是我的第一个博客，喜欢鼓捣很多东西]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F08%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
