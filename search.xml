<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[数据库隔离]]></title>
    <url>%2F2019%2F09%2F21%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9A%94%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[数据库常用的事务隔离级别什么是事务隔离？ 任何支持事务的数据库，都必须具备四个特性，分别是：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability），也就是我们常说的事务ACID，这样才能保证事务（（Transaction）中数据的正确性。 而事务的隔离性就是指，多个并发的事务同时访问一个数据库时，一个事务不应该被另一个事务所干扰，每个并发的事务间要相互进行隔离。 如果没有事务隔离，会出现什么样的情况呢？ 假设我们现在有这样一张表（T），里面记录了很多牛人的名字，我们不进行事务的隔离看看会发生什么呢？ 第一天，事务A访问了数据库，它干了一件事情，往数据库里加上了新来的牛人的名字，但是没有提交事务。 insert into T values (4, ‘牛D’); 这时，来了另一个事务B，他要查询所有牛人的名字。 select Name from T; 这时，如果没有事务之间没有有效隔离，那么事务B返回的结果中就会出现“牛D”的名字。这就是“脏读（dirty read）”。 第二天，事务A访问了数据库，他要查看ID是1的牛人的名字，于是执行了 select Name from T where ID = 1; 这时，事务B来了，因为ID是1的牛人改名字了，所以要更新一下，然后提交了事务。 update T set Name = ‘不牛’ where ID = 1; 接着，事务A还想再看看ID是1的牛人的名字，于是又执行了 select Name from T where ID = 1; 结果，两次读出来的ID是1的牛人名字竟然不相同，这就是不可重复读（unrepeatable read）。 第三天，事务A访问了数据库，他想要看看数据库的牛人都有哪些，于是执行了 select * from T; 这时候，事务B来了，往数据库加入了一个新的牛人。 insert into T values(4, ‘牛D’); 这时候，事务A忘了刚才的牛人都有哪些了，于是又执行了。 select * from T; 结果，第一次有三个牛人，第二次有四个牛人。 相信这个时候事务A就蒙了，刚才发生了什么？这种情况就叫“幻读（phantom problem）”。 为了防止出现脏读、不可重复读、幻读等情况，我们就需要根据我们的实际需求来设置数据库的隔离级别。 数据库都有哪些隔离级别呢？ 一般的数据库，都包括以下四种隔离级别： 读未提交（Read Uncommitted）读提交（Read Committed）可重复读（Repeated Read）串行化（Serializable）如何使用这些隔离级别，那就需要根据业务的实际情况来进行判断了。 我们接下来就看看这四个隔离级别的具体情况 隔离级别读未提交（Read Uncommitted）读未提交，顾名思义，就是可以读到未提交的内容。 因此，在这种隔离级别下，查询是不会加锁的，也由于查询的不加锁，所以这种隔离级别的一致性是最差的，可能会产生“脏读”、“不可重复读”、“幻读”。 如无特殊情况，基本是不会使用这种隔离级别的。 读提交（Read Committed）读提交，顾名思义，就是只能读到已经提交了的内容。 这是各种系统中最常用的一种隔离级别，也是SQL Server和Oracle的默认隔离级别。这种隔离级别能够有效的避免脏读，但除非在查询中显示的加锁，如： select * from T where ID=2 lock in share mode; select * from T where ID=2 for update; 不然，普通的查询是不会加锁的。 那为什么“读提交”同“读未提交”一样，都没有查询加锁，但是却能够避免脏读呢？ 这就要说道另一个机制“快照（snapshot）”，而这种既能保证一致性又不加锁的读也被称为“快照读（Snapshot Read）” 假设没有“快照读”，那么当一个更新的事务没有提交时，另一个对更新数据进行查询的事务会因为无法查询而被阻塞，这种情况下，并发能力就相当的差。 而“快照读”就可以完成高并发的查询，不过，“读提交”只能避免“脏读”，并不能避免“不可重复读”和“幻读”。 可重复读(Repeated Read)可重复读，顾名思义，就是专门针对“不可重复读”这种情况而制定的隔离级别，自然，它就可以有效的避免“不可重复读”。而它也是MySql的默认隔离级别。 在这个级别下，普通的查询同样是使用的“快照读”，但是，和“读提交”不同的是，当事务启动时，就不允许进行“修改操作（Update）”了，而“不可重复读”恰恰是因为两次读取之间进行了数据的修改，因此，“可重复读”能够有效的避免“不可重复读”，但却避免不了“幻读”，因为幻读是由于“插入或者删除操作（Insert or Delete）”而产生的。 串行化（Serializable）这是数据库最高的隔离级别，这种级别下，事务“串行化顺序执行”，也就是一个一个排队执行。 这种级别下，“脏读”、“不可重复读”、“幻读”都可以被避免，但是执行效率奇差，性能开销也最大，所以基本没人会用。 总结为什么会出现“脏读”？因为没有“select”操作没有规矩。 为什么会出现“不可重复读”？因为“update”操作没有规矩。 为什么会出现“幻读”？因为“insert”和“delete”操作没有规矩。 “读未提（Read Uncommitted）”能预防啥？啥都预防不了。 “读提交（Read Committed）”能预防啥？使用“快照读（Snapshot Read）”，避免“脏读”，但是可能出现“不可重复读”和“幻读”。 “可重复读（Repeated Red）”能预防啥？使用“快照读（Snapshot Read）”，锁住被读取记录，避免出现“脏读”、“不可重复读”，但是可能出现“幻读”。 “串行化（Serializable）”能预防啥？排排坐，吃果果，有效避免“脏读”、“不可重复读”、“幻读”，不过效果谁用谁知道。]]></content>
      <categories>
        <category>mysql</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库隔离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA内部类]]></title>
    <url>%2F2019%2F09%2F17%2FJAVA%E5%86%85%E9%83%A8%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[JAVA内部类内部类在 Java 里面算是非常常见的一个功能了，在日常开发中我们肯定多多少少都用过，这里总结一下关于 Java 中内部类的相关知识点和一些使用内部类时需要注意的点。从种类上说，内部类可以分为四类：普通内部类、静态内部类、匿名内部类、局部内部类。我们来一个个看： 普通内部类这个是最常见的内部类之一了，其定义也很简单，在一个类里面作为类的一个字段直接定义就可以了，例 public class InnerClassTest { public class InnerClassA { } } 在这里 InnerClassA 类为 InnerClassTest 类的普通内部类，在这种定义方式下，普通内部类对象依赖外部类对象而存在，即在创建一个普通内部类对象时首先需要创建其外部类对象，我们在创建上面代码中的 InnerClassA 对象时先要创建 InnerClassTest 对象，例： public class InnerClassTest { public int outField1 = 1; protected int outField2 = 2; int outField3 = 3; private int outField4 = 4; public InnerClassTest() { // 在外部类对象内部，直接通过 new InnerClass(); 创建内部类对象 InnerClassA innerObj = new InnerClassA(); System.out.println(&quot;创建 &quot; + this.getClass().getSimpleName() + &quot; 对象&quot;); System.out.println(&quot;其内部类的 field1 字段的值为: &quot; + innerObj.field1); System.out.println(&quot;其内部类的 field2 字段的值为: &quot; + innerObj.field2); System.out.println(&quot;其内部类的 field3 字段的值为: &quot; + innerObj.field3); System.out.println(&quot;其内部类的 field4 字段的值为: &quot; + innerObj.field4); } public class InnerClassA { public int field1 = 5; protected int field2 = 6; int field3 = 7; private int field4 = 8; // static int field5 = 5; // 编译错误！普通内部类中不能定义 static 属性 public InnerClassA() { System.out.println(&quot;创建 &quot; + this.getClass().getSimpleName() + &quot; 对象&quot;); System.out.println(&quot;其外部类的 outField1 字段的值为: &quot; + outField1); System.out.println(&quot;其外部类的 outField2 字段的值为: &quot; + outField2); System.out.println(&quot;其外部类的 outField3 字段的值为: &quot; + outField3); System.out.println(&quot;其外部类的 outField4 字段的值为: &quot; + outField4); } } public static void main(String[] args) { InnerClassTest outerObj = new InnerClassTest(); // 不在外部类内部，使用：外部类对象. new 内部类构造器(); 的方式创建内部类对象 // InnerClassA innerObj = outerObj.new InnerClassA(); } } 这里的内部类就像外部类声明的一个属性字段一样，可以有访问限定符，也因此new其对象时依附于外部类对象而存在的，我们来看一下结果 我们注意到，内部类对象可以访问外部类对象中所有访问权限的字段，同时，外部类对象也可以通过内部类的对象引用来访问内部类中定义的所有访问权限的字段，后面我们将从源码里面分析具体的原因。成员内部类不能定义静态成员。 静态内部类我们知道，一个类的静态成员独立于这个类的任何一个对象存在，只要在具有访问权限的地方，我们就可以通过 类名.静态成员名 的形式来访问这个静态成员，同样的，静态内部类也是作为一个外部类的静态成员而存在，创建一个类的静态内部类对象不需要依赖其外部类对象。例： public class InnerClassTest { public int field1 = 1; public InnerClassTest() { System.out.println(&quot;创建 &quot; + this.getClass().getSimpleName() + &quot; 对象&quot;); // 创建静态内部类对象 StaticClass innerObj = new StaticClass(); System.out.println(&quot;其内部类的 field1 字段的值为: &quot; + innerObj.field1); System.out.println(&quot;其内部类的 field2 字段的值为: &quot; + innerObj.field2); System.out.println(&quot;其内部类的 field3 字段的值为: &quot; + innerObj.field3); System.out.println(&quot;其内部类的 field4 字段的值为: &quot; + innerObj.field4); } static class StaticClass { public int field1 = 1; protected int field2 = 2; int field3 = 3; private int field4 = 4; // 静态内部类中可以定义 static 属性 static int field5 = 5; public StaticClass() { System.out.println(&quot;创建 &quot; + StaticClass.class.getSimpleName() + &quot; 对象&quot;); // System.out.println(&quot;其外部类的 field1 字段的值为: &quot; + field1); // 编译错误！！ } } public static void main(String[] args) { // 无需依赖外部类对象，直接创建内部类对象 InnerClassTest.StaticClass staticClassObj = new InnerClassTest.StaticClass(); } } 可以看到，静态内部类就像外部类的一个静态成员一样，创建其对象无需依赖外部类对象（访问一个类的静态成员也无需依赖这个类的对象，因为它是独立于所有类的对象的,new它的对象时无需加载外部类）。但是于此同时，静态内部类中也无法访问外部类的非静态成员，因为外部类的非静态成员是属于每一个外部类对象的，而本身静态内部类就是独立外部类对象存在的，所以静态内部类不能访问外部类的非静态成员，而外部类依然可以访问静态内部类对象的所有访问权限的成员，这一点和普通内部类无异。 匿名内部类匿名内部类有多种形式，其中最常见的一种形式莫过于在方法参数中新建一个接口对象 / 类对象，并且实现这个接口声明 / 类中原有的方法了： public class InnerClassTest { public int field1 = 1; protected int field2 = 2; int field3 = 3; private int field4 = 4; public InnerClassTest() { System.out.println(&quot;创建 &quot; + this.getClass().getSimpleName() + &quot; 对象&quot;); } // 自定义接口 interface OnClickListener { void onClick(Object obj); } private void anonymousClassTest() { // 在这个过程中会新建一个匿名内部类对象， // 这个匿名内部类实现了 OnClickListener 接口并重写 onClick 方法 OnClickListener clickListener = new OnClickListener() { // 可以在内部类中定义属性，但是只能在当前内部类中使用， // 无法在外部类中使用，因为外部类无法获取当前匿名内部类的类名， // 也就无法创建匿名内部类的对象 int field = 1; @Override public void onClick(Object obj) { System.out.println(&quot;对象 &quot; + obj + &quot; 被点击&quot;); System.out.println(&quot;其外部类的 field1 字段的值为: &quot; + field1); System.out.println(&quot;其外部类的 field2 字段的值为: &quot; + field2); System.out.println(&quot;其外部类的 field3 字段的值为: &quot; + field3); System.out.println(&quot;其外部类的 field4 字段的值为: &quot; + field4); } }; // new Object() 过程会新建一个匿名内部类，继承于 Object 类， // 并重写了 toString() 方法 clickListener.onClick(new Object() { @Override public String toString() { return &quot;obj1&quot;; } }); } public static void main(String[] args) { InnerClassTest outObj = new InnerClassTest(); outObj.anonymousClassTest(); } } 上面的代码中展示了常见的两种使用匿名内部类的情况：1、直接 new 一个接口，并实现这个接口声明的方法，在这个过程其实会创建一个匿名内部类实现这个接口，并重写接口声明的方法，然后再创建一个这个匿名内部类的对象并赋值给前面的 OnClickListener 类型的引用；2、new 一个已经存在的类 / 抽象类，并且选择性的实现这个类中的一个或者多个非 final 的方法，这个过程会创建一个匿名内部类对象继承对应的类 / 抽象类，并且重写对应的方法。 同样的，在匿名内部类中可以使用外部类的属性，但是外部类却不能使用匿名内部类中定义的属性，因为是匿名内部类，因此在外部类中无法获取这个类的类名，也就无法得到属性信息。 局部内部类局部内部类使用的比较少，其声明在一个方法体 / 一段代码块的内部，而且不在定义类的定义域之内便无法使用，其提供的功能使用匿名内部类都可以实现，而本身匿名内部类可以写得比它更简洁，因此局部内部类用的比较少。来看一个局部内部类的小例子： public class InnerClassTest { public int field1 = 1; protected int field2 = 2; int field3 = 3; private int field4 = 4; public InnerClassTest() { System.out.println(&quot;创建 &quot; + this.getClass().getSimpleName() + &quot; 对象&quot;); } private void localInnerClassTest() { // 局部内部类 A，只能在当前方法中使用 class A { // static int field = 1; // 编译错误！局部内部类中不能定义 static 字段 public A() { System.out.println(&quot;创建 &quot; + A.class.getSimpleName() + &quot; 对象&quot;); System.out.println(&quot;其外部类的 field1 字段的值为: &quot; + field1); System.out.println(&quot;其外部类的 field2 字段的值为: &quot; + field2); System.out.println(&quot;其外部类的 field3 字段的值为: &quot; + field3); System.out.println(&quot;其外部类的 field4 字段的值为: &quot; + field4); } } A a = new A(); if (true) { // 局部内部类 B，只能在当前代码块中使用 class B { public B() { System.out.println(&quot;创建 &quot; + B.class.getSimpleName() + &quot; 对象&quot;); System.out.println(&quot;其外部类的 field1 字段的值为: &quot; + field1); System.out.println(&quot;其外部类的 field2 字段的值为: &quot; + field2); System.out.println(&quot;其外部类的 field3 字段的值为: &quot; + field3); System.out.println(&quot;其外部类的 field4 字段的值为: &quot; + field4); } } B b = new B(); } // B b1 = new B(); // 编译错误！不在类 B 的定义域内，找不到类 B， } public static void main(String[] args) { InnerClassTest outObj = new InnerClassTest(); outObj.localInnerClassTest(); } } 同样的，在局部内部类里面可以访问外部类对象的所有访问权限的字段，而外部类却不能访问局部内部类中定义的字段，因为局部内部类的定义只在其特定的方法体 / 代码块中有效，一旦出了这个定义域，那么其定义就失效了，就像代码注释中描述的那样，即外部类不能获取局部内部类的对象，因而无法访问局部内部类的字段。最后看看运行结果： 内部类的嵌套内部类的嵌套，即为内部类中再定义内部类，这个问题从内部类的分类角度去考虑比较合适： 普通内部类：在这里我们可以把它看成一个外部类的普通成员方法，在其内部可以定义普通内部类（嵌套的普通内部类），但是无法定义 static 修饰的内部类，就像你无法在成员方法中定义 static 类型的变量一样，当然也可以定义匿名内部类和局部内部类； 静态内部类：因为这个类独立于外部类对象而存在，我们完全可以将其拿出来，去掉修饰它的 static 关键字，他就是一个完整的类，因此在静态内部类内部可以定义普通内部类，也可以定义静态内部类，同时也可以定义 static 成员； 匿名内部类：和普通内部类一样，定义的普通内部类只能在这个匿名内部类中使用，定义的局部内部类只能在对应定义域内使用； 局部内部类：和匿名内部类一样，但是嵌套定义的内部类只能在对应定义域内使用。 深入理解内部类不知道小伙伴们对上面的代码有没有产生疑惑：非静态内部类可以访问外部类所有访问权限修饰的字段（即包括了 private 权限的），同时，外部类也可以访问内部类的所有访问权限修饰的字段。而我们知道，private 权限的字段只能被当前类本身访问。然而在上面我们确实在代码中直接访问了对应外部类 / 内部类的 private 权限的字段，要解除这个疑惑，只能从编译出来的类下手了，为了简便，这里采用下面的代码进行测试： public class InnerClassTest { int field1 = 1; private int field2 = 2; public InnerClassTest() { InnerClassA inner = new InnerClassA(); int v = inner.x2; } public class InnerClassA { int x1 = field1; private int x2 = field2; } } 我在外部类中定义了一个默认访问权限（同一个包内的类可以访问）的字段 field1， 和一个 private 权限的字段 field2 ，并且定义了一个内部类 InnerClassA ，并且在这个内部类中也同样定义了两个和外部类中定义的相同修饰权限的字段，并且访问了外部类对应的字段。最后在外部类的构造方法中我定义了一个方法内变量赋值为内部类中 private 权限的字段。我们用 javac 命令（javac InnerClassTest.java）编译这个 .java 文件，会得到两个 .classs 文件：InnerClassTest.class 和 InnerClassTest$InnerClassA.class，我们再用 javap -c 命令（javap -c InnerClassTest 和 javap -c InnerClassTest$InnerClassA）分别反编译这两个 .class 文件，InnerClassTest.class 的字节码如下： 我们注意到字节码中多了一个默认修饰权限并且名为 access$100 的静态方法，其接受一个 InnerClassTest 类型的参数，即其接受一个外部类对象作为参数，方法内部用三条指令取到参数对象的 field2 字段的值并返回。由此，我们现在大概能猜到内部类对象是怎么取到外部类的 private 权限的字段了：就是通过这个外部类提供的静态方法。类似的，我们注意到 24 行字节码指令 invokestatic ，这里代表执行了一个静态方法，而后面的注释也写的很清楚，调用的是 InnerClassTest$InnerClassA.access$000 方法，即调用了内部类中名为 access$000 的静态方法，根据我们上面的外部类字节码规律，我们也能猜到这个方法就是内部类编译过程中编译器自动生成的，那么我们赶紧来看一下 InnerClassTest$InnerClassA 类的字节码吧： 果然，我们在这里发现了名为 access$000 的静态方法，并且这个静态方法接受一个 InnerClassTest$InnerClassA 类型的参数，方法的作用也很简单：返回参数代表的内部类对象的 x2 字段值。我们还注意到编译器给内部类提供了一个接受 InnerClassTest 类型对象（即外部类对象）的构造方法，内部类本身还定义了一个名为 this$0 的 InnerClassTest 类型的引用，这个引用在构造方法中指向了参数所对应的外部类对象。 最后，我们在 25 行字节码指令发现：内部类的构造方法通过 invokestatic 指令执行外部类的 access$100 静态方法（在 InnerClassTest 的字节码中已经介绍了）得到外部类对象的 field2 字段的值，并且在后面赋值给 x2 字段。这样的话内部类就成功的通过外部类提供的静态方法得到了对应外部类对象的 field2 。 上面我们只是对普通内部类进行了分析，但其实匿名内部类和局部内部类的原理和普通内部类是类似的，只是在访问上有些不同：外部类无法访问匿名内部类和局部内部类对象的字段，因为外部类根本就不知道匿名内部类 / 局部内部类的类型信息（匿名内部类的类名被隐匿，局部内部类只能在定义域内使用）。但是匿名内部类和局部内部类却可以访问外部类的私有成员，原理也是通过外部类提供的静态方法来得到对应外部类对象的私有成员的值。而对于静态内部类来说，因为其实独立于外部类对象而存在，因此编译器不会为静态内部类对象提供外部类对象的引用，因为静态内部类对象的创建根本不需要外部类对象支持。但是外部类对象还是可以访问静态内部类对象的私有成员，因为外部类可以知道静态内部类的类型信息，即可以得到静态内部类的对象，那么就可以通过静态内部类提供的静态方法来获得对应的私有成员值。来看一个简单的代码证明： public class InnerClassTest { int field1 = 1; private int field2 = 2; public InnerClassTest() { InnerClassA inner = new InnerClassA(); int v = inner.x2; } // 这里改成了静态内部类，因而不能访问外部类的非静态成员 public static class InnerClassA { private int x2 = 0; } } 同样的编译步骤，得到了两个 .class 文件，这里看一下内部类的 .class 文件反编译的字节码 InnerClassTest$InnerClassA： 仔细看一下，确实没有找到指向外部类对象的引用，编译器只为这个静态内部类提供了一个无参构造方法。而且因为外部类对象需要访问当前类的私有成员，编译器给这个静态内部类生成了一个名为 access$000 的静态方法，作用已不用我多说了。如果我们不看类名，这个类完全可以作为一个普通的外部类来看，这正是静态内部类和其余的内部类的区别所在：静态内部类对象不依赖其外部类对象存在，而其余的内部类对象必须依赖其外部类对象而存在。 OK，到这里问题都得到了解释：在非静态内部类访问外部类私有成员 / 外部类访问内部类私有成员 的时候，对应的外部类 / 外部类会生成一个静态方法，用来返回对应私有成员的值，而对应外部类对象 / 内部类对象通过调用其内部类 / 外部类提供的静态方法来获取对应的私有成员的值。 内部类和多重继承我们已经知道，Java 中的类不允许多重继承，也就是说 Java 中的类只能有一个直接父类，而 Java 本身提供了内部类的机制，这是否可以在一定程度上弥补 Java 不允许多重继承的缺陷呢？我们这样来思考这个问题：假设我们有三个基类分别为 A、B、C，我们希望有一个类 D 达成这样的功能：通过这个 D 类的对象，可以同时产生 A 、B 、C 类的对象，通过刚刚的内部类的介绍，我们也应该想到了怎么完成这个需求了，创建一个类 D.java： class A {} class B {} class C {} public class D extends A { // 内部类，继承 B 类 class InnerClassB extends B { } // 内部类，继承 C 类 class InnerClassC extends C { } // 生成一个 B 类对象 public B makeB() { return new InnerClassB(); } // 生成一个 C 类对象 public C makeC() { return new InnerClassC(); } public static void testA(A a) { // ... } public static void testB(B b) { // ... } public static void testC(C c) { // ... } public static void main(String[] args) { D d = new D(); testA(d); testB(d.makeB()); testC(d.makeC()); } } 程序正确运行。而且因为普通内部类可以访问外部类的所有成员并且外部类也可以访问普通内部类的所有成员，因此这种方式在某种程度上可以说是 Java 多重继承的一种实现机制。但是这种方法也是有一定代价的，首先这种结构在一定程度上破坏了类结构，一般来说，建议一个 .java 文件只包含一个类，除非两个类之间有非常明确的依赖关系（比如说某种汽车和其专用型号的轮子），或者说一个类本来就是为了辅助另一个类而存在的（比如说 HashMap 类和其内部用于遍历其元素的 HashIterator 类），那么这个时候使用内部类会有较好代码结构和实现效果。而在其他情况，将类分开写会有较好的代码可读性和代码维护性。 内部类和内存泄露在 Java 中，因为 JVM 有垃圾回收功能，对于我们自己创建的对象无需手动回收这些对象的内存空间，这种机制确实在一定程度上减轻了开发者的负担，但是也增加了开发者对 JVM 垃圾回收机制的依赖性，从某个方面来说，也是弱化了开发者防止内存泄露的意识。当然，JVM 的垃圾回收机制的利是远远大于弊的，只是我们在开发过程中不应该丧失了这种对象和内存的意识。 内部类和内存泄露又有什么关系呢？我们在上面已经知道了，创建非静态内部类的对象时，新建的非静态内部类对象会持有对外部类对象的引用，这个我们在上面的源码反编译中已经介绍过了，正是因为非静态内部类对象会持有外部类对象的引用，因此如果说这个非静态内部类对象因为某些原因无法被回收，就会导致这个外部类对象也无法被回收，这个听起来是有道理的，因为我们在上文也已经介绍了：非静态内部类对象依赖于外部类对象而存在，所以内部类对象没被回收，其外部类对象自然也不能被回收。但是可能存在这种情况：非静态内部类对象在某个时刻已经不在被使用，或者说这个内部类对象可以在不影响程序正确运行的情况下被回收，而因为我们对这个内部类的使用不当而使得其无法被 JVM 回收，同时会导致其外部类对象无法被回收，即为发生内存泄露。那么这个 “使用不当” 具体指的是哪个方面呢？看一个简单的例子，新建一个 MemoryLeakTest 的类： public class MemoryLeakTest { // 抽象类，模拟一些组件的基类 abstract static class Component { final void create() { onCreate(); } final void destroy() { onDestroy(); } // 子类实现，模拟组件创建的过程 abstract void onCreate(); // 子类实现，模拟组件摧毁的过程 abstract void onDestroy(); } // 具体某个组件 static class MyComponent extends Component { // 组件中窗口的单击事件监听器 static OnClickListener clickListener; // 模拟组件中的窗口 MyWindow myWindow; @Override void onCreate() { // 执行组件内一些资源初始化的代码 clickListener = new OnClickListener() { @Override public void onClick(Object obj) { System.out.println(&quot;对象 &quot; + obj + &quot; 被单击&quot;); } }; // 新建我的窗口对象，并设置其单击事件监听器 myWindow = new MyWindow(); myWindow.setClickListener(clickListener); } @Override void onDestroy() { // 执行组件内一些资源回收的代码 myWindow.removeClickListener(); } } // 我的窗口类，模拟一个可视化控件 static class MyWindow { OnClickListener clickListener; // 设置当前控件的单击事件监听器 void setClickListener(OnClickListener clickListener) { this.clickListener = clickListener; } // 移除当前控件的单击事件监听器 void removeClickListener() { this.clickListener = null; } } // 对象的单击事件的监听接口 public interface OnClickListener { void onClick(Object obj); } public static void main(String[] args) { MyComponent myComponent = new MyComponent(); myComponent.create(); myComponent.destroy(); // myComponent 引用置为 null，排除它的干扰 myComponent = null; // 调用 JVM 的垃圾回收动作，回收无用对象 System.gc(); System.out.println(&quot;&quot;); } 我们在代码中添加一些断点，然后采用 debug 模式查看： 程序执行到 72 行代码，此时 72 行代码还未执行，因此 myComponent 引用和其对象还未创建，继续执行： 这里成功创建了一个 MyComponent 对象，但是其 create 方法还未执行，所以 myWindow 字段为 null，这里可能有小伙伴会问了，myComponent 对象的 clickListener 字段呢？怎么不见了？其实这和我们在代码中定义 clickListener 字段的形式有关，我们定义的是 static OnClickListener clickListener; ，因此 clickListener 是一个静态字段，其在类加载的完成的时候储存在 JVM 中内存区域的 方法区 中，而创建的 Java 对象储存在 JVM 的堆内存中，两者不在同一块内存区域。关于这些细节，想深入了解的小伙伴建议阅读《深入理解JVM虚拟机》。好了，我们继续执行代码： myComponent.destroy 方法执行完成之后，myWindow.removeClickListener 方法也执行完成，此时 myWindow 对象中的 clickListener 字段为 null。我们继续： 代码执行到了 80 行，在此之前，所有的代码和解释都没有什么难度，跟着运行图走，一切都那么顺利成章，其实这张图的运行结果也很好理解，只不过图中的文字需要思考一下：myComponent 引用指向的对象真的被回收了吗？要解答这个问题，我们需要借助 Java 中提供的内存分析工具 jvisualvm (以前它还不叫这个名字…），它一般在你安装 JDK 的目录下的 bin 子目录下： 在程序左边可以找到我们当前正在执行的 Java 进程，双击进入： 单击 tab 中的 监视 选项卡，可以看到当前正在执行的 Java 进程的一些资源占用信息，当然我们现在的主要目的是分析内存，那么们单击右上角的 堆 Dump ： 在这个界面，单击 类 选项卡，会出现当前 Java 进程中用到的所有的类，我们已经知道我们要查找的类的对象只创建了一个，因此我们根据右上角的 实例数 来进行排除：我们成功的找到了我们创建的对象！而这样也意味着当我们在上面代码中调用 JVM 的垃圾回收动作没有回收这三个对象，这其实就是一个真真切切的内存泄露！因为我们将 main 方法中的 myComponent 引用赋值为 null，就意味着我们已经不再使用这个组件和里面的一些子组件（MyWindow 对象），即这个组件和其内部的一些组件应该被回收。但是调用 JVM 的垃圾回收却并没有将其对应的对象回收。造成这个问题的原因在哪呢？ 其实就在于我们刚刚在 MyComponent 类中定义的 clickListener 字段，我们在代码中将其定义成了 static 类型的，同时这个字段又指向了一个匿名内部类对象（在 create 方法中 创建了一个 OnClickListener 接口对象，即通过一个匿名内部类实现这个接口并创建其对象），根据 JVM 寻找和标记无用对象的规则（可达性分析算法），其会将 clickListener 字段作为一个 “root” ，并通过它来寻找还有用的对象，在这个例子中，clickListener 字段指向一个匿名内部类对象，这个匿名内部类对象有一个外部类对象（MyComponent 类型的对象）的引用，而外部类对象中又有一个 MyWindow 类型的对象引用。因此 JVM 会将这三个对象都视为有用的对象不会回收。用图来解释吧： Ok，通过这个过程，相信你已经理解了造成此次内存泄露的原因了，那么我们该如何解决呢？对于当前这个例子，我们只需要改一些代码：1、把 MyComponent 类中的 clickListener 字段前面的 static 修饰符去掉就可以了（static OnClickListener clickListener; -&gt; OnClickListener clickListener;），这样的话 clickListener 指向的对象，就作为 MyComponent 类的对象的一部分了，在 MyComponent 对象被回收时里面的子组件也会被回收。同时它们之间也只是互相引用（MyComponent 外部类对象中有一个指向 OnClickListener 内部类对象的引用，OnClickListener 内部类对象有一个指向 MyComponent 外部类对象的引用），根据 JVM 的 “可达性分析” 算法，在两个对象都不再被外部使用时，JVM 的垃圾回收机制是可以标记并回收这两个对象的。虽然不强制要求你在 MyComponent 类中的 onDestroy 方法中将其 clickListener 引用赋值为 null，但是我还是建议你这样做，因为这样更能确保你的程序的安全性（减少发生内存泄露的机率，毕竟匿名内部类对象会持有外部类对象的引用），在某个组件被销毁时将其内部的一些子组件进行合理的处理是一个很好的习惯。 2、你也可以自定义一个静态内部类或者是另外自定义一个类文件，并实现 OnClickListener 接口，之后通过这个类创建对象，这样就可以避免通过非静态内部类的形式创建 OnClickListener 对象增加内存泄露的可能性。 避免内存泄漏那么我们在日常开发中怎么合理的使用内部类来避免产生内存泄露呢？这里给出一点我个人的理解： 1、能用静态内部类就尽量使用静态内部类，从上文中我们也知道了，静态内部类的对象创建不依赖外部类对象，即静态内部对象不会持有外部类对象的引用，自然不会因为静态内部类对象而导致内存泄露，所以如果你的内部类中不需要访问外部类中的一些非 static 成员，那么请把这个内部类改造成静态内部类； 2、对于一些自定义类的对象，慎用 static 关键字修饰（除非这个类的对象的声明周期确实应该很长），我们已经知道，JVM 在进行垃圾回收时会将 static 关键字修饰的一些静态字段作为 “root” 来进行存活对象的查找，所以程序中 static 修饰的对象越多，对应的 “root” 也就越多，每一次 JVM 能回收的对象就越少。当然这并不是建议你不使用 static 关键字，只是在使用这个关键字之前可以考虑一下这个对象使用 static 关键字修饰对程序的执行确实更有利吗？ 3、为某些组件（大型）提供一个当这个大型组件需要被回收的时候用于合理处理其中的一些小组件的方法（例如上面代码中 MyComponent 的 onDestroy 方法），在这个方法中，确保正确的处理一些需要处理的对象（将某些引用置为 null、释放一些其他（CPU…）资源）。]]></content>
      <categories>
        <category>java基础</category>
        <category>java内部类</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC之一次http请求过程]]></title>
    <url>%2F2019%2F09%2F08%2FSpringMVC%E4%B9%8B%E4%B8%80%E6%AC%A1http%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[SpringMVC之一次http请求过程SpringMVC框架是一个基于请求驱动的Web框架，并且使用了‘前端控制器’模型来进行设计，再根据‘请求映射规则’分发给相应的页面控制器进行处理。 整体流程 具体步骤： 1、 首先用户发送请求到前端控制器，前端控制器根据请求信息（如 URL）来决定选择哪一个页面控制器进行处理并把请求委托给它，即以前的控制器的控制逻辑部分；图中的 1、2 步骤； 2、 页面控制器接收到请求后，进行功能处理，首先需要收集和绑定请求参数到一个对象，这个对象在 Spring Web MVC 中叫命令对象，并进行验证，然后将命令对象委托给业务对象进行处理；处理完毕后返回一个 ModelAndView（模型数据和逻辑视图名）；图中的 3、4、5 步骤； 3、 前端控制器收回控制权，然后根据返回的逻辑视图名，选择相应的视图进行渲染，并把模型数据传入以便视图渲染；图中的步骤 6、7； 4、 前端控制器再次收回控制权，将响应返回给用户，图中的步骤 8；至此整个结束。 核心流程 具体步骤： 第一步：发起请求到前端控制器(DispatcherServlet) 第二步：前端控制器请求HandlerMapping查找 Handler （可以根据xml配置、注解进行查找） 第三步：处理器映射器HandlerMapping向前端控制器返回Handler，HandlerMapping会把请求映射为HandlerExecutionChain对象（包含一个Handler处理器（页面控制器）对象，多个HandlerInterceptor拦截器对象），通过这种策略模式，很容易添加新的映射策略 第四步：前端控制器调用处理器适配器去执行Handler 第五步：处理器适配器HandlerAdapter将会根据适配的结果去执行Handler 第六步：Handler执行完成给适配器返回ModelAndView 第七步：处理器适配器向前端控制器返回ModelAndView （ModelAndView是springmvc框架的一个底层对象，包括 Model和view） 第八步：前端控制器请求视图解析器去进行视图解析 （根据逻辑视图名解析成真正的视图(jsp)），通过这种策略很容易更换其他视图技术，只需要更改视图解析器即可 第九步：视图解析器向前端控制器返回View 第十步：前端控制器进行视图渲染 （视图渲染将模型数据(在ModelAndView对象中)填充到request域） 第十一步：前端控制器向用户响应结果 总结 核心开发步骤1、 DispatcherServlet 在 web.xml 中的部署描述，从而拦截请求到 Spring Web MVC 2、 HandlerMapping 的配置，从而将请求映射到处理器 3、 HandlerAdapter 的配置，从而支持多种类型的处理器 注：处理器映射求和适配器使用纾解的话包含在了注解驱动中，不需要在单独配置 4、 ViewResolver 的配置，从而将逻辑视图名解析为具体视图技术 5、 处理器（页面控制器）的配置，从而进行功能处理 View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf…）]]></content>
      <categories>
        <category>SpringMVC</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AOP]]></title>
    <url>%2F2019%2F09%2F08%2FAOP%2F</url>
    <content type="text"><![CDATA[AOP简述AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 AOP技术恰恰相反，它利用一种称为”横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其命名为”Aspect”，即切面。所谓”切面”，简单说就是那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。 使用”横切”技术，AOP把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处基本相似，比如权限认证、日志、事物。AOP的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。 核心概念1、横切关注点 对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点 2、切面（aspect） 类是对物体特征的抽象，切面就是对横切关注点的抽象 3、连接点（joinpoint） 程序执行的某个特定位置（如：某个方法调用前、调用后，方法抛出异常后）。一个类或一段程序代码拥有一些具有边界性质的特定点，这些代码中的特定点就是连接点。Spring仅支持方法的连接点。 4、切入点（pointcut） 对连接点进行拦截的定义，如果连接点相当于数据中的记录，那么切点相当于查询条件，一个切点可以匹配多个连接点。Spring AOP的规则解析引擎负责解析切点所设定的查询条件，找到对应的连接点。 5、通知（advice） 所谓通知指的就是指拦截到连接点之后要执行的代码，通知分为前置、后置、异常、最终、环绕通知五类。Spring提供的增强接口都是带方位名的，如：BeforeAdvice、AfterReturningAdvice、ThrowsAdvice等。 6、目标对象 代理的目标对象 7、织入（weave） 织入是将增强添加到目标类具体连接点上的过程，AOP有三种织入方式：①编译期织入：需要特殊的Java编译期（例如AspectJ的ajc）；②装载期织入：要求使用特殊的类加载器，在装载类的时候对类进行增强；③运行时织入：在运行时为目标类生成代理实现增强。Spring采用了动态代理的方式实现了运行时织入，而AspectJ采用了编译期织入和装载期织入的方式。 8、引入（introduction） 在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法或字段、 9、引介（Introduction） 引介是一种特殊的增强，它为类添加一些属性和方法。这样，即使一个业务类原本没有实现某个接口，通过引介功能，可以动态的未该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。 原理AOP（Aspect Orient Programming），指面向方面（切面）编程，作为面向对象的一种补充，用于处理系统中分布于各个模块的横切关注点，比如事务管理、日志、缓存等等。AOP实现的关键在于AOP框架自动创建的AOP代理，AOP代理主要分为静态代理和动态代理，静态代理的代表为AspectJ；而动态代理则以Spring AOP为代表。通常使用AspectJ的编译时增强实现AOP，AspectJ是静态代理的增强，所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强。 Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。 如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。 Spring AOPSpring中AOP代理由Spring的IOC容器负责生成、管理，其依赖关系也由IOC容器负责管理。因此，AOP代理可以直接使用容器中的其它bean实例作为目标，这种关系可由IOC容器的依赖注入提供。Spring创建代理的规则为： 1、默认使用Java动态代理来创建AOP代理，这样就可以为任何接口实例创建代理了 2、当需要代理的类不是代理接口的时候，Spring会切换为使用CGLIB代理，也可强制使用CGLIB AOP编程其实是很简单的事情，纵观AOP编程，程序员只需要参与三个部分： 1、定义普通业务组件 2、定义切入点，一个切入点可能横切多个业务组件 3、定义增强处理，增强处理就是在AOP框架为普通业务组件织入的处理动作 所以进行AOP编程的关键就是定义切入点和定义增强处理，一旦定义了合适的切入点和增强处理，AOP框架将自动生成AOP代理，即：代理对象的方法=增强处理+被代理对象的方法。 强制使用CGLIB生成代理 前面说过Spring使用动态代理或是CGLIB生成代理是有规则的，高版本的Spring会自动选择是使用动态代理还是CGLIB生成代理内容，当然我们也可以强制使用CGLIB生成代理，那就是aop:config里面有一个”proxy-target-class”属性，这个属性值如果被设置为true，那么基于类的代理将起作用，如果proxy-target-class被设置为false或者这个属性被省略，那么基于接口的代理将起作用 AOP的应用场景Authentication 权限 ，Caching 缓存 ，Context passing 内容传递 ，Error handling 错误处理 ，Lazy loading 懒加载 ，Debugging 调试 ，logging, tracing, profiling and monitoring 记录跟踪 优化 校准，Performance optimization 性能优化 ，Persistence 持久化 ，Resource pooling 资源池 ，Synchronization 同步，Transactions 事务。]]></content>
      <categories>
        <category>AOP</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程之线程池]]></title>
    <url>%2F2019%2F09%2F08%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[多线程之线程池如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。 那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？ 所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。线程池顾名思义就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。 JAVA线程池类型1、newFixedThreadPool创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。 2、newCachedThreadPool创建一个可缓存的线程池。这种类型的线程池特点是：1).工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。2).如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。 3、newSingleThreadExecutor创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，如果这个线程异常结束，会有另一个取代它，保证顺序执行(我觉得这点是它的特色)。单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的 。 4、newScheduleThreadPool创建一个定长的线程池，而且支持定时的以及周期性的任务执行，类似于Timer。(这种线程池原理暂还没完全了解透彻) 线程池有什么优势第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能执行。 第三：提高线程的可管理性，线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。 Java中的ThreadPoolExecutor类java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下ThreadPoolExecutor类的具体实现源码。 在ThreadPoolExecutor类中提供了四个构造方法： public class ThreadPoolExecutor extends AbstractExecutorService { ..... public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); ... } 从上面的代码可以得知，ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。 下面解释下一下构造器中各个参数的含义： corePoolSize：核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程； keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性： TimeUnit.DAYS; //天 TimeUnit.HOURS; //小时 TimeUnit.MINUTES; //分钟 TimeUnit.SECONDS; //秒 TimeUnit.MILLISECONDS; //毫秒 TimeUnit.MICROSECONDS; //微妙 TimeUnit.NANOSECONDS; //纳秒 workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择： ArrayBlockingQueue; LinkedBlockingQueue; SynchronousQueue; ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。 threadFactory：线程工厂，主要用来创建线程； handler：表示当拒绝处理任务时的策略，有以下四种取值： ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 从上面给出的ThreadPoolExecutor类的代码可以知道，ThreadPoolExecutor继承了AbstractExecutorService，我们来看一下AbstractExecutorService的实现： public abstract class AbstractExecutorService implements ExecutorService { protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) { }; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) { }; public Future&lt;?&gt; submit(Runnable task) {}; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) { }; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) { }; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException { }; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException { }; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { }; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException { }; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException { }; } AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。 我们接着看ExecutorService接口的实现： public interface ExecutorService extends Executor { void shutdown(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; } 而ExecutorService又是继承了Executor接口，我们看一下Executor接口的实现： public interface Executor { void execute(Runnable command); } 到这里，大家应该明白了ThreadPoolExecutor、AbstractExecutorService、ExecutorService和Executor几个之间的关系了。 Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的； 然后ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等； 抽象类AbstractExecutorService实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法； 然后ThreadPoolExecutor继承了类AbstractExecutorService。 在ThreadPoolExecutor类中有几个非常重要的方法： execute() submit() shutdown() shutdownNow() execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果（Future相关内容将在下一篇讲述）。 shutdown()和shutdownNow()是用来关闭线程池的。 还有很多其他的方法： 比如：getQueue() 、getPoolSize() 、getActiveCount()、getCompletedTaskCount()等获取与线程池相关属性的方法，有兴趣的朋友可以自行查阅API。 深入剖析线程池实现原理在上面我们从宏观上介绍了ThreadPoolExecutor，下面我们来深入解析一下线程池的具体实现原理，将从下面几个方面讲解： 1.线程池状态 2.任务的执行 3.线程池中的线程初始化 4.任务缓存队列及排队策略 5.任务拒绝策略 6.线程池的关闭 7.线程池容量的动态调整 1.线程池状态在ThreadPoolExecutor中定义了一个volatile变量，另外定义了几个static final变量表示线程池的各个状态： volatile int runState; static final int RUNNING = 0; static final int SHUTDOWN = 1; static final int STOP = 2; static final int TERMINATED = 3; runState表示当前线程池的状态，它是一个volatile变量用来保证线程之间的可见性； 下面的几个static final变量表示runState可能的几个取值。 当创建线程池后，初始时，线程池处于RUNNING状态； 如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕； 如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务； 当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 2.任务的执行 在了解将任务提交给线程池到任务执行完毕整个过程之前，我们先来看一下ThreadPoolExecutor类中其他的一些比较重要成员变量： private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务 private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小 //、runState等）的改变都要使用这个锁 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作集 private volatile long keepAliveTime; //线程存活时间 private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间 private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列） private volatile int maximumPoolSize; //线程池最大能容忍的线程数 private volatile int poolSize; //线程池中当前的线程数 private volatile RejectedExecutionHandler handler; //任务拒绝策略 private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程 private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数 private long completedTaskCount; //用来记录已经执行完毕的任务个数 每个变量的作用都已经标明出来了，这里要重点解释一下corePoolSize、maximumPoolSize、largestPoolSize三个变量。 corePoolSize在很多地方被翻译成核心池大小，其实我的理解这个就是线程池的大小。举个简单的例子： 假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。 因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做； 当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待； 如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来； 然后就将任务也分配给这4个临时工人做； 如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。 当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。 这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。 也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。 不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。 largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系。 下面我们进入正题，看一下任务从提交到最终执行完毕经历了哪些过程。 在ThreadPoolExecutor类中，最核心的任务提交方法是execute()方法，虽然通过submit也可以提交任务，但是实际上submit方法里面最终调用的还是execute()方法，所以我们只需要研究execute()方法的实现原理即可： public void execute(Runnable command) { if (command == null) throw new NullPointerException(); if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) { if (runState == RUNNING &amp;&amp; workQueue.offer(command)) { if (runState != RUNNING || poolSize == 0) ensureQueuedTaskHandled(command); } else if (!addIfUnderMaximumPoolSize(command)) reject(command); // is shutdown or saturated } } 上面的代码可能看起来不是那么容易理解，下面我们一句一句解释： 首先，判断提交的任务command是否为null，若是null，则抛出空指针异常； 接着是这句，这句要好好理解一下： if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) 由于是或条件运算符，所以先计算前半部分的值，如果线程池中当前线程数不小于核心池大小，那么就会直接进入下面的if语句块了。 如果线程池中当前线程数小于核心池大小，则接着执行后半部分，也就是执行： addIfUnderCorePoolSize(command) 如果执行完addIfUnderCorePoolSize这个方法返回false，则继续执行下面的if语句块，否则整个方法就直接执行完毕了。 如果执行完addIfUnderCorePoolSize这个方法返回false，然后接着判断： if (runState == RUNNING &amp;&amp; workQueue.offer(command)) 如果当前线程池处于RUNNING状态，则将任务放入任务缓存队列；如果当前线程池不处于RUNNING状态或者任务放入缓存队列失败，则执行： addIfUnderMaximumPoolSize(command) 如果执行addIfUnderMaximumPoolSize方法失败，则执行reject()方法进行任务拒绝处理。 回到前面： if (runState == RUNNING &amp;&amp; workQueue.offer(command)) 这句的执行，如果说当前线程池处于RUNNING状态且将任务放入任务缓存队列成功，则继续进行判断： if (runState != RUNNING || poolSize == 0) 这句判断是为了防止在将此任务添加进任务缓存队列的同时其他线程突然调用shutdown或者shutdownNow方法关闭了线程池的一种应急措施。如果是这样就执行： ensureQueuedTaskHandled(command) 进行应急处理，从名字可以看出是保证 添加到任务缓存队列中的任务得到处理。 我们接着看2个关键方法的实现：addIfUnderCorePoolSize和addIfUnderMaximumPoolSize： private boolean addIfUnderCorePoolSize(Runnable firstTask) { Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { if (poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); //创建线程去执行firstTask任务 } finally { mainLock.unlock(); } if (t == null) return false; t.start(); return true; } 这个是addIfUnderCorePoolSize方法的具体实现，从名字可以看出它的意图就是当低于核心吃大小时执行的方法。下面看其具体实现，首先获取到锁，因为这地方涉及到线程池状态的变化，先通过if语句判断当前线程池中的线程数目是否小于核心池大小，有朋友也许会有疑问：前面在execute()方法中不是已经判断过了吗，只有线程池当前线程数目小于核心池大小才会执行addIfUnderCorePoolSize方法的，为何这地方还要继续判断？原因很简单，前面的判断过程中并没有加锁，因此可能在execute方法判断的时候poolSize小于corePoolSize，而判断完之后，在其他线程中又向线程池提交了任务，就可能导致poolSize不小于corePoolSize了，所以需要在这个地方继续判断。然后接着判断线程池的状态是否为RUNNING，原因也很简单，因为有可能在其他线程中调用了shutdown或者shutdownNow方法。然后就是执行 t = addThread(firstTask); 这个方法也非常关键，传进去的参数为提交的任务，返回值为Thread类型。然后接着在下面判断t是否为空，为空则表明创建线程失败（即poolSize&gt;=corePoolSize或者runState不等于RUNNING），否则调用t.start()方法启动线程。 我们来看一下addThread方法的实现： private Thread addThread(Runnable firstTask) { Worker w = new Worker(firstTask); Thread t = threadFactory.newThread(w); //创建一个线程，执行任务 if (t != null) { w.thread = t; //将创建的线程的引用赋值为w的成员变量 workers.add(w); int nt = ++poolSize; //当前线程数加1 if (nt &gt; largestPoolSize) largestPoolSize = nt; } return t; } 在addThread方法中，首先用提交的任务创建了一个Worker对象，然后调用线程工厂threadFactory创建了一个新的线程t，然后将线程t的引用赋值给了Worker对象的成员变量thread，接着通过workers.add(w)将Worker对象添加到工作集当中。 下面我们看一下Worker类的实现： private final class Worker implements Runnable { private final ReentrantLock runLock = new ReentrantLock(); private Runnable firstTask; volatile long completedTasks; Thread thread; Worker(Runnable firstTask) { this.firstTask = firstTask; } boolean isActive() { return runLock.isLocked(); } void interruptIfIdle() { final ReentrantLock runLock = this.runLock; if (runLock.tryLock()) { try { if (thread != Thread.currentThread()) thread.interrupt(); } finally { runLock.unlock(); } } } void interruptNow() { thread.interrupt(); } private void runTask(Runnable task) { final ReentrantLock runLock = this.runLock; runLock.lock(); try { if (runState &lt; STOP &amp;&amp; Thread.interrupted() &amp;&amp; runState &gt;= STOP) boolean ran = false; beforeExecute(thread, task); //beforeExecute方法是ThreadPoolExecutor类的一个方法，没有具体实现，用户可以根据 //自己需要重载这个方法和后面的afterExecute方法来进行一些统计信息，比如某个任务的执行时间等 try { task.run(); ran = true; afterExecute(task, null); ++completedTasks; } catch (RuntimeException ex) { if (!ran) afterExecute(task, ex); throw ex; } } finally { runLock.unlock(); } } public void run() { try { Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) { runTask(task); task = null; } } finally { workerDone(this); //当任务队列中没有任务时，进行清理工作 } } } 它实际上实现了Runnable接口，因此上面的Thread t = threadFactory.newThread(w);效果跟下面这句的效果基本一样： Thread t = new Thread(w); 相当于传进去了一个Runnable任务，在线程t中执行这个Runnable。 既然Worker实现了Runnable接口，那么自然最核心的方法便是run()方法了： public void run() { try { Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) { runTask(task); task = null; } } finally { workerDone(this); } } 从run方法的实现可以看出，它首先执行的是通过构造器传进来的任务firstTask，在调用runTask()执行完firstTask之后，在while循环里面不断通过getTask()去取新的任务来执行，那么去哪里取呢？自然是从任务缓存队列里面去取，getTask是ThreadPoolExecutor类中的方法，并不是Worker类中的方法，下面是getTask方法的实现： Runnable getTask() { for (;;) { try { int state = runState; if (state &gt; SHUTDOWN) return null; Runnable r; if (state == SHUTDOWN) // Help drain queue r = workQueue.poll(); else if (poolSize &gt; corePoolSize || allowCoreThreadTimeOut) //如果线程数大于核心池大小或者允许为核心池线程设置空闲时间， //则通过poll取任务，若等待一定的时间取不到任务，则返回null r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS); else r = workQueue.take(); if (r != null) return r; if (workerCanExit()) { //如果没取到任务，即r为null，则判断当前的worker是否可以退出 if (runState &gt;= SHUTDOWN) // Wake up others interruptIdleWorkers(); //中断处于空闲状态的worker return null; } // Else retry } catch (InterruptedException ie) { // On interruption, re-check runState } } } 在getTask中，先判断当前线程池状态，如果runState大于SHUTDOWN（即为STOP或者TERMINATED），则直接返回null。 如果runState为SHUTDOWN或者RUNNING，则从任务缓存队列取任务。 如果当前线程池的线程数大于核心池大小corePoolSize或者允许为核心池中的线程设置空闲存活时间，则调用poll(time,timeUnit)来取任务，这个方法会等待一定的时间，如果取不到任务就返回null。 然后判断取到的任务r是否为null，为null则通过调用workerCanExit()方法来判断当前worker是否可以退出，我们看一下workerCanExit()的实现： private boolean workerCanExit() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); boolean canExit; //如果runState大于等于STOP，或者任务缓存队列为空了 //或者 允许为核心池线程设置空闲存活时间并且线程池中的线程数目大于1 try { canExit = runState &gt;= STOP || workQueue.isEmpty() || (allowCoreThreadTimeOut &amp;&amp; poolSize &gt; Math.max(1, corePoolSize)); } finally { mainLock.unlock(); } return canExit; } 也就是说如果线程池处于STOP状态、或者任务队列已为空或者允许为核心池线程设置空闲存活时间并且线程数大于1时，允许worker退出。如果允许worker退出，则调用interruptIdleWorkers()中断处于空闲状态的worker，我们看一下interruptIdleWorkers()的实现： void interruptIdleWorkers() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) //实际上调用的是worker的interruptIfIdle()方法 w.interruptIfIdle(); } finally { mainLock.unlock(); } } 从实现可以看出，它实际上调用的是worker的interruptIfIdle()方法，在worker的interruptIfIdle()方法中： void interruptIfIdle() { final ReentrantLock runLock = this.runLock; if (runLock.tryLock()) { //注意这里，是调用tryLock()来获取锁的，因为如果当前worker正在执行任务，锁已经被获取了，是无法获取到锁的 //如果成功获取了锁，说明当前worker处于空闲状态 try { if (thread != Thread.currentThread()) thread.interrupt(); } finally { runLock.unlock(); } } } 这里有一个非常巧妙的设计方式，假如我们来设计线程池，可能会有一个任务分派线程，当发现有线程空闲时，就从任务缓存队列中取一个任务交给空闲线程执行。但是在这里，并没有采用这样的方式，因为这样会要额外地对任务分派线程进行管理，无形地会增加难度和复杂度，这里直接让执行完任务的线程去任务缓存队列里面取任务来执行。 我们再看addIfUnderMaximumPoolSize方法的实现，这个方法的实现思想和addIfUnderCorePoolSize方法的实现思想非常相似，唯一的区别在于addIfUnderMaximumPoolSize方法是在线程池中的线程数达到了核心池大小并且往任务队列中添加任务失败的情况下执行的： private boolean addIfUnderMaximumPoolSize(Runnable firstTask) { Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { if (poolSize &lt; maximumPoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); } finally { mainLock.unlock(); } if (t == null) return false; t.start(); return true; } 看到没有，其实它和addIfUnderCorePoolSize方法的实现基本一模一样，只是if语句判断条件中的poolSize &lt; maximumPoolSize不同而已。 到这里，大部分朋友应该对任务提交给线程池之后到被执行的整个过程有了一个基本的了解，下面总结一下： 1）首先，要清楚corePoolSize和maximumPoolSize的含义； 2）其次，要知道Worker是用来起到什么作用的； 3）要知道任务提交给线程池之后的处理策略，这里总结一下主要有4点： 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务； 如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务； 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理； 如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。 3.线程池中的线程初始化默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。 在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程； prestartAllCoreThreads()：初始化所有核心线程 下面是这2个方法的实现： public boolean prestartCoreThread() { return addIfUnderCorePoolSize(null); //注意传进去的参数是null } public int prestartAllCoreThreads() { int n = 0; while (addIfUnderCorePoolSize(null))//注意传进去的参数是null ++n; return n; } 注意上面传进去的参数是null，根据第2小节的分析可知如果传进去的参数为null，则最后执行线程会阻塞在getTask方法中的 r = workQueue.take(); 即等待任务队列中有任务。 4.任务缓存队列及排队策略在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。 workQueue的类型为BlockingQueue，通常可以取下面三种类型： 1）ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小； 2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE； 3）synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。 5.任务拒绝策略当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略： ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 6.线程池的关闭ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 7.线程池容量的动态调整ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()， setCorePoolSize：设置核心池大小setMaximumPoolSize：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构之各种树]]></title>
    <url>%2F2019%2F09%2F03%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%90%84%E7%A7%8D%E6%A0%91%2F</url>
    <content type="text"><![CDATA[数据结构之各种树数据结构中有很多树的结构，其中包括二叉树、二叉搜索树、2-3树、红黑树等等。本文中对数据结构中常见的几种树的概念和用途进行了汇总，不求严格精准，但求简单易懂。 二叉树二叉树是数据结构中一种重要的数据结构，也是树表家族最为基础的结构。 二叉树的定义：二叉树的每个结点至多只有二棵子树(不存在度大于2的结点)，二叉树的子树有左右之分，次序不能颠倒。二叉树的第i层至多有2^(i-1)个结点；深度为k的二叉树至多有2^(k-1)个结点；对任何一棵二叉树T，如果其终端结点数为n0，度为2的结点数为n2，则n0=n2+1。 二叉树示例： 满二叉树和完全二叉树满二叉树：除最后一层无任何子节点外，每一层上的所有结点都有两个子结点。也可以这样理解，除叶子结点外的所有结点均有两个子结点。节点数达到最大值，所有叶子结点必须在同一层上。 满二叉树的性质： 1) 一颗树深度为h，最大层数为k，深度与最大层数相同，k=h; 2) 叶子数为2^h; 3) 第k层的结点数是：2^(k-1); 4) 总结点数是：2^k-1，且总节点数一定是奇数。 完全二叉树：若设二叉树的深度为h，除第 h 层外，其它各层 (1～(h-1)层) 的结点数都达到最大个数，第h层所有的结点都连续集中在最左边，这就是完全二叉树。 注：完全二叉树是效率很高的数据结构，堆是一种完全二叉树或者近似完全二叉树，所以效率极高，像十分常用的排序算法、Dijkstra算法、Prim算法等都要用堆才能优化，二叉排序树的效率也要借助平衡性来提高，而平衡性基于完全二叉树。 二叉查找树二叉查找树定义：又称为是二叉排序树（Binary Sort Tree）或二叉搜索树。二叉排序树或者是一棵空树，或者是具有下列性质的二叉树： 1) 若左子树不空，则左子树上所有结点的值均小于它的根结点的值； 2) 若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值； 3) 左、右子树也分别为二叉排序树； 4) 没有键值相等的节点。 二叉查找树的性质：对二叉查找树进行中序遍历，即可得到有序的数列。 二叉查找树的时间复杂度：它和二分查找一样，插入和查找的时间复杂度均为O(logn)，但是在最坏的情况下仍然会有O(n)的时间复杂度。原因在于插入和删除元素的时候，树没有保持平衡（比如，我们查找上图（b）中的“93”，我们需要进行n次查找操作）。我们追求的是在最坏的情况下仍然有较好的时间复杂度，这就是平衡查找树设计的初衷。 二叉查找树的高度决定了二叉查找树的查找效率。二叉查找树的插入过程如下： 1) 若当前的二叉查找树为空，则插入的元素为根节点; 2) 若插入的元素值小于根节点值，则将元素插入到左子树中; 3) 若插入的元素值不小于根节点值，则将元素插入到右子树中。 二叉查找树的删除，分三种情况进行处理： 1) p为叶子节点，直接删除该节点，再修改其父节点的指针（注意分是根节点和不是根节点），如图a; 2) p为单支节点（即只有左子树或右子树）。让p的子树与p的父亲节点相连，删除p即可（注意分是根节点和不是根节点），如图b; 3) p的左子树和右子树均不空。找到p的后继y，因为y一定没有左子树，所以可以删除y，并让y的父亲节点成为y的右子树的父亲节点，并用y的值代替p的值；或者方法二是找到p的前驱x，x一定没有右子树，所以可以删除x，并让x的父亲节点成为y的左子树的父亲节点。如图c。 平衡二叉树我们知道，对于一般的二叉搜索树（Binary Search Tree），其期望高度（即为一棵平衡树时）为log2n，其各操作的时间复杂度O(log2n)同时也由此而决定。但是，在某些极端的情况下（如在插入的序列是有序的时），二叉搜索树将退化成近似链或链，此时，其操作的时间复杂度将退化成线性的，即O(n)。我们可以通过随机化建立二叉搜索树来尽量的避免这种情况，但是在进行了多次的操作之后，由于在删除时，我们总是选择将待删除节点的后继代替它本身，这样就会造成总是右边的节点数目减少，以至于树向左偏沉。这同时也会造成树的平衡性受到破坏，提高它的操作的时间复杂度。于是就有了我们下边介绍的平衡二叉树。 平衡二叉树定义：平衡二叉树（Balanced Binary Tree）又被称为AVL树（有别于AVL算法），且具有以下性质： 它是一 棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用算法有红黑树、AVL树等。在平衡二叉搜索树中，我们可以看到，其高度一般都良好地维持在O(log2n)，大大降低了操作的时间复杂度。 最小二叉平衡树的节点的公式如下： F(n)=F(n-1)+F(n-2)+1 这个类似于一个递归的数列，可以参考Fibonacci数列，1是根节点，F(n-1)是左子树的节点数量，F(n-2)是右子树的节点数量。 平衡查找树之AVL树AVL树定义：AVL树是最先发明的自平衡二叉查找树。AVL树得名于它的发明者 G.M. Adelson-Velsky 和 E.M. Landis，他们在 1962 年的论文 “An algorithm for the organization of information” 中发表了它。在AVL中任何节点的两个儿子子树的高度最大差别为1，所以它也被称为高度平衡树，n个结点的AVL树最大深度约1.44log2n。查找、插入和删除在平均和最坏情况下都是O(logn)。增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。这个方案很好的解决了二叉查找树退化成链表的问题，把插入，查找，删除的时间复杂度最好情况和最坏情况都维持在O(logN)。但是频繁旋转会使插入和删除牺牲掉O(logN)左右的时间，不过相对二叉查找树来说，时间上稳定了很多。 AVL树的自平衡操作——旋转： AVL树最关键的也是最难的一步操作就是旋转。旋转主要是为了实现AVL树在实施了插入和删除操作以后，树重新回到平衡的方法。下面我们重点研究一下AVL树的旋转。 对于一个平衡的节点，由于任意节点最多有两个儿子，因此高度不平衡时，此节点的两颗子树的高度差2.容易看出，这种不平衡出现在下面四种情况： 1) 6节点的左子树3节点高度比右子树7节点大2，左子树3节点的左子树1节点高度大于右子树4节点，这种情况成为左左。 2) 6节点的左子树2节点高度比右子树7节点大2，左子树2节点的左子树1节点高度小于右子树4节点，这种情况成为左右。 3) 2节点的左子树1节点高度比右子树5节点小2，右子树5节点的左子树3节点高度大于右子树6节点，这种情况成为右左。 4) 2节点的左子树1节点高度比右子树4节点小2，右子树4节点的左子树3节点高度小于右子树6节点，这种情况成为右右。 从图2中可以可以看出，1和4两种情况是对称的，这两种情况的旋转算法是一致的，只需要经过一次旋转就可以达到目标，我们称之为单旋转。2和3两种情况也是对称的，这两种情况的旋转算法也是一致的，需要进行两次旋转，我们称之为双旋转。 单旋转单旋转是针对于左左和右右这两种情况的解决方案，这两种情况是对称的，只要解决了左左这种情况，右右就很好办了。图3是左左情况的解决方案，节点k2不满足平衡特性，因为它的左子树k1比右子树Z深2层，而且k1子树中，更深的一层的是k1的左子树X子树，所以属于左左情况。 为使树恢复平衡，我们把k1变成这棵树的根节点，因为k2大于k1，把k2置于k1的右子树上，而原本在k1右子树的Y大于k1，小于k2，就把Y置于k2的左子树上，这样既满足了二叉查找树的性质，又满足了平衡二叉树的性质。 这样的操作只需要一部分指针改变，结果我们得到另外一颗二叉查找树，它是一棵AVL树，因为X向上一移动了一层，Y还停留在原来的层面上，Z向下移动了一层。整棵树的新高度和之前没有在左子树上插入的高度相同，插入操作使得X高度长高了。因此，由于这颗子树高度没有变化，所以通往根节点的路径就不需要继续旋转了。 双旋转对于左右和右左这两种情况，单旋转不能使它达到一个平衡状态，要经过两次旋转。双旋转是针对于这两种情况的解决方案，同样的，这样两种情况也是对称的，只要解决了左右这种情况，右左就很好办了。图4是左右情况的解决方案，节点k3不满足平衡特性，因为它的左子树k1比右子树D深2层，而且k1子树中，更深的一层的是k1的右子树k2子树，所以属于左右情况。 为使树恢复平衡，我们需要进行两步，第一步，把k1作为根，进行一次右右旋转，旋转之后就变成了左左情况，所以第二步再进行一次左左旋转，最后得到了一棵以k2为根的平衡二叉树。 平衡二叉树之红黑树红黑树的定义：红黑树是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。它是在1972年由鲁道夫·贝尔发明的，称之为”对称二叉B树”，它现代的名字是在 Leo J. Guibas 和 Robert Sedgewick 于1978年写的一篇论文中获得的。它是复杂的，但它的操作有着良好的最坏情况运行时间，并且在实践中是高效的: 它可以在O(logn)时间内做查找，插入和删除，这里的n是树中元素的数目。 红黑树和AVL树一样都对插入时间、删除时间和查找时间提供了最好可能的最坏情况担保。这不只是使它们在时间敏感的应用如实时应用（real time application）中有价值，而且使它们有在提供最坏情况担保的其他数据结构中作为建造板块的价值；例如，在计算几何中使用的很多数据结构都可以基于红黑树。此外，红黑树还是2-3-4树的一种等同，它们的思想是一样的，只不过红黑树是2-3-4树用二叉树的形式表示的。 红黑树的性质： 红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制的一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求: 性质1. 节点是红色或黑色。 性质2. 根是黑色。 性质3. 所有叶子都是黑色（叶子是NIL节点）。 性质4. 每个红色节点必须有两个黑色的子节点。(从每个叶子到根的所有路径上不能有两个连续的红色节点。) 性质5. 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 下面是一个具体的红黑树的图例： 这些约束确保了红黑树的关键特性: 从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限允许红黑树在最坏情况下都是高效的，而不同于普通的二叉查找树。 要知道为什么这些性质确保了这个结果，注意到性质4导致了路径不能有两个毗连的红色节点就足够了。最短的可能路径都是黑色节点，最长的可能路径有交替的红色和黑色节点。因为根据性质5所有最长的路径都有相同数目的黑色节点，这就表明了没有路径能多于任何其他路径的两倍长。 B树B树也是一种用于查找的平衡树，但是它不是二叉树。 B树的定义：B树（B-tree）是一种树状数据结构，能够用来存储排序后的数据。这种数据结构能够让查找数据、循序存取、插入数据及删除的动作，都在对数时间内完成。B树，概括来说是一个一般化的二叉查找树，可以拥有多于2个子节点。与自平衡二叉查找树不同，B-树为系统最优化大块数据的读和写操作。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。这种数据结构常被应用在数据库和文件系统的实作上。 在B树中查找给定关键字的方法是，首先把根结点取来，在根结点所包含的关键字K1,…,Kn查找给定的关键字（可用顺序查找或二分查找法），若找到等于给定值的关键字，则查找成功；否则，一定可以确定要查找的关键字在Ki与Ki+1之间，Pi为指向子树根节点的指针，此时取指针Pi所指的结点继续查找，直至找到，或指针Pi为空时查找失败。 B树作为一种多路搜索树（并不是二叉的）： 1) 定义任意非叶子结点最多只有M个儿子；且M&gt;2； 2) 根结点的儿子数为[2, M]； 3) 除根结点以外的非叶子结点的儿子数为[M/2, M]； 4) 每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字） 5) 非叶子结点的关键字个数=指向儿子的指针个数-1； 6) 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]； 7) 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 8) 所有叶子结点位于同一层； 如下图为一个M=3的B树示例： B+树B+树是B树的变体，也是一种多路搜索树： 1) 其定义基本与B-树相同，除了： 2) 非叶子结点的子树指针与关键字个数相同； 3) 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）； 4) 为所有叶子结点增加一个链指针； 5) 所有关键字都在叶子结点出现； B+树的搜索与B树也基本相同，区别是B+树只有达到叶子结点才命中（B树可以在非叶子结点命中），其性能也等价于在关键字全集做一次二分查找； B+的性质： 1.所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的； 2.不可能在非叶子结点命中； 3.非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层； 4.更适合文件索引系统。 下面为一个B+树创建的示意图： B*树B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针，将结点的最低利用率从1/2提高到2/3。 B树定义了非叶子结点关键字个数至少为(2/3)M，即块的最低使用率为2/3（代替B+树的1/2）； B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针； B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针； 所以，B*树分配新结点的概率比B+树要低，空间使用率更高。 Trie树Tire树称为字典树，又称单词查找树，Trie树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。 Tire树的三个基本性质： 1) 根节点不包含字符，除根节点外每一个节点都只包含一个字符； 2) 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串； 3) 每个节点的所有子节点包含的字符都不相同。 Tire树的应用： 1) 串的快速检索 给出N个单词组成的熟词表，以及一篇全用小写英文书写的文章，请你按最早出现的顺序写出所有不在熟词表中的生词。 在这道题中，我们可以用数组枚举，用哈希，用字典树，先把熟词建一棵树，然后读入文章进行比较，这种方法效率是比较高的。 2) “串”排序 给定N个互不相同的仅由一个单词构成的英文名，让你将他们按字典序从小到大输出。用字典树进行排序，采用数组的方式创建字典树，这棵树的每个结点的所有儿子很显然地按照其字母大小排序。对这棵树进行先序遍历即可。 3) 最长公共前缀 对所有串建立字典树，对于两个串的最长公共前缀的长度即他们所在的结点的公共祖先个数，于是，问题就转化为求公共祖先的问题。]]></content>
      <categories>
        <category>数据结构</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>tag 数据结构</tag>
        <tag>tag 树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM堆内存参数设置]]></title>
    <url>%2F2019%2F09%2F03%2FJVM%E5%A0%86%E5%86%85%E5%AD%98%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[JVM堆内存参数设置堆内存设置原理JVM堆内存分为2块： Permanent Space 和 Heap Space。 Permanent 即 持久代（Permanent Generation），主要存放的是Java类定义信息，与垃圾收集器要收集的Java对象关系不大。 Heap = { Old + NEW = {Eden, from, to} }，Old 即 年老代（Old Generation），New 即 年轻代（Young Generation）。年老代和年轻代的划分对垃圾收集影响比较大。 年轻代所有新生成的对象首先都是放在年轻代。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。年轻代一般分3个区，1个Eden区，2个Survivor区（from 和 to）。 大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当一个Survivor区满时，此区的存活对象将被复制到另外一个Survivor区，当另一个Survivor区也满了的时候，从前一个Survivor区复制过来的并且此时还存活的对象，将可能被复制到年老代。 2个Survivor区是对称的，没有先后关系，所以同一个Survivor区中可能同时存在从Eden区复制过来对象，和从另一个Survivor区复制过来的对象；而复制到年老区的只有从另一个Survivor区过来的对象。而且，因为需要交换的原因，Survivor区至少有一个是空的。特殊的情况下，根据程序需要，Survivor区是可以配置为多个的（多于2个），这样可以增加对象在年轻代中的存在时间，减少被放到年老代的可能。 针对年轻代的垃圾回收即 Young GC。 年老代在年轻代中经历了N次（可配置）垃圾回收后仍然存活的对象，就会被复制到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 针对年老代的垃圾回收即 Full GC。 持久代用于存放静态类型数据，如 Java Class, Method 等。持久代对垃圾回收没有显著影响。但是有些应用可能动态生成或调用一些Class，例如 Hibernate CGLib 等，在这种时候往往需要设置一个比较大的持久代空间来存放这些运行过程中动态增加的类型。 内存申请过程所以，当一组对象生成时，内存申请过程如下： 1、JVM会试图为相关Java对象在年轻代的Eden区中初始化一块内存区域。 2、当Eden区空间足够时，内存申请结束。否则执行下一步。 3、JVM试图释放在Eden区中所有不活跃的对象（Young GC）。释放后若Eden空间仍然不足以放入新对象，JVM则试图将部分Eden区中活跃对象放入Survivor区。 4、Survivor区被用来作为Eden区及年老代的中间交换区域。当年老代空间足够时，Survivor区中存活了一定次数的对象会被移到年老代。 5、当年老代空间不够时，JVM会在年老代进行完全的垃圾回收（Full GC）。 6、 Full GC后，若Survivor区及年老代仍然无法存放从Eden区复制过来的对象，则会导致JVM无法在Eden区为新生成的对象申请内存，即出现“Out of Memory”。 OOM（“Out of Memory”）异常原因OOM（“Out of Memory”）异常一般主要有如下2种原因： 年老代溢出，表现为：java.lang.OutOfMemoryError:Javaheapspace这是最常见的情况，产生的原因可能是：设置的内存参数Xmx过小或程序的内存泄露及使用不当问题。例如循环上万次的字符串处理、创建上千万个对象、在一段代码内申请上百M甚至上G的内存。还有的时候虽然不会报内存溢出，却会使系统不间断的垃圾回收，也无法处理其它请求。这种情况下除了检查程序、打印堆内存等方法排查，还可以借助一些内存分析工具，比如MAT就很不错。 持久代溢出，表现为：java.lang.OutOfMemoryError:PermGenspace通常由于持久代设置过小，动态加载了大量Java类而导致溢出，解决办法唯有将参数 -XX:MaxPermSize 调大（一般256m能满足绝大多数应用程序需求）。将部分Java类放到容器共享区（例如Tomcat share lib）去加载的办法也是一个思路，但前提是容器里部署了多个应用，且这些应用有大量的共享类库。 参数说明-Xmx3550m：设置JVM最大堆内存为3550M。 -Xms3550m：设置JVM初始堆内存为3550M。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 -Xss128k：设置每个线程的栈大小。JDK5.0以后每个线程栈大小为1M，之前每个线程栈大小为256K。应当根据应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。需要注意的是：当这个值被设置的较大（例如&gt;2MB）时将会在很大程度上降低系统的性能。 -Xmn2g：设置年轻代大小为2G。在整个堆内存大小确定的情况下，增大年轻代将会减小年老代，反之亦然。此值关系到JVM垃圾回收，对系统性能影响较大，官方推荐配置为整个堆大小的3/8。 -XX:NewSize=1024m：设置年轻代初始值为1024M。 -XX:MaxNewSize=1024m：设置年轻代最大值为1024M。 -XX:PermSize=256m：设置持久代初始值为256M。 -XX:MaxPermSize=256m：设置持久代最大值为256M。 -XX:NewRatio=4：设置年轻代（包括1个Eden和2个Survivor区）与年老代的比值。表示年轻代比年老代为1:4。 -XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的比值。表示2个Survivor区（JVM堆内存年轻代中默认有2个大小相等的Survivor区）与1个Eden区的比值为2:4，即1个Survivor区占整个年轻代大小的1/6。 -XX:MaxTenuringThreshold=7：表示一个对象如果在Survivor区（救助空间）移动了7次还没有被垃圾回收就进入年老代。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代，对于需要大量常驻内存的应用，这样做可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象在年轻代存活时间，增加对象在年轻代被垃圾回收的概率，减少Full GC的频率，这样做可以在某种程度上提高服务稳定性。 疑问解答-Xmn，-XX:NewSize/-XX:MaxNewSize，-XX:NewRatio 3组参数都可以影响年轻代的大小，混合使用的情况下，优先级是什么？ 如下： 高优先级：-XX:NewSize/-XX:MaxNewSize 中优先级：-Xmn（默认等效 -Xmn=-XX:NewSize=-XX:MaxNewSize=?） 低优先级：-XX:NewRatio 推荐使用-Xmn参数，原因是这个参数简洁，相当于一次设定 NewSize/MaxNewSIze，而且两者相等，适用于生产环境。-Xmn 配合 -Xms/-Xmx，即可将堆内存布局完成。 -Xmn参数是在JDK 1.4 开始支持。 垃圾回收器选择JVM给出了3种选择：串行收集器、并行收集器、并发收集器。串行收集器只适用于小数据量的情况，所以生产环境的选择主要是并行收集器和并发收集器。 默认情况下JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行智能判断。 串行收集器-XX:+UseSerialGC：设置串行收集器。 并行收集器（吞吐量优先）-XX:+UseParallelGC：设置为并行收集器。此配置仅对年轻代有效。即年轻代使用并行收集，而年老代仍使用串行收集。 -XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时有多少个线程一起进行垃圾回收。此值建议配置与CPU数目相等。 -XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0开始支持对年老代并行收集。 -XX:MaxGCPauseMillis=100：设置每次年轻代垃圾回收的最长时间（单位毫秒）。如果无法满足此时间，JVM会自动调整年轻代大小，以满足此时间。 -XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动调整年轻代Eden区大小和Survivor区大小的比例，以达成目标系统规定的最低响应时间或者收集频率等指标。此参数建议在使用并行收集器时，一直打开。 并发收集器（响应时间优先）-XX:+UseConcMarkSweepGC：即CMS收集，设置年老代为并发收集。CMS收集是JDK1.4后期版本开始引入的新GC算法。它的主要适合场景是对响应时间的重要性需求大于对吞吐量的需求，能够承受垃圾回收线程和应用线程共享CPU资源，并且应用中存在比较多的长生命周期对象。CMS收集的目标是尽量减少应用的暂停时间，减少Full GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存。 -XX:+UseParNewGC：设置年轻代为并发收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此参数。 -XX:CMSFullGCsBeforeCompaction=0：由于并发收集器不对内存空间进行压缩和整理，所以运行一段时间并行收集以后会产生内存碎片，内存使用效率降低。此参数设置运行0次Full GC后对内存空间进行压缩和整理，即每次Full GC后立刻开始压缩和整理内存。 -XX:+UseCMSCompactAtFullCollection：打开内存空间的压缩和整理，在Full GC后执行。可能会影响性能，但可以消除内存碎片。 -XX:+CMSIncrementalMode：设置为增量收集模式。一般适用于单CPU情况。 -XX:CMSInitiatingOccupancyFraction=70：表示年老代内存空间使用到70%时就开始执行CMS收集，以确保年老代有足够的空间接纳来自年轻代的对象，避免Full GC的发生。 其它垃圾回收参数-XX:+ScavengeBeforeFullGC：年轻代GC优于Full GC执行。 -XX:-DisableExplicitGC：不响应 System.gc() 代码。 -XX:+UseThreadPriorities：启用本地线程优先级API。即使 java.lang.Thread.setPriority() 生效，不启用则无效。 -XX:SoftRefLRUPolicyMSPerMB=0：软引用对象在最后一次被访问后能存活0毫秒（JVM默认为1000毫秒）。 -XX:TargetSurvivorRatio=90：允许90%的Survivor区被占用（JVM默认为50%）。提高对于Survivor区的使用率。 辅助信息参数设置-XX:-CITime：打印消耗在JIT编译的时间。 -XX:ErrorFile=./hs_err_pid.log：保存错误日志或数据到指定文件中。 -XX:HeapDumpPath=./java_pid.hprof：指定Dump堆内存时的路径。 -XX:-HeapDumpOnOutOfMemoryError：当首次遭遇内存溢出时Dump出此时的堆内存。 -XX:OnError=”;”：出现致命ERROR后运行自定义命令。 -XX:OnOutOfMemoryError=”;”：当首次遭遇内存溢出时执行自定义命令。-XX:-PrintClassHistogram：按下 Ctrl+Break 后打印堆内存中类实例的柱状信息，同JDK的 jmap -histo 命令。 -XX:-PrintConcurrentLocks：按下 Ctrl+Break 后打印线程栈中并发锁的相关信息，同JDK的 jstack -l 命令。 -XX:-PrintCompilation：当一个方法被编译时打印相关信息。-XX:-PrintGC：每次GC时打印相关信息。 -XX:-PrintGCDetails：每次GC时打印详细信息。 -XX:-PrintGCTimeStamps：打印每次GC的时间戳。 -XX:-TraceClassLoading：跟踪类的加载信息。 -XX:-TraceClassLoadingPreorder：跟踪被引用到的所有类的加载信息。-XX:-TraceClassResolution：跟踪常量池。 -XX:-TraceClassUnloading：跟踪类的卸载信息。 关于参数名称等标准参数（-），所有JVM都必须支持这些参数的功能，而且向后兼容；例如： -client——设置JVM使用Client模式，特点是启动速度比较快，但运行时性能和内存管理效率不高，通常用于客户端应用程序或开发调试；在32位环境下直接运行Java程序默认启用该模式。 -server——设置JVM使Server模式，特点是启动速度比较慢，但运行时性能和内存管理效率很高，适用于生产环境。在具有64位能力的JDK环境下默认启用该模式。 非标准参数（-X），默认JVM实现这些参数的功能，但是并不保证所有JVM实现都满足，且不保证向后兼容； 非稳定参数（-XX），此类参数各个JVM实现会有所不同，将来可能会不被支持，需要慎重使用； JVM服务参数调优实战大型网站服务器案例承受海量访问的动态Web应用 服务器配置：8 CPU, 8G MEM, JDK 1.6.X 参数方案： -server -Xmx3550m -Xms3550m -Xmn1256m -Xss128k -XX:SurvivorRatio=6 -XX:MaxPermSize=256m -XX:ParallelGCThreads=8 -XX:MaxTenuringThreshold=0 -XX:+UseConcMarkSweepGC 调优说明： -Xmx 与 -Xms 相同以避免JVM反复重新申请内存。-Xmx 的大小约等于系统内存大小的一半，即充分利用系统资源，又给予系统安全运行的空间。-Xmn1256m 设置年轻代大小为1256MB。此值对系统性能影响较大，Sun官方推荐配置年轻代大小为整个堆的3/8。 -Xss128k 设置较小的线程栈以支持创建更多的线程，支持海量访问，并提升系统性能。 -XX:SurvivorRatio=6 设置年轻代中Eden区与Survivor区的比值。系统默认是8，根据经验设置为6，则2个Survivor区与1个Eden区的比值为2:6，一个Survivor区占整个年轻代的1/8。 -XX:ParallelGCThreads=8 配置并行收集器的线程数，即同时8个线程一起进行垃圾回收。此值一般配置为与CPU数目相等。 -XX:MaxTenuringThreshold=0 设置垃圾最大年龄（在年轻代的存活次数）。如果设置为0的话，则年轻代对象不经过Survivor区直接进入年老代。对于年老代比较多的应用，可以提高效率；如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概率。根据被海量访问的动态Web应用之特点，其内存要么被缓存起来以减少直接访问DB，要么被快速回收以支持高并发海量请求，因此其内存对象在年轻代存活多次意义不大，可以直接进入年老代，根据实际应用效果，在这里设置此值为0。 -XX:+UseConcMarkSweepGC 设置年老代为并发收集。CMS（ConcMarkSweepGC）收集的目标是尽量减少应用的暂停时间，减少Full GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存，适用于应用中存在比较多的长生命周期对象的情况。 内部集成构建服务器案例高性能数据处理的工具应用 服务器配置：1 CPU, 4G MEM, JDK 1.6.X 参数方案： -server -XX:PermSize=196m -XX:MaxPermSize=196m -Xmn320m -Xms768m -Xmx1024m 调优说明： -XX:PermSize=196m -XX:MaxPermSize=196m 根据集成构建的特点，大规模的系统编译可能需要加载大量的Java类到内存中，所以预先分配好大量的持久代内存是高效和必要的。 -Xmn320m 遵循年轻代大小为整个堆的3/8原则。 -Xms768m -Xmx1024m 根据系统大致能够承受的堆内存大小设置即可。 在64位服务器上运行应用程序，构建执行时，用 jmap -heap 11540 命令观察JVM堆内存状况如下： Attaching to process ID 11540, please wait... Debugger attached successfully. Server compiler detected. JVM version is 20.12-b01 using thread-local object allocation. Parallel GC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 1073741824 (1024.0MB) NewSize = 335544320 (320.0MB) MaxNewSize = 335544320 (320.0MB) OldSize = 5439488 (5.1875MB) NewRatio = 2 SurvivorRatio = 8 PermSize = 205520896 (196.0MB) MaxPermSize = 205520896 (196.0MB) Heap Usage: PS Young Generation Eden Space: capacity = 255852544 (244.0MB) used = 101395504 (96.69828796386719MB) free = 154457040 (147.3017120361328MB) 39.63044588683081% used From Space: capacity = 34144256 (32.5625MB) used = 33993968 (32.41917419433594MB) free = 150288 (0.1433258056640625MB) 99.55984397492803% used To Space: capacity = 39845888 (38.0MB) used = 0 (0.0MB) free = 39845888 (38.0MB) 0.0% used PS Old Generation capacity = 469762048 (448.0MB) used = 44347696 (42.29325866699219MB) free = 425414352 (405.7067413330078MB) 9.440459523882184% used PS Perm Generation capacity = 205520896 (196.0MB) used = 85169496 (81.22396087646484MB) free = 120351400 (114.77603912353516MB) 41.440796365543285% used 结果是比较健康的。]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库的依赖以及范式]]></title>
    <url>%2F2019%2F08%2F24%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%BE%9D%E8%B5%96%E4%BB%A5%E5%8F%8A%E8%8C%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[数据库的依赖以及范式三种依赖1.部分依赖设X,Y是关系R的两个属性集合，存在X→Y，若X’是X的真子集，存在X’→Y，则称Y部分函数依赖于X。 举个例子：通过AB能得出C，通过A也能得出C，通过B也能得出C，那么说C部分依赖于AB。 2.完全依赖设X,Y是关系R的两个属性集合，X’是X的真子集，存在X→Y，但对每一个X’都有X’!→Y，则称Y完全函数依赖于X。 举个例子：通过AB能得出C，但是AB单独得不出C，那么说C完全依赖于AB. 3.传递依赖设X,Y,Z是关系R中互不相同的属性集合，存在X→Y(Y !→X),Y→Z，则称Z传递函数依赖于X。 举个例子：通过A得到B，通过B得到C，但是C得不到B，B得不到A，那么成C传递依赖于A 5种范式第一范式（1NF）在任何一个关系数据库中，第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库。所谓第一范式（1NF）是指数据库表的每一列(即每个属性)都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。简而言之，第一范式就是无重复的列。 每个关系r的属性值为不可分的原子值 当赵同学有两个手机号时，他不能将两个手机号存储在一个属性框中，需要分开存放，如下表所示。 错误 正确一 正确二 第二范式（2NF）第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。第二范式（2NF）要求数据库表中的每个实例或行必须可以被唯一地区分。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。员工信息表中加上了员工编号（emp_id）列，因为每个员工的员工编号是唯一的，因此每个员工可以被唯一区分。这个唯一属性列被称为主关键字或主键、主码。 第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。简而言之，第二范式就是非主属性依赖于主关键字。 满足1NF，非主属性完全函数依赖于候选键(左部不可约) 若一张表的数据包括：“学号、姓名、课程号、授课老师”中，设“学号、课程号”为主键，其中，一门课程可以有多个老师进行授课。会存在如下关系： (学号、课程号)→姓名 学号→姓名 ---------为局部依赖，即候选键的一部分可以推出非主属性系名 可分解为两个表，达到完全依赖：“学号、姓名”与“学号、课程号、授课老师” 第三范式（3NF）满足第三范式（3NF）必须先满足第二范式（2NF）。在满足第二范式的基础上，切不存在传递函数依赖，那么就是第三范式。简而言之，第三范式就是属性不依赖于其它非主属性。 满足2NF，消除非主属性对候选键的传递依赖 若一张表的数据包括：“学号、系名、系主任”，其中“学号”为主键，存在如下关系： 学号→系名→系主任 学号→系主任 ---------为传递依赖 同样可分解为两张表：“学号、系名”和“系名、系主任” 对于第三范式，我们反过来理解也是可以的，在表1（学号、系名），表2（系名、系主任）中，学号和系名都是各自表中的主键，所以系名依赖于学号，系主任依赖于系名。当三个数据放置在一张表中时，学号是可以推出系主任的。你可以理解为通过看学生张小二的学号，是可以推理出他的系主任是谁的。 BCNF满足3NF，消除每一属性对候选键的传递依赖 若一张表的数据包括：“书号、书名、作者”其中，书号是唯一的，书名允许相同，一个书号对应一本书。一本书的作者可以多个，但是同一个作者所参与编著的书名应该是不同，希望没有说晕，看图看图。 存在关系： 书号→书名 (书名、作者)→书号 其中，每一个属性都为主属性，但是上述关系存在传递依赖，不能是BCNF。即： (书名、作者)→书号→书名 (书名、作者)→书名 我们可以通过分解为两张表，实现BCNF。 4NF非形式说：只要两个独立的1：N联系出现在一个关系中，那么就可能出现多只依赖。举例说明。 一个表中存在三个数据：“课程、学生、先修课”。假设2017级的计算机专业学生想要学习JAVA课程，那么他们需要先学习VB、C#、BS三门课，才可以选择进行JAVA课程。存在关系： 课程→学生 课程→先修课 两个均是1：N的关系，当出现在一张表的时候，会出现大量的冗余。所以就我们需要分解它，减少冗余。(Ps：该例子主要是为了说明概念帮助理解，具体应用中不会只是这样的简单粗暴的。)]]></content>
      <categories>
        <category>数据库</category>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>tag 数据库依赖</tag>
        <tag>tag 数据库范式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库索引及查询优化]]></title>
    <url>%2F2019%2F08%2F23%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E5%8F%8A%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[数据库索引及查询优化索引的作用一般的应用系统，读写比例在10:1左右，而且插入操作和一般的更新操作很少出现性能问题，在生产环境中，我们遇到最多的，也是最容易出问题的，还是一些复杂的查询操作，因此对查询语句的优化显然是重中之重。说起加速查询，就不得不提到索引了。 索引在MySQL中也叫做“键”，是存储引擎用于快速找到记录的一种数据结构。索引对于良好的性能非常关键，尤其是当表中的数据量越来越大时，索引对于性能的影响愈发重要。 索引优化应该是对查询性能优化最有效的手段了。索引能够轻易将查询性能提高好几个数量级。索引相当于字典的音序表，如果要查某个字，如果不使用音序表，则需要从几百页中逐页去查。 索引原理索引原理目的 提高查询效率 本质 通过不断地缩小想要获取数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件， 有了这种索引机制，可以总是用同一种查找方式来锁定数据。 磁盘IO与预读磁盘IO和预读，磁盘读取数据靠的是机械运动，每次读取数据花费的时间可以分为寻道时间、旋转延迟、传输时间三个部分， 寻道时间 指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下； 旋转延迟 就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2 = 4.17ms； 传输时间 指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。 一次磁盘的时间，即一次磁盘IO的时间约等于5+4.17 = 9ms左右，听起来还挺不错的，但 一台500 -MIPS（Million Instructions Per Second）的机器每秒可以执行5亿条指令， 磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据而是把相邻的数据也都读取到内存缓冲区内，因为 局部预读性原理 告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，对索引的数据结构设计非常有帮助。 索引的数据结构任何一种数据结构都不是凭空产生的，一定会有它的背景和使用场景，要每次查找数据时把磁盘IO次数控制在一个很小的数量级， 最好是常数数量级。多路搜索树， b+树 应运而生。 索引 === 平衡树 —btree(树的平衡—高度) ====== 减少IO 磁盘块(数据项+指针) 磁盘块(数据项+指针) 磁盘块(数据项+指针) 真实的数据项 真实的数据项 真实的数据项 真实的数据项 真实的数据项 (叶子节点) 浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。 b+树的查找过程如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。 b+树性质索引字段要尽量的小：通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。 索引的最左匹配特性：当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 MySQL索引1 功能 索引的功能就是加速查找 mysql中的 primary key，unique，联合唯一也都是索引，这些索引除了加速查找以外，还有约束的功能 2 MySQL常用的索引 普通索引INDEX：加速查找 唯一索引： -主键索引PRIMARY KEY：加速查找+约束（不为空、不能重复） -唯一索引UNIQUE:加速查找+约束（不能重复） 联合索引： -PRIMARY KEY(id,name):联合主键索引 -UNIQUE(id,name):联合唯一索引 -INDEX(id,name):联合普通索引 3 索引的两大类型hash与btree 索引类型，分两类 hash类型的索引：查询单条快，范围查询慢 btree类型的索引：b+树，层数越多，数据量指数级增长（我们就用它，因为innodb默认支持它） 不同的存储引擎支持的索引类型也不一样 InnoDB 支持事务，支持行级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引； MyISAM 不支持事务，支持表级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引； Memory 不支持事务，支持表级别锁定，支持 B-tree、Hash 等索引，不支持 Full-text 索引； NDB 支持事务，支持行级别锁定，支持 Hash 索引，不支持 B-tree、Full-text 等索引； Archive 不支持事务，支持表级别锁定，不支持 B-tree、Hash、Full-text 等索引； 4 创建/删除索引的语法 1 ：创建表时 CREATE TABLE 表名 ( 字段名1 数据类型 [完整性约束条件…], 字段名2 数据类型 [完整性约束条件…], [UNIQUE | FULLTEXT | SPATIAL ] INDEX | KEY [索引名] (字段名[(长度)] [ASC |DESC]) ); 2 ： CREATE在已存在的表上创建索引 CREATE [UNIQUE | FULLTEXT | SPATIAL ] INDEX 索引名 ON 表名 (字段名[(长度)] [ASC |DESC]) ; 3 ：ALTER TABLE在已存在的表上创建索引 ALTER TABLE 表名 ADD [UNIQUE | FULLTEXT | SPATIAL ] INDEX 索引名 (字段名[(长度)] [ASC |DESC]) ; 删除索引：DROP INDEX 索引名 ON 表名字; 5 创建索引时需要注意： === 1 选择区分度高的字段作为 索引 字段 === 2 范围 ，条件不明确的 有索引 速度也会很慢 === 3 索引字段 不能 通过 *10 avg() 查询 === 4 最左前缀 --联合索引 (a,b,c,d) 重复性高的 字段( name ,gender )不要加索引 范围大的 索引 速度 会很慢 like &apos;%xx&apos; % 在左边 索引会很慢 要从头到尾先查询一遍 用 name, id 字段 作为 索引的 只能 用 本来的字段进行查询 (不能用 id*10, avg(id) 等来查询) and 左右条件 会先找 有索引的 查 or 会按顺序找 a,b,c,d ==== 联合索引 (a=1,b=1,d=2,c&gt;3) 范围放到最后---最左前缀匹配 select * from s1 where a=3,b=5,c&gt;3,d=6 (先找 区分度高的 索引) 一定是为搜索条件的字段创建索引，比如select * from s1 where id = 333; 就需要为id加上索引 在表中已经有大量数据的情况下，建索引会很慢，且占用硬盘空间，建完后查询速度加快比如create index idx on s1(id);会扫描表中所有的数据，然后以id为数据项，创建索引结构，存放于硬盘的表中。建完以后，再查询就会很快了。 innodb表的索引 会存放于s1.ibd文件中，而 myisam表的索引 则会有单独的索引文件table1.MYIinnodb 引擎 — frm + idb(数据+索引)myisam 引擎 —- frm + myd + myi (数据与索引分离)MySAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在innodb中，表数据文件本身就是按照B+Tree（BTree即Balance True）组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此innodb表数据文件本身就是主索引。 因为inndob的数据文件要按照主键聚集，所以innodb要求表必须要有主键（Myisam可以没有），如果没有显式定义，则mysql系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则mysql会自动为innodb表生成一个隐含字段作为主键，这字段的长度为6个字节，类型为长整型. 正确使用索引一 索引未命中 并不是说我们创建了索引就一定会加快查询速度，若想利用索引达到预想的提高查询速度的效果，我们在添加索引时，必须遵循以下问题 1 范围问题，或者说条件不明确，条件中出现这些符号或关键字：&gt;、&gt;=、&lt;、&lt;=、!= 、between…and…、like、 大于号、小于号 不等于！= between …and… like 2 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录 3 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 4 索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’) 5 and/or #注意：条件1 and 条件2:查询原理是：首先条件1与条件2都成立的前提下，才算匹配成功一条记录；其次mysql会按先优先判断索引字段的条件,如果按照该条件为真，但锁定的范围很小，或者干脆为假，那我们即便是没有为其他条件的字段添加索引，最终的结果仍然很快 #例如：若条件1的字段有索引，而条件2的字段没有索引，那么如果在按照条件1查出的结果很少的情况下，即便我们没有为条件2创建索引，最终的查询速度依然很快 若条件1的字段没有索引，而条件2的字段有索引，那么如果在按照条件2查出的结果很少的情况下，即便我们没有为条件1创建索引，最终的查询速度依然很快 在左边条件成立但是索引字段的区分度低的情况下（name与gender均属于这种情况），会依次往右找到一个区分度高的索引字段，加速查询 经过分析，在条件为name=’egon’ and gender=’male’ and id&gt;333 and email=’xxx’的情况下，我们完全没必要为前三个条件的字段加索引，因为只能用上email字段的索引，前三个字段的索引反而会降低我们的查询效率 6 最左前缀匹配原则，非常重要的原则，对于组合索引mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配(指的是范围大了，有索引速度也慢)，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 7 其他情况 复制代码 使用函数 select * from tb1 where reverse(email) = ‘egon’; 类型不一致 如果列是字符串类型，传入条件是必须用引号引起来，不然… select * from tb1 where email = 999; #排序条件为索引，则select字段必须也是索引字段，否则无法命中 order by select name from s1 order by email desc; 当根据索引排序时候，select查询的字段如果不是索引，则速度仍然很慢 select email from s1 order by email desc; 特别的：如果对主键排序，则还是速度很快： select * from tb1 order by nid desc; 组合索引最左前缀 如果组合索引为：(name,email) name and email – 命中索引 name – 命中索引 email – 未命中索引 count(1)或count(列)代替count(*)在mysql中没有差别了 create index xxxx on tb(title(19)) #text类型，必须制定长度 其他注意事项 避免使用select * count(1)或count(列) 代替 count(*) 创建表时尽量时 char 代替 varchar 表的字段顺序固定长度的字段优先 组合索引代替多个单列索引（经常使用多个条件查询时） 尽量使用短索引 使用连接（JOIN）来代替子查询(Sub-Queries) 连表时注意条件类型需一致 索引散列值（重复少）不适合建索引，例：性别不适合 覆盖索引与索引合并覆盖索引 所有字段（条件的，查询结果的等）都是索引字段 分析 select age from s1 where id=123 and name = ‘egon’; #id字段有索引，但是name字段没有索引 该sql命中了索引，但未覆盖全部。 利用id=123到索引的数据结构中定位到了id字段，但是仍要判断name字段，但是name字段没有索引，而且查询结果的字段age也没有索引最牛逼的情况是，索引字段覆盖了所有，那全程通过索引来加速查询以及获取结果就ok了 #索引合并：把多个单列索引合并使用 #分析：组合索引能做到的事情，我们都可以用索引合并去解决，比如create index ne on s1(name,email); 组合索引 我们完全可以单独为name和email创建索引，然后按照where name=’xxx’ and email=’xxx’使用 #索引合并 组合索引可以命中： select * from s1 where name=&apos;egon&apos; ; select * from s1 where name=&apos;egon&apos; and email=&apos;adf&apos;; 索引合并可以命中： select * from s1 where name=&apos;egon&apos; ; select * from s1 where email=&apos;adf&apos;; select * from s1 where name=&apos;egon&apos; and email=&apos;adf&apos;; 乍一看好像索引合并更好了：可以命中更多的情况，但其实要分情况去看，如果是name=’egon’ and email=’adf’,那么组合索引的效率要高于索引合并，如果是单条件查，那么还是用索引合并比较合理 查询优化神器-explain关于explain命令相信大家并不陌生，具体用法和字段含义可以参考官网explain-output，这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。 执行计划：让mysql预估执行操作(一般正确) all &lt; index &lt; range &lt; index_merge &lt; ref_or_null &lt; ref &lt; eq_ref &lt; system/const id,email 慢： select * from userinfo3 where name=&apos;alex&apos; explain select * from userinfo3 where name=&apos;alex&apos; type: ALL(全表扫描) select * from userinfo3 limit 1; 快： select * from userinfo3 where email=&apos;alex&apos; type: const(走索引) 慢查询优化的基本步骤0.先运行看看是否真的很慢，注意设置SQL_NO_CACHE 1.where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高 2.explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询） 3.order by limit 形式的sql语句让排序的表优先查 4.了解业务方使用场景 5.加索引时参照建索引的几大原则 6.观察结果，不符合预期继续从0分析 慢日志管理慢日志 - 执行时间 &gt; 10 - 未命中索引 - 日志文件路径 配置： - 内存 show variables like &apos;%query%&apos;; show variables like &apos;%queries%&apos;; set global 变量名 = 值 - 配置文件 mysqld --defaults-file=&apos;E:\wupeiqi\mysql-5.7.16-winx64\mysql-5.7.16-winx64\my-default.ini&apos; my.conf内容： slow_query_log = ON slow_query_log_file = D:/.... 注意：修改配置文件之后，需要重启服务]]></content>
      <categories>
        <category>数据库</category>
        <category>MYSQL</category>
      </categories>
      <tags>
        <tag>tag 数据库索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA静态变量那些事儿]]></title>
    <url>%2F2019%2F08%2F23%2FJAVA%E9%9D%99%E6%80%81%E5%8F%98%E9%87%8F%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%2F</url>
    <content type="text"><![CDATA[JAVA静态变量那些事儿类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载七个阶段。 类初始化是类加载过程的最后一个阶段，到初始化阶段，才真正开始执行类中的Java程序代码。虚拟机规范严格规定了有且只有5种情况必须立即对类进行初始化： 第一种：遇到new、getstatic、putstatic、invokestatic这四条字节码指令时，如果类还没有进行过初始化，则需要先触发其初始化。生成这四条指令最常见的Java代码场景是：使用new关键字实例化对象时、读取或设置一个类的静态字段（static）时（被static修饰又被final修饰的，已在编译期把结果放入常量池的静态字段除外）、以及调用一个类的静态方法时。 第二种：使用Java.lang.refect包的方法对类进行反射调用时，如果类还没有进行过初始化，则需要先触发其初始化。 第三种：当初始化一个类的时候，如果发现其父类还没有进行初始化，则需要先触发其父类的初始化。 第四种：当虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先执行该主类。 第五种：当使用JDK1.5支持时，如果一个java.langl.incoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始 例子说明情况一变量是 static final 修饰的“编译期常量”,如 public static final String a = “JD”; public class Test { public static void main(String[] args) { System.out.println(Test2.a); } } class Test2 { public static final String a = &quot;JD&quot;; static { System.out.print(&quot;OK&quot;); } } 情况二变量是 static final 修饰的“非编译期常量”,如 public static final String a = new String(“JD”); public class Test { public static void main(String[] args) { System.out.println(Test2.a); } } class Test2 { public static final String a = new String(&quot;JD&quot;); static { System.out.print(&quot;OK&quot;); } } 情况三static 变量域不是 final,如 public static String a = “JD”; public class Test { public static void main(String[] args) { System.out.println(Test2.a); } } class Test2 { public static String a = &quot;JD&quot;; static { System.out.print(&quot;OK&quot;); } } 情况四继承是JAVA语言的一个特性，针对类的继承，虚拟机会如何进行父类和子类的初始化加载呢？1. public class Test { public static void main(String[] args) { System.out.print(B.c); } } class A { static { System.out.print(&quot;A&quot;); } } class B extends A { static { System.out.print(&quot;B&quot;); } public static final String c = &quot;C&quot;; } 2. public class Test { public static void main(String[] args) { System.out.print(B.c); } } class A { static { System.out.print(&quot;A&quot;); } } class B extends A { static { System.out.print(&quot;B&quot;); } public static String c = &quot;C&quot;; } 3. public class Test { public static void main(String[] args) { System.out.print(B.c); } } class A { static { System.out.print(&quot;A&quot;); } } class B extends A { static { System.out.print(&quot;B&quot;); } public static String c = new String(&quot;C&quot;); } 4. public class Test { public static void main(String[] args) { System.out.print(B.c); } } class A { static { System.out.print(&quot;A&quot;); } // 测试：只能选择其中一种一条语句 // public static final String c = &quot;C&quot;; // public static String c = &quot;C&quot;; // public static final String c = new String(&quot;C&quot;); public static String c = new String(&quot;C&quot;); } class B extends A { static { System.out.print(&quot;B&quot;); } } 总结如果一个static final值是“编译期常量”，就像static final int numB = 2;那样，那么这个值不需要对B类进行初始化就可以读取。但是，如果只是将一个域设置为static和final的，那不一足以确保这种行为，例如，对static final int numA = Main.rand.nextInt(100);的访问将强制进行类的初始化，因为它不是一个编译期常量。如果一个static 域不是final，那么在对它访问时，总是要求在它被读取之前，要先进行链接(为这个域分配存储空间)和初始化(初始化该存储空间)就像static int numC = 3;那样！！！]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>静态变量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux硬链接与软链接]]></title>
    <url>%2F2019%2F08%2F23%2FLinux%E7%A1%AC%E9%93%BE%E6%8E%A5%E4%B8%8E%E8%BD%AF%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[Linux硬链接与软链接Linux 系统中有软链接和硬链接两种特殊的“文件”。 软链接可以看作是Windows中的快捷方式，可以让你快速链接到目标档案或目录。 硬链接则透过文件系统的inode来产生新档名，而不是产生新档案。 创建方法都很简单： 软链接（符号链接） ln -s source target 硬链接 （实体链接）ln source target Inode要解释清楚两者的区别和联系需要先说清楚 linux 文件系统中的 inode 这个东西。当划分磁盘分区并格式化的时候，整个分区会被划分为两个部分，即inode区和data block(实际数据放置在数据区域中）这个inode即是（目录、档案）文件在一个文件系统中的唯一标识，需要访问这个文件的时候必须先找到并读取这个 文件的 inode。 Inode 里面存储了文件的很多重要参数，其中唯一标识称作 Inumber, 其他信息还有创建时间（ctime）、修改时间(mtime) 、文件大小、属主、归属的用户组、读写权限、数据所在block号等信息。 通常会根据分区的用途来安排inode的数量（这是另外一个话题了），比如文件数量很多而文件都很小，则需要调增inode较大，以便能索引全部文件。否则将会出现这个分区并没有写满而无法写入任何文件的情况。 目录文件与档案文件 目录文件：记录该目录下的文件名 档案文件：记录实际文件数据 inode本身并不记录文件名，文件名记录在目录文件的block当中，所以新增、删除、更改文件名与目录的W权限有关。因此当我们要读某个档案时，就务必经过其目录的inode和block，然后才能够找到待读取档案的inode号，最终才会读到正确的档案block内的数据。系统是通过索引节点(而不是文件名)来定位每一个文件。 目录inode（满足权限？） =&gt; 目录block =&gt; 档案inode（满足权限？） =&gt; 档案block 硬链接 多个档名对应同一个inode，硬链接只是在某个目录下新增一笔档名链 接到某个inode号码的关联记录而已。如果将上图中任何一个档名删除，档案的inode与block都还存在，依然还可以通过另一个档名来读取正确的档 案数据。此外，不论用哪一个档名来编辑，最终的结果都会写入相同的inode和block中，因此均能进行数据的修改。 软连接 软连接就是建立一个独立的文件，而这个文件会让数据的读取指向它link的那个档案的档名，由于只是作为指向的动作，所以当来源档案被删除之后，软连接的档案无法开启，因为找不到原始档名。连结档的内容只有档名，根据档名链接到正确的目录进一步取得目标档案的inode，最终就能够读取到正确的数据。如果目标档案的原始档名被删除了那么整个环节就进行不下去了。 下面用一个实例来说明硬链接和软链接现在目录下有两个文件，一个名为AAA，一个名为BBB。 引用 $ ls -il 963922 -rw-r--r-- 1 ocean ocean 92 2007-05-18 15:46 AAA 963923 -rw-r--r-- 1 ocean ocean 95 2007-05-18 15:46 BBB 首先先做一个AAA的硬链接。 引用 $ ln AAA AAAhard $ls -il 963922 -rw-r--r-- 2 ocean ocean 92 2007-05-18 15:46 AAA 963922 -rw-r--r-- 2 ocean ocean 92 2007-05-18 15:46 AAAhard 963923 -rw-r--r-- 1 ocean ocean 95 2007-05-18 15:46 BBB 这里我们注意在创建链接前，AAA显示的链接数目为1，创建链接后 1.AAA和AAAhard的链接数目都变为2。 2.AAA和AAAhard的inode号是一样的，都是963922。 3.AAA和AAAhard显示的文件大小也是一样，都是92B。 可见进行了ln命令的操作结果：AAA和AAAhard是同一个文件的两个名字， 它们具有同样的索引节点号和文件属性，建立文件AAA的硬链接，就是为 AAA的文件索引节点在当前目录上建立一个新指针。你可以删除其中任何一个，如rm AAA，每次只会删除一个指针，链接数同时减一，只有将所有指向文件内容的指针，也即链接数减为0时，内核才会把文件内容从磁盘上删除。 尽管硬链接节省空间，也是Linux系统整合文件系统的传统方式，但是存在一些不足之处： 1.不允许给目录创建硬链接。 2.不可以在不同文件系统的文件间建立链接。因为 inode 是这个文件在当前分区中的索引值，是相对于这个分区的，当然不能跨越文件系统了。 接着我们做一个指向BBB的软链接，软链接克服了硬链接的不足，没有任何文件系统的限制，任何用户可以创建指向目录的符号链接。因而现在更为广泛使用，它具有更大的灵活性，甚至可以跨越不同机器、不同网络对文件进行链接。 引用 $ ln -s BBB BBBsoft $ ls -il 总用量 0 963922 -rw-r--r-- 2 ocean ocean 92 2007-05-18 15:46 AAA 963922 -rw-r--r-- 2 ocean ocean 92 2007-05-18 15:46 AAAhard 963923 -rw-r--r-- 1 ocean ocean 95 2007-05-18 15:46 BBB 963924 lrwxrwxrwx 1 ocean ocean 3 2007-05-18 15:47 BBBsoft -&gt; BBB 从上面链接后的结果可以看出来软链接与硬链接，区别不仅仅是在概念上，在实现上也是完全不同的。 区别1.硬链接原文件/链接文件公用一个inode号，说明他们是同一个文件，而软链接原文件/链接文件拥有不同的inode号，表明他们是两个不同的文件； 2.在文件属性上软链接明确写出了是链接文件，而硬链接没有写出来，因为在本质上硬链接文件和原文件是完全平等关系； 3.链接数目是不一样的，软链接的链接数目不会增加； 4.文件大小是不一样的，硬链接文件显示的大小是跟原文件是一样的。而这里软链接显示的大小与原文件就不同了，BBB大小是95B，而BBBsoft是3B。因为BBB共有3个字符 5.软链接没有任何文件系统的限制，任何用户可以创建指向目录的符号链接 总之，建立软链接就是建立了一个新文件。当访问链接文件时，系统就会发现他是个链接文件，它读取链接文件找到真正要访问的文件。 当然软链接也有硬链接没有的缺点：因为链接文件包含有原文件的路径信息，所以当原文件从一个目录下移到其他目录中，再访问链接文件，系统就找不到了，而硬链接就没有这个缺陷，你想怎么移就怎么移；还有它要系统分配额外的空间用于建立新的索引节点和保存原文件的路径。]]></content>
      <categories>
        <category>Linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>软硬链接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP拥塞控制、网络各层协议]]></title>
    <url>%2F2019%2F08%2F23%2FTCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E3%80%81%E7%BD%91%E7%BB%9C%E5%90%84%E5%B1%82%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[TCP拥塞控制、网络各层协议我们知道TCP和UDP都是传输层的协议，最大的区别UDP无连接是面向报文的，不保证可靠传输，无拥塞控制，就是TCP是面向连接的协议，能提供安全，可靠，有序的数据传输，保证数据无差错，不丢失，不重复按序到达 那么TCP是如何保证可靠传输的？（1）校验和如果接受到的段检验和有差错，TCP将丢弃这个段，且不会确认收到 （2）流量控制流量控制的目的是防止数据丢失，如果发送方发送的太快，接收方来不及接受处理那么数据就会丢失，所以流量控制是控制发送方的发送速度的。 流量控制采用滑动窗口在实现，在接收端有自己的缓存大小，接收方只允许发送方发送的数据大小就是目前自己的缓存还能接受多少数据，这个大小也就是滑动窗口的大小。接收方在返回确认信息的时候就会返回自己滑动窗口的大小， （3）拥塞控制拥塞控制是作用于网络的，防止过多的数据出现在网络中，导致网络负载过大，主要通过慢开始，快重传，快恢复和避免拥塞来实现的。 慢开始（1）发送方维护一个拥塞窗口cwnd，这个窗口有一个慢开始ssthresh，发送方一开始传输的时候采用慢开始，也就是不会一下子发送大小为ssthresh的数据量，而是按照指数的增长速度来慢慢加大cwnd的大小，如下图。 当cwnd&gt;ssthresh时就开始采用拥塞避免算法 拥塞避免拥塞避免算法就是让cwnd的大小线性增长，一个轮次只增加1，这样不会那么快使得网络拥塞。 不论是在慢开始阶段还是拥塞避免阶段，如果出现网络拥塞，ssthresh的大小变为拥塞发生时cwnd值的一半，然后cwnd变为1，在开始慢开始算法 快重传快重传是指当接收方收到一个失序的数据，可以立刻向发送方发送重复确认信息，而不会等到发送下一个确认时捎带发送，发送方只要接收三个连续的重复确认，就会立刻重复发送刚才没有收到确认的数据 快恢复与快重传配合使用，当发送方接收到连续三个重复确认请求，为了避免网络拥塞，就会把ssthresh的值减少为当然拥塞窗口的一半，但是发送方认为当前网络并没有发生拥塞，因为还可以接收到三个确认请求，所以不会去执行慢开始算法，而是执行拥塞避免算法 （4）停止等待协议发送方没发送一个数据就会等待接收方的确认，超过时间没有收到，就会重传 网络各层协议]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>TCP</tag>
        <tag>拥塞控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL家的引擎]]></title>
    <url>%2F2019%2F08%2F20%2FMySQL%E5%AE%B6%E7%9A%84%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[MySQL数据库引擎数据库引擎数据库引擎是用于存储、处理和保护数据的核心服务。利用数据库引擎可控制访问权限并快速处理事务，从而满足企业内大多数需要处理大量数据的应用程序的要求。使用数据库引擎创建用于联机事务处理或者联机分析处理数据的关系数据库。这包括创建用于存储数据的表和用于查看、管理和保护数据安全的数据库对象（如索引、视图、存储过程）。 MySQL数据库引擎取决于MySQL安装时是如何被编译的。要添加新引擎，就必须重新编译。缺省情况下，MySQL支持三个引擎，ISAM,MYISAM和HEAP。另外两种类型，INNODB和BERKLEY也常常使用。 数据库引擎任务在数据库引擎文档中，各主题的顺序遵循用于实现使用数据库引擎进行数据存储的系统的任务的主要顺序 设计并创建数据库以保持系统所需的关系或XML文档 实现系统以访问和更改数据库中存储的数据。包括实现网站或者使用数据的应用程序性，还包括生成SQL Server工具和使用工具以使用数据的过程 为单位或客户部署实现的系统 提供日常管理以优化数据库性能 查看存储引擎MySQL给开发者提供了查询存储引擎的功能，我这里使用的是MySQL5.1，可以使用： SHOW ENGINES 如果要想查看数据库默认使用哪个引擎，可以通过使用命令： SHOW VARIABLES LIKE ‘storage_engine’; 在MySQL中，不需要在整个服务器中使用同一种存储引擎，针对具体的要求，可以对每一个表使用不同的存储引擎。Support列的值表示某种引擎是否能使用：YES表示可以使用、NO表示不能使用、DEFAULT表示该引擎为当前默认的存储引擎 。下面来看一下其中几种常用的引擎。 修改数据库引擎1、更改方式1：修改配置文件my.ini 将my-small.ini另存为my.ini，在[mysqld]后面添加default-storage-engine=InnoDB，重启服务，数据库默认的引擎修改为InnoDB 2、更改方式2:在建表的时候指定 建表时指定： create table mytbl( id int primary key, name varchar(50) )type=MyISAM; 3、更改方式3：建表后更改 alter table mytbl2 type = InnoDB; MySQL数据库引擎们ISAMISAM是一个定义明确且历经时间考验的数据表格管理方法，它在设计之时就考虑到数据库被查询的次数远大于更新的次数。因此，ISAM执行读取的操作速度很快，而且不占用大量的内存和存储资源。ISAM的两个主要不足之处在于，它不支持事务处理，也不能够容错。如果那你的硬盘崩溃了，那么数据文件无法恢复。如果你正在把ISAM用在关键应用程序里，那就必须经常备份你所有的实时数据。通过其复制性，MYSQL能够支持这样的备份应用程序。 MYISAMMyISAM基于ISAM存储引擎，并对其进行扩展。它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。MyISAM拥有较高的插入、查询速度，但不支持事物。MyISAM主要特性有： 1、大文件（达到63位文件长度）在支持大文件的文件系统和操作系统上被支持 2、当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块，以及若下一个块被删除，就扩展到下一块自动完成 3、每个MyISAM表最大索引数是64，这可以通过重新编译来改变。每个索引最大的列数是16 4、最大的键长度是1000字节，这也可以通过编译来改变，对于键长度超过250字节的情况，一个超过1024字节的键将被用上 5、BLOB和TEXT列可以被索引 6、NULL被允许在索引的列中，这个值占每个键的0~1个字节 7、所有数字键值以高字节优先被存储以允许一个更高的索引压缩 8、每个MyISAM类型的表都有一个AUTO_INCREMENT的内部列，当INSERT和UPDATE操作的时候该列被更新，同时AUTO_INCREMENT列将被刷新。所以说，MyISAM类型表的AUTO_INCREMENT列更新比InnoDB类型的AUTO_INCREMENT更快 9、可以把数据文件和索引文件放在不同目录 10、每个字符列可以有不同的字符集 11、有VARCHAR的表可以固定或动态记录长度 12、VARCHAR和CHAR列可以多达64KB使用MyISAM引擎创建数据库，将产生3个文件。文件的名字以表名字开始，扩展名之处文件类型：frm文件存储表定义、数据文件的扩展名为.MYD（MYData）、索引文件的扩展名时.MYI（MYIndex） InnoDB存储引擎InnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，上图也看到了，InnoDB是默认的MySQL引擎。InnoDB主要特性有： 1、InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事物安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合 2、InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系型数据库引擎锁不能匹敌的 3、InnoDB存储引擎完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上 4、InnoDB支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键 5、InnoDB被用在众多需要高性能的大型数据库站点上InnoDB不创建目录，使用InnoDB时，MySQL将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件 MEMORY存储引擎MEMORY存储引擎将表中的数据存储到内存中，未查询和引用其他表数据提供快速访问。MEMORY主要特性有： 1、MEMORY表的每个表可以有多达32个索引，每个索引16列，以及500字节的最大键长度 2、MEMORY存储引擎执行HASH和BTREE缩影 3、可以在一个MEMORY表中有非唯一键值 4、MEMORY表使用一个固定的记录长度格式 5、MEMORY不支持BLOB或TEXT列 6、MEMORY支持AUTO_INCREMENT列和对可包含NULL值的列的索引 7、MEMORY表在所由客户端之间共享（就像其他任何非TEMPORARY表） 8、MEMORY表内存被存储在内存中，内存是MEMORY表和服务器在查询处理时的空闲中，创建的内部表共享 9、当不再需要MEMORY表的内容时，要释放被MEMORY表使用的内存，应该执行DELETE FROM或TRUNCATE TABLE，或者删除整个表（使用DROP TABLE） 存储引擎的选择 如果要提供提交、回滚、崩溃恢复能力的事物安全（ACID兼容）能力，并要求实现并发控制，InnoDB是一个好的选择 如果数据表主要用来插入和查询记录，则MyISAM引擎能提供较高的处理效率如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存中的Memory引擎，MySQL中使用该引擎作为临时表，存放查询的中间结果 如果只有INSERT和SELECT操作，可以选择Archive，Archive支持高并发的插入操作，但是本身不是事务安全的。Archive非常适合存储归档数据，如记录日志信息可以使用Archive 使用哪一种引擎需要灵活选择，一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求，使用合适的存储引擎，将会提高整个数据库的性能 MyIASM 和 Innodb引擎详解Innodb引擎 Innodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别，关于数据库事务与其隔离级别的内容请见数据库事务与其隔离级别这篇文章。该引擎还提供了行级锁和外键约束，它的设计目标是处理大容量数据库系统，它本身其实就是基于MySQL后台的完整数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引。但是该引擎不支持FULLTEXT类型的索引，而且它没有保存表的行数，当SELECT COUNT(*) FROM TABLE时需要扫描全表。当需要使用数据库事务时，该引擎当然是首选。由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率。但是使用行级锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表。 名词解析：ACID A 事务的原子性(Atomicity)：指一个事务要么全部执行,要么不执行.也就是说一个事务不可能只执行了一半就停止了.比如你从取款机取钱,这个事务可以分成两个步骤:1划卡,2出钱.不可能划了卡,而钱却没出来.这两步必须同时完成.要么就不完成. C 事务的一致性(Consistency)：指事务的运行并不改变数据库中数据的一致性.例如,完整性约束了a+b=10,一个事务改变了a,那么b也应该随之改变. I 独立性(Isolation）:事务的独立性也有称作隔离性,是指两个以上的事务不会出现交错执行的状态.因为这样可能会导致数据不一致. D 持久性(Durability）:事务的持久性是指事务执行成功以后,该事务所对数据库所作的更改便是持久的保存在数据库之中，不会无缘无故的回滚. MyIASM引擎MyIASM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT(插入)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。不过和Innodb不同，MyIASM中存储了表的行数，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描。如果表的读操作远远多于写操作且不需要数据库事务的支持，那么MyIASM也是很好的选择。 两种引擎的选择大尺寸的数据集趋向于选择InnoDB引擎，因为它支持事务处理和故障恢复。数据库的大小决定了故障恢复的时间长短，InnoDB可以利用事务日志进行数据恢复，这会比较快。主键查询在InnoDB引擎下也会相当快，不过需要注意的是如果主键太长也会导致性能问题，关于这个问题我会在下文中讲到。大批的INSERT语句(在每个INSERT语句中写入多行，批量插入)在MyISAM下会快一些，但是UPDATE语句在InnoDB下则会更快一些，尤其是在并发量大的时候。 Index——索引索引（Index）是帮助MySQL高效获取数据的数据结构。MyIASM和Innodb都使用了树这种数据结构做为索引。下面我接着讲这两种引擎使用的索引结构，讲到这里，首先应该谈一下B-Tree和B+Tree。 B-Tree和B+TreeB+Tree是B-Tree的变种，那么我就先讲B-Tree吧，相信大家都知道红黑树，这是我前段时间学《算法》一书时，实现的一颗红黑树，大家可以参考。其实红黑树类似2,3-查找树，这种树既有2叉结点又有3叉结点。B-Tree也与之类似，它的每个结点做多可以有d个分支（叉），d称为B-Tree的度，如下图所示，它的每个结点可以有4个元素，5个分支，于是它的度为5。B-Tree中的元素是有序的，比如图中元素7左边的指针指向的结点中的元素都小于7，而元素7和16之间的指针指向的结点中的元素都处于7和16之间，正是满足这样的关系，才能高效的查找：首先从根节点进行二分查找，找到就返回对应的值，否则就进入相应的区间结点递归的查找，直到找到对应的元素或找到null指针，找到null指针则表示查找失败。这个查找是十分高效的，其时间复杂度为O(logN)（以d为底，当d很大时，树的高度就很低），因为每次检索最多只需要检索树高h个结点。 接下来就该讲B+Tree了，它是B-Tree的变种，如下面两张图所示： MyIASM引擎的索引结构MyISAM引擎的索引结构为B+Tree，其中B+Tree的数据域存储的内容为实际数据的地址，也就是说它的索引和实际的数据是分开的，只不过是用索引指向了实际的数据，这种索引就是所谓的非聚集索引。如下图所示： 这里设表一共有三列，假设我们以Col1为主键，则上图是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示： 同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。 Innodb引擎的索引结构与MyISAM引擎的索引结构同样也是B+Tree，但是Innodb的索引文件本身就是数据文件，即B+Tree的数据域存储的就是实际的数据，这种索引就是聚集索引。这个索引的key就是数据表的主键，因此InnoDB表数据文件本身就是主索引。 并且和MyISAM不同，InnoDB的辅助索引数据域存储的也是相应记录主键的值而不是地址，所以当以辅助索引查找时，会先根据辅助索引找到主键，再根据主键索引找到实际的数据。所以Innodb不建议使用过长的主键，否则会使辅助索引变得过大。建议使用自增的字段作为主键，这样B+Tree的每一个结点都会被顺序的填满，而不会频繁的分裂调整，会有效的提升插入数据的效率。 两者区别： 第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 上图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。 第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，下图为定义在Col3上的一个辅助索引： 这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调(可能是指“非递增”的意思)的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调(可能是指“非递增”的意思)的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。 MyISAM与InnoDB的抉择1、首先我目前平台上承载的大部分项目是读多写少的项目，而MyISAM的读性能是比Innodb强不少的。 2、MyISAM的索引和数据是分开的，并且索引是有压缩的，内存使用率就对应提高了不少。能加载更多索引，而Innodb是索引和数据是紧密捆绑的，没有使用压缩从而会造成Innodb比MyISAM体积庞大不小。 3、从平台角度来说，经常隔1，2个月就会发生应用开发人员不小心update一个表where写的范围不对，导致这个表没法正常用了，这个时候MyISAM的优越性就体现出来了，随便从当天拷贝的压缩包取出对应表的文件，随便放到一个数据库目录下，然后dump成sql再导回到主库，并把对应的binlog补上。如果是Innodb，恐怕不可能有这么快速度，别和我说让Innodb定期用导出xxx.sql机制备份，因为我平台上最小的一个数据库实例的数据量基本都是几十G大小。 4、从我接触的应用逻辑来说，select count(*) 和order by是最频繁的，大概能占了整个sql总语句的60%以上的操作，而这种操作Innodb其实也是会锁表的，很多人以为Innodb是行级锁，那个只是where对它主键是有效，非主键的都会锁全表的。 5、还有就是经常有很多应用部门需要我给他们定期某些表的数据，MyISAM的话很方便，只要发给他们对应那表的frm.MYD,MYI的文件，让他们自己在对应版本的数据库启动就行，而Innodb就需要导出xxx.sql了，因为光给别人文件，受字典数据文件的影响，对方是无法使用的。 6、如果和MyISAM比insert写操作的话，Innodb还达不到MyISAM的写性能，如果是针对基于索引的update操作，虽然MyISAM可能会逊色Innodb,但是那么高并发的写，从库能否追的上也是一个问题，还不如通过多实例分库分表架构来解决。 7、如果是用MyISAM的话，merge引擎可以大大加快应用部门的开发速度，他们只要对这个merge表做一些selectcount(*)操作，非常适合大项目总量约几亿的rows某一类型(如日志，调查统计)的业务表。当然Innodb也不是绝对不用，用事务的项目如模拟炒股项目，我就是用Innodb的，活跃用户20多万时候，也是很轻松应付了，因此我个人也是很喜欢Innodb的，只是如果从数据库平台应用出发，我还是会首MyISAM。另外，可能有人会说你MyISAM无法抗太多写操作，但是我可以通过架构来弥补，说个我现有用的数据库平台容量：主从数据总量在几百T以上，每天十多亿pv的动态页面，还有几个大项目是通过数据接口方式调用未算进pv总数，(其中包括一个大项目因为初期memcached没部署,导致单台数据库每天处理9千万的查询)。而我的整体数据库服务器平均负载都在0.5-1左右。 一般来说，MyISAM适合： (1)做很多count 的计算； (2)插入不频繁，查询非常频繁； (3)没有事务。 InnoDB适合： (1)可靠性要求比较高，或者要求事务； (2)表更新和查询都相当的频繁，并且表锁定的机会比较大的情况指定数据引擎的创建 让所有的灵活性成为可能的开关是提供给ANSI SQL的MySQL扩展——TYPE参数。MySQL能够让你在表格这一层指定数据库引擎，所以它们有时候也指的是table formats。下面的示例代码表明了如何创建分别使用MyISAM、ISAM和HEAP引擎的表格。要注意，创建每个表格的代码是相同的，除了最后的 TYPE参数，这一参数用来指定数据引擎。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>数据库引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈设计模式们]]></title>
    <url>%2F2019%2F08%2F18%2F%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BB%AC%2F</url>
    <content type="text"><![CDATA[JAVA开发中的23种设计模式设计模式(Design Patterns)设计模式是一套被反复使用，多数人知晓的，经过分类编目的，代码设计经验的总结。使用设计模式是为了可重用代码，让代码更容易被他们理解，保证代码可靠性。设计模式使代码编写真正工程化，合理的运用设计模式可以完美解决很多问题，每种模式都有相应的原理与之对应，每一个模式描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案。 分类总体来说，设计模式分为三大类： 创建型模式,5种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式,7种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为模式,11种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介模式、解释器模式 其实还有两类：并发型模式和线程池模式 如图所示: 设计模式的六大原则1、开闭原则（Open Close Principle）开闭原则即 对拓展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。一句话，为了使程序的拓展性好，易于维护和升级。为达到这种效果，我们需要使用接口和抽象类。 2、里氏代换原则（Liskov Substitution Principle LSP)里氏代换原则是面向对象设计的基本原则之一。里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受影响，基类才能真正被复用，而衍生类也能在基类的基础上增加新的行为。里氏代换原则是对‘开闭原则’的补充。实现开闭原则的关键步骤是抽象化。而基类与子类的继承关系就是抽象化的具体实现。所以里氏代换原则就是对实现抽象化的具体步骤规范。 3、依赖倒转原则（Dependence Inversion Principle）这个是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。 4、接口隔离原则（Interface Segregation Principle）使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的意思。 5、迪米特法则（最少知道原则）（Demeter Principle）最少知道原则，就是说：一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 6、合成复用原则（Composite Reuse Principle）原则是尽量使用合成/聚合的方式，而不是使用继承 JAVA中的23种设计模式1、工厂方法模式（Factory Method）工厂方法模式有3种: 普通工厂模式就是建立一个工厂类，对实现了同一接口的一些类进行实例的创建。举个例子 public interface Sender {//通用接口 void send(); } public class MailSender implements Sender{//具体实现1 @Override public void send() { } } public class SmsSender implements Sender {//具体实现2 @Override public void send() { } } public class SendFactory {//工厂类 public Sender produce(String type){ if (&quot;mail&quot;.equals(type)) { return new MailSender(); } else if (&quot;sms&quot;.equals(type)) { return new SmsSender(); } else { System.out.println(&quot;请输入正确的类型!&quot;); return null; } } } 综上，对于实现了同一Sender接口的实现类来说，工厂类利用多态返回一个Sender对象引用，根据传入的参数决定对象具体是哪种实现。 多个工厂方法模式是对普通工厂方法模式的改进，在普通工厂方法模式中，如果传递的字符串出错，则不能正确创建对象，而多个工厂方法模式是提供多个工厂方法，分别创建对象 对上面的代码简单改动，改动SendFactory类即可 public Sender produceMail(){ public Sender produceMail(){ //返回一个Mail实现对象 return new MailSender(); } public Sender produceSms(){ 返回一个Sms实现对象 return new SmsSender(); } } 综上，多个工厂方法模式即生成的具体对象实现，有方法指定，而不是传入参数。 静态工厂方法模式将上面的多个工厂方法模式里的方法置为静态的，不需要创建实例，直接调用即可。 public class SendFactory { public static Sender produceMail(){ return new MailSender(); } public static Sender produceSms(){ return new SmsSender(); } } 综上：静态工厂方法即将工厂类的工厂方法设置为静态的，在调用时可以直接通过类名.方法名直接调用。 抽象工厂模式（Abstract Factory）工厂方法模式有一个问题，就是类的创建依赖于工厂类。也就是说，如果想要拓展程序，就必须对工厂类进行修改，这违背了闭包原则。抽象工厂模式，创建多个工厂类，这样一旦需要增加新功能，直接添加新的工厂类就可以了，不需要修改之前的代码。 public interface Sender { //功能接口 public void Send(); } public class MailSender implements Sender { @Override public void Send() { //实现类1 System.out.println(&quot;this is mailsender!&quot;); } } public class SmsSender implements Sender { @Override public void Send() { //实现类2 System.out.println(&quot;this is sms sender!&quot;); } } public class SendMailFactory implements Provider { @Override public Sender produce(){ //专门生产Mail实现的工厂类 return new MailSender(); } } public class SendSmsFactory implements Provider{ @Override public Sender produce() { //专门生产Sms实现的工厂类 return new SmsSender(); } } public interface Provider { //通用接口 public Sender produce(); } 综上:如果你现在想增加一个功能：发及时信息，则只需做一个实现类，实现Sender接口，同时做一个工厂类，实现Provider接口，就OK了，无需去改动现成的代码。这样做，拓展性较好！ 单例模式（Singleton）单例对象是一种常用的设计模式。在java应用中，单例对象能保证在一个JVM中，该对象只有一个实例存在。这样的模式有几个好处: 1.某些类创建频繁，对于一些大型的对象，这是一笔很大的系统开销 2.省去了new操作符，降低了系统内存的使用频率，减少GC压力 3.有些类如交易所的核心交易引擎，控制着交易流程，如果出现多个对象系统就出现混乱。 public class Singleton { /* 持有私有静态实例，防止被引用，此处赋值为null，目的是实现延迟加载 */ private static Singleton instance = null; /* 私有构造方法，防止被实例化 */ private Singleton() { } /* 静态工程方法，创建实例 */ public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } /* 如果该对象被用于序列化，可以保证对象在序列化前后保持一致 */ public Object readResolve() { return instance; } } 这个类可以满足基本要求，但是，像这样毫无线程安全保护的类，如果我们把它放入多线程的环境下，肯定就会出现问题了，如何解决？我们首先会想到对getInstance方法加synchronized关键字，如下： public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } 但是，synchronized关键字锁住的是这个对象，这样的用法，在性能上会有所下降，因为每次调用getInstance()，都要对对象上锁，事实上，只有在第一次创建对象的时候需要加锁，之后就不需要了，所以，这个地方需要改进。我们改成下面这个： public static Singleton getInstance() { if (instance == null) { synchronized (instance) { if (instance == null) { instance = new Singleton(); } } } return instance; } 似乎解决了之前提到的问题，将synchronized关键字加在了内部，也就是说当调用的时候是不需要加锁的，只有在instance为null，并创建对象的时候才需要加锁，性能有一定的提升。但是，这样的情况，还是有可能有问题的。 看下面的情况：在Java指令中创建对象和赋值操作是分开进行的，也就是说instance = new Singleton();语句是分两步执行的。但是JVM并不保证这两个操作的先后顺序，也就是说有可能JVM会为新的Singleton实例分配空间，然后直接赋值给instance成员，然后再去初始化这个Singleton实例。这样就可能出错了，我们以A、B两个线程为例： a&gt;A、B线程同时进入了第一个if判断 b&gt;A首先进入synchronized块，由于instance为null，所以它执行instance = new Singleton(); c&gt;由于JVM内部的优化机制，JVM先画出了一些分配给Singleton实例的空白内存，并赋值给instance成员（注意此时JVM没有开始初始化这个实例），然后A离开了synchronized块。 d&gt;B进入synchronized块，由于instance此时不是null，因此它马上离开了synchronized块并将结果返回给调用该方法的程序。 e&gt;此时B线程打算使用Singleton实例，却发现它没有被初始化，于是错误发生了。 所以程序还是有可能发生错误，其实程序在运行过程是很复杂的，从这点我们就可以看出，尤其是在写多线程环境下的程序更有难度，有挑战性。我们对该程序做进一步优化： private static class SingletonFactory{ private static Singleton instance = new Singleton(); } public static Singleton getInstance(){ return SingletonFactory.instance; } 实际情况是，单例模式使用内部类来维护单例的实现，JVM内部的机制能够保证当一个类被加载的时候，这个类的加载过程是线程互斥的。这样当我们第一次调用getInstance的时候，JVM能够帮我们保证instance只被创建一次，并且会保证把赋值给instance的内存初始化完毕，这样我们就不用担心上面的问题。同时该方法也只会在第一次调用的时候使用互斥机制，这样就解决了低性能问题。这样我们暂时总结一个完美的单例模式： public class Singleton { /* 私有构造方法，防止被实例化 */ private Singleton() { } /* 此处使用一个内部类来维护单例 */ private static class SingletonFactory { private static Singleton instance = new Singleton(); } /* 获取实例 */ public static Singleton getInstance() { return SingletonFactory.instance; } /* 如果该对象被用于序列化，可以保证对象在序列化前后保持一致 */ public Object readResolve() { return getInstance(); } } 其实说它完美，也不一定，如果在构造函数中抛出异常，实例将永远得不到创建，也会出错。所以说，十分完美的东西是没有的，我们只能根据实际情况，选择最适合自己应用场景的实现方法。也有人这样实现：因为我们只需要在创建类的时候进行同步，所以只要将创建和getInstance()分开，单独为创建加synchronized关键字，也是可以的： public class SingletonTest { private static SingletonTest instance = null; private SingletonTest() { } private static synchronized void syncInit() { if (instance == null) { instance = new SingletonTest(); } } public static SingletonTest getInstance() { if (instance == null) { syncInit(); } return instance; } } 补充：采用”影子实例”的办法为单例对象的属性同步更新 public class SingletonTest { private static SingletonTest instance = null; private Vector properties = null; public Vector getProperties() { return properties; } private SingletonTest() { } private static synchronized void syncInit() { if (instance == null) { instance = new SingletonTest(); } } public static SingletonTest getInstance() { if (instance == null) { syncInit(); } return instance; } public void updateProperties() { SingletonTest shadow = new SingletonTest(); properties = shadow.getProperties(); } } 综上: 1、单例模式理解起来简单，但是具体实现起来还是有一定的难度。 2、synchronized关键字锁定的是对象，在用的时候，一定要在恰当的地方使用（注意需要使用锁的对象和过程，可能有的时候并不是整个对象及整个过程都需要锁）。 到这儿，单例模式基本已经讲完了，结尾处，笔者突然想到另一个问题，就是采用类的静态方法，实现单例模式的效果，也是可行的，此处二者有什么不同？ 首先，静态类不能实现接口。（从类的角度说是可以的，但是那样就破坏了静态了。因为接口中不允许有static修饰的方法，所以即使实现了也是非静态的） 其次，单例可以被延迟初始化，静态类一般在第一次加载是初始化。之所以延迟加载，是因为有些类比较庞大，所以延迟加载有助于提升性能。 再次，单例类可以被继承，他的方法可以被覆写。但是静态类内部方法都是static，无法被覆写。 最后一点，单例类比较灵活，毕竟从实现上只是一个普通的Java类，只要满足单例的基本需求，你可以在里面随心所欲的实现一些其它功能，但是静态类不行。从上面这些概括中，基本可以看出二者的区别，但是，从另一方面讲，我们上面最后实现的那个单例模式，内部就是用一个静态类来实现的，所以，二者有很大的关联，只是我们考虑问题的层面不同罢了。两种思想的结合，才能造就出完美的解决方案，就像HashMap采用数组+链表来实现一样，其实生活中很多事情都是这样，单用不同的方法来处理问题，总是有优点也有缺点，最完美的方法是，结合各个方法的优点，才能最好的解决问题 建造者模式（Builder）工厂类模式提供的是创建单个类的模式，而建造者模式是将各种产品集中起来进行管理，用来创建复合对象，所谓复合对象就是某个类具有不同的属性，其实建造者模式就是前面抽象工厂模式和最后的Test结合起来的。 还和前面一样，一个Sender接口，两个实现类MailSender和SmsSender。最后，建造者类如下 public class Builder { private List&lt;Sender&gt; list = new ArrayList&lt;Sender&gt;(); public void produceMailSender(int count){ for(int i=0; i&lt;count; i++){ list.add(new MailSender()); } } public void produceSmsSender(int count){ for(int i=0; i&lt;count; i++){ list.add(new SmsSender()); } } } 从这点看出，建造者模式将很多功能集成到一个类里，这个类可以创造出比较复杂的东西。所以与工厂模式的区别就是：工厂模式关注的是创建单个产品，而建造者模式则关注创建符合对象，多个部分。因此，是选择工厂模式还是建造者模式，依实际情况而定。 原型模式原型模式虽然是创建型的模式，但是与工厂模式没有关系，该模式的思想就是将一个对象作为模型，对其复制、克隆，产生一个和原对象类似的新对象。 public class Prototype implements Cloneable { public Object clone() throws CloneNotSupportedException { Prototype proto = (Prototype) super.clone(); return proto; } }很简单，一个原型类，只需要实现Cloneable接口，覆写clone方法，此处clone方法可以改成任意的名称，因为Cloneable接口是个空接口，你可以任意定义实现类的方法名，如cloneA或者cloneB，因为此处的重点是super.clone()这句话，super.clone()调用的是Object的clone()方法，而在Object类中，clone()是native的。 在这儿，我将结合对象的浅复制和深复制来说一下，首先需要了解对象深、浅复制的概念： 浅复制：将一个对象复制后，基本数据类型的变量都会重新创建，而引用类型，指向的还是原对象所指向的。 深复制：将一个对象复制后，不论是基本数据类型还有引用类型，都是重新创建的。简单来说，就是深复制进行了完全彻底的复制，而浅复制不彻底。 public class Prototype implements Cloneable, Serializable { private static final long serialVersionUID = 1L; private String string; private SerializableObject obj; /* 浅复制 */ public Object clone() throws CloneNotSupportedException { Prototype proto = (Prototype) super.clone(); return proto; } /* 深复制 */ public Object deepClone() throws IOException, ClassNotFoundException { /* 写入当前对象的二进制流 */ ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(this); /* 读出二进制流产生的新对象 */ ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); return ois.readObject(); } public String getString() { return string; } public void setString(String string) { this.string = string; } public SerializableObject getObj() { return obj; } public void setObj(SerializableObject obj) { this.obj = obj; } } class SerializableObject implements Serializable { private static final long serialVersionUID = 1L; } 要实现深复制，需要采用流的形式读入当前对象的二进制输入，再写出二进制数据对应的对象。 7种结构型模式适配器模式、装饰模式、代理模式、外观模式、桥接模式、组合模式、享元模式。其中对象的适配器模式是各种模式的起源，我们看下面的图： 适配器模式将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。主要分为三类：类的适配器模式、对象的适配器模式、接口的适配器模式。 类的适配器模式核心思想就是：有一个Source类，拥有一个方法，待适配，目标接口时Targetable，通过Adapter类，将Source的功能扩展到Targetable里，看代码： public class Source { public void method1() { System.out.println(&quot;this is original method!&quot;); } } public interface Targetable { /* 与原类中的方法相同 */ public void method1(); /* 新类的方法 */ public void method2(); } public class Adapter extends Source implements Targetable { @Override public void method2() { System.out.println(&quot;this is the targetable method!&quot;); } } Adapter类继承Source类，实现Targetable接口，这样Targetable接口的实现类就具有了Source类的功能 对象的适配器模式基本思路和类的适配器模式相同，只是将Adapter类作修改，这次不继承Source类，而是持有Source类的实例，以达到解决兼容性的问题。看图只需要修改Adapter类的源码即可： public class Wrapper implements Targetable { private Source source; public Wrapper(Source source){ super(); this.source = source; } @Override public void method2() { System.out.println(&quot;this is the targetable method!&quot;); } @Override public void method1() { source.method1(); } } 接口的适配器模式接口的适配器是这样的：有时我们写的一个接口中有多个抽象方法，当我们写该接口的实现类时，必须实现该接口的所有方法，这明显有时比较浪费，因为并不是所有的方法都是我们需要的，有时只需要某一些，此处为了解决这个问题，我们引入了接口的适配器模式，借助于一个抽象类，该抽象类实现了该接口，实现了所有的方法，而我们不和原始的接口打交道，只和该抽象类取得联系，所以我们写一个类，继承该抽象类，重写我们需要的方法就行。这个很好理解，在实际开发中，我们也常会遇到这种接口中定义了太多的方法，以致于有时我们在一些实现类中并不是都需要。 public interface Sourceable { public void method1(); public void method2(); } public abstract class Wrapper2 implements Sourceable{ public void method1(){} public void method2(){} } public class SourceSub1 extends Wrapper2 { public void method1(){ System.out.println(&quot;the sourceable interface&apos;s first Sub1!&quot;); } } public class SourceSub2 extends Wrapper2 { public void method2(){ System.out.println(&quot;the sourceable interface&apos;s second Sub2!&quot;); } } 讲了这么多，总结一下三种适配器模式的应用场景： 类的适配器模式：当希望将一个类转换成满足另一个新接口的类时，可以使用类的适配器模式，创建一个新类，继承原有的类，实现新的接口即可。 对象的适配器模式：当希望将一个对象转换成满足另一个新接口的对象时，可以创建一个Wrapper类，持有原类的一个实例，在Wrapper类的方法中，调用实例的方法就行。 接口的适配器模式：当不希望实现一个接口中所有的方法时，可以创建一个抽象类Wrapper，实现所有方法，我们写别的类的时候，继承抽象类即可。 装饰模式（Decorator)顾名思义，装饰模式就是给一个对象增加一些新的功能，而且是动态的，要求装饰对象和被装饰对象实现同一个接口，装饰对象持有被装饰对象的实例，关系图如下： Source类是被装饰类，Decorator类是一个装饰类，可以为Source类动态的添加一些功能 public interface Sourceable { public void method(); } public class Source implements Sourceable { @Override public void method() { System.out.println(&quot;the original method!&quot;); } } public class Decorator implements Sourceable { private Sourceable source; public Decorator(Sourceable source){ super(); this.source = source; } @Override public void method() { System.out.println(&quot;before decorator!&quot;); source.method(); System.out.println(&quot;after decorator!&quot;); } } 装饰器模式的应用场景： 1、需要扩展一个类的功能。 2、动态的为一个对象增加功能，而且还能动态撤销。（继承不能做到这一点，继承的功能是静态的，不能动态增删。） 缺点：产生过多相似的对象，不易排错 代理模式（Proxy）其实每个模式名称就表明了该模式的作用，代理模式就是多一个代理类出来，替原对象进行一些操作，比如我们在租房子的时候回去找中介，为什么呢？因为你对该地区房屋的信息掌握的不够全面，希望找一个更熟悉的人去帮你做，此处的代理就是这个意思。再如我们有的时候打官司，我们需要请律师，因为律师在法律方面有专长，可以替我们进行操作，表达我们的想法。先来看看关系图： public interface Sourceable { public void method(); } public class Source implements Sourceable { @Override public void method() { System.out.println(&quot;the original method!&quot;); } } public class Proxy implements Sourceable { private Source source; public Proxy(){ super(); this.source = new Source(); } @Override public void method() { before(); source.method(); atfer(); } private void atfer() { System.out.println(&quot;after proxy!&quot;); } private void before() { System.out.println(&quot;before proxy!&quot;); } } 代理模式的应用场景： 如果已有的方法在使用的时候需要对原有的方法进行改进，此时有两种办法： 1、修改原有的方法来适应。这样违反了“对扩展开放，对修改关闭”的原则。 2、就是采用一个代理类调用原有的方法，且对产生的结果进行控制。这种方法就是代理模式。 使用代理模式，可以将功能划分的更加清晰，有助于后期维护！ 外观模式（Facade）外观模式是为了解决类与类之家的依赖关系的，像spring一样，可以将类和类之间的关系配置到配置文件中，而外观模式就是将他们的关系放在一个Facade类中，降低了类类之间的耦合度，该模式中没有涉及到接口，看下类图：（我们以一个计算机的启动过程为例） public class CPU { public void startup(){ System.out.println(&quot;cpu startup!&quot;); } public void shutdown(){ System.out.println(&quot;cpu shutdown!&quot;); } } public class Memory { public void startup(){ System.out.println(&quot;memory startup!&quot;); } public void shutdown(){ System.out.println(&quot;memory shutdown!&quot;); } } public class Disk { public void startup(){ System.out.println(&quot;disk startup!&quot;); } public void shutdown(){ System.out.println(&quot;disk shutdown!&quot;); } } public class Computer { private CPU cpu; private Memory memory; private Disk disk; public Computer(){ cpu = new CPU(); memory = new Memory(); disk = new Disk(); } public void startup(){ System.out.println(&quot;start the computer!&quot;); cpu.startup(); memory.startup(); disk.startup(); System.out.println(&quot;start computer finished!&quot;); } public void shutdown(){ System.out.println(&quot;begin to close the computer!&quot;); cpu.shutdown(); memory.shutdown(); disk.shutdown(); System.out.println(&quot;computer closed!&quot;); } 如果我们没有Computer类，那么，CPU、Memory、Disk他们之间将会相互持有实例，产生关系，这样会造成严重的依赖，修改一个类，可能会带来其他类的修改，这不是我们想要看到的，有了Computer类，他们之间的关系被放在了Computer类里，这样就起到了解耦的作用，这，就是外观模式！ 桥接模式（Bridge）桥接模式就是把事物和其具体实现分开，使他们可以各自独立的变化。桥接的用意是：将抽象化与实现化解耦，使得二者可以独立变化，像我们常用的JDBC桥DriverManager一样，JDBC进行连接数据库的时候，在各个数据库之间进行切换，基本不需要动太多的代码，甚至丝毫不用动，原因就是JDBC提供统一接口，每个数据库提供各自的实现，用一个叫做数据库驱动的程序来桥接就行了。我们来看看关系图： 先定义接口： public interface Sourceable { public void method(); } 分别定义两个实现类 public class SourceSub1 implements Sourceable { @Override public void method() { System.out.println(&quot;this is the first sub!&quot;); } } public class SourceSub2 implements Sourceable { @Override public void method() { System.out.println(&quot;this is the second sub!&quot;); } } 定义一个桥，持有Sourceable的一个实例： public abstract class Bridge { private Sourceable source; public void method(){ source.method(); } public Sourceable getSource() { return source; } public void setSource(Sourceable source) { this.source = source; } } public class MyBridge extends Bridge { public void method(){ getSource().method(); } } 这样，就通过对Bridge类的调用，实现了对接口Sourceable的实现类SourceSub1和SourceSub2的调用。接下来我再画个图，大家就应该明白了，因为这个图是我们JDBC连接的原理，有数据库学习基础的，一结合就都懂了。 组合模式（Composite）组合模式有时又叫部分-整体模式在处理类似树形结构的问题时比较方便，看看关系图： public class TreeNode { private String name; private TreeNode parent; private Vector children = new Vector(); public TreeNode(String name){ this.name = name; } public String getName() { return name; } public void setName(String name) { this.name = name; } public TreeNode getParent() { return parent; } public void setParent(TreeNode parent) { this.parent = parent; } //添加孩子节点 public void add(TreeNode node){ children.add(node); } //删除孩子节点 public void remove(TreeNode node){ children.remove(node); } //取得孩子节点 public Enumeration&lt;TreeNode&gt; getChildren(){ return children.elements(); } } public class Tree { TreeNode root = null; public Tree(String name) { root = new TreeNode(name); } public static void main(String[] args) { Tree tree = new Tree(&quot;A&quot;); TreeNode nodeB = new TreeNode(&quot;B&quot;); TreeNode nodeC = new TreeNode(&quot;C&quot;); nodeB.add(nodeC); tree.root.add(nodeB); System.out.println(&quot;build the tree finished!&quot;); } } 使用场景：将多个对象组合在一起进行操作，常用于表示树形结构中，例如二叉树，数等 享元模式（Flyweight）享元模式的主要目的是实现对象的共享，即共享池，当系统中对象多的时候可以减少内存的开销，通常与工厂模式一起使用。FlyWeightFactory负责创建和管理享元单元，当一个客户端请求时，工厂需要检查当前对象池中是否有符合条件的对象，如果有，就返回已经存在的对象，如果没有，则创建一个新对象，FlyWeight是超类。一提到共享池，我们很容易联想到Java里面的JDBC连接池，想想每个连接的特点，我们不难总结出：适用于作共享的一些个对象，他们有一些共有的属性，就拿数据库连接池来说，url、driverClassName、username、password及dbname，这些属性对于每个连接来说都是一样的，所以就适合用享元模式来处理，建一个工厂类，将上述类似属性作为内部数据，其它的作为外部数据，在方法调用时，当做参数传进来，这样就节省了空间，减少了实例的数量。 public class ConnectionPool { private Vector&lt;Connection&gt; pool; /*公有属性*/ private String url = &quot;jdbc:mysql://localhost:3306/test&quot;; private String username = &quot;root&quot;; private String password = &quot;root&quot;; private String driverClassName = &quot;com.mysql.jdbc.Driver&quot;; private int poolSize = 100; private static ConnectionPool instance = null; Connection conn = null; /*构造方法，做一些初始化工作*/ private ConnectionPool() { pool = new Vector&lt;Connection&gt;(poolSize); for (int i = 0; i &lt; poolSize; i++) { try { Class.forName(driverClassName); conn = DriverManager.getConnection(url, username, password); pool.add(conn); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); } } } /* 返回连接到连接池 */ public synchronized void release() { pool.add(conn); } /* 返回连接池中的一个数据库连接 */ public synchronized Connection getConnection() { if (pool.size() &gt; 0) { Connection conn = pool.get(0); pool.remove(conn); return conn; } else { return null; } } } 通过连接池的管理，实现了数据库连接的共享，不需要每一次都重新创建连接，节省了数据库重新创建的开销，提升了系统的性能！ 11种行为型模式策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 先来张图，看看这11中模式的关系： 第一类：通过父类与子类的关系进行实现。第二类：两个类之间。第三类：类的状态。第四类：通过中间类 策略模式（strategy）策略模式定义了一系列算法，并将每个算法封装起来，使他们可以相互替换，且算法的变化不会影响到使用算法的客户。需要设计一个接口，为一系列实现类提供统一的方法，多个实现类实现该接口，设计一个抽象类（可有可无，属于辅助类），提供辅助函数，关系图如下： 图中ICalculator提供同意的方法，AbstractCalculator是辅助类，提供辅助方法，接下来，依次实现下每个类： public interface ICalculator { public int calculate(String exp); } public abstract class AbstractCalculator { public int[] split(String exp,String opt){ String array[] = exp.split(opt); int arrayInt[] = new int[2]; arrayInt[0] = Integer.parseInt(array[0]); arrayInt[1] = Integer.parseInt(array[1]); return arrayInt; } } 三个实现类 public class Plus extends AbstractCalculator implements ICalculator { @Override public int calculate(String exp) { int arrayInt[] = split(exp,&quot;\\+&quot;); return arrayInt[0]+arrayInt[1]; } } public class Minus extends AbstractCalculator implements ICalculator { @Override public int calculate(String exp) { int arrayInt[] = split(exp,&quot;-&quot;); return arrayInt[0]-arrayInt[1]; } } public class Multiply extends AbstractCalculator implements ICalculator { @Override public int calculate(String exp) { int arrayInt[] = split(exp,&quot;\\*&quot;); return arrayInt[0]*arrayInt[1]; } } 策略模式的决定权在用户，系统本身提供不同算法的实现，新增或者删除算法，对各种算法做封装。因此，策略模式多用在算法决策系统中，外部用户只需要决定用哪个算法即可。 模板方法模式（Template Method）解释一下模板方法模式，就是指：一个抽象类中，有一个主方法，再定义1…n个方法，可以是抽象的，也可以是实际的方法，定义一个类，继承该抽象类，重写抽象方法，通过调用抽象类，实现对子类的调用，先看个关系图： 就是在AbstractCalculator类中定义一个主方法calculate，calculate()调用spilt()等，Plus和Minus分别继承AbstractCalculator类，通过对AbstractCalculator的调用实现对子类的调用，看下面的例子： public abstract class AbstractCalculator { /*主方法，实现对本类其它方法的调用*/ public final int calculate(String exp,String opt){ int array[] = split(exp,opt); return calculate(array[0],array[1]); } /*被子类重写的方法*/ abstract public int calculate(int num1,int num2); public int[] split(String exp,String opt){ String array[] = exp.split(opt); int arrayInt[] = new int[2]; arrayInt[0] = Integer.parseInt(array[0]); arrayInt[1] = Integer.parseInt(array[1]); return arrayInt; } } public class Plus extends AbstractCalculator { @Override public int calculate(int num1,int num2) { return num1 + num2; } } public class StrategyTest { public static void main(String[] args) { String exp = &quot;8+8&quot;; AbstractCalculator cal = new Plus(); int result = cal.calculate(exp, &quot;\\+&quot;); System.out.println(result); } } 我跟踪下这个小程序的执行过程：首先将exp和”\+”做参数，调用AbstractCalculator类里的calculate(String,String)方法，在calculate(String,String)里调用同类的split()，之后再调用calculate(int ,int)方法，从这个方法进入到子类中，执行完return num1 + num2后，将值返回到AbstractCalculator类，赋给result，打印出来。正好验证了我们开头的思路。 观察者模式（Observer）包括这个模式在内的接下来的四个模式，都是类和类之间的关系，不涉及到继承.观察者模式很好理解，类似于邮件订阅和RSS订阅，当我们浏览一些博客或wiki时，经常会看到RSS图标，就这的意思是，当你订阅了该文章，如果后续有更新，会及时通知你。其实，简单来讲就一句话：当一个对象变化时，其它依赖该对象的对象都会收到通知，并且随着变化！对象之间是一种一对多的关系。先来看看关系图： MySubject类就是我们的主对象，Observer1和Observer2是依赖于MySubject的对象，当MySubject变化时，Observer1和Observer2必然变化。AbstractSubject类中定义着需要监控的对象列表，可以对其进行修改：增加或删除被监控对象，且当MySubject变化时，负责通知在列表内存在的对象。我们看实现代码： 一个Observer接口： public interface Observer { public void update(); } 两个实现类 public class Observer1 implements Observer { @Override public void update() { System.out.println(&quot;observer1 has received!&quot;); } } public class Observer2 implements Observer { @Override public void update() { System.out.println(&quot;observer2 has received!&quot;); } } Subject接口及实现类： public interface Subject { /*增加观察者*/ public void add(Observer observer); /*删除观察者*/ public void del(Observer observer); /*通知所有的观察者*/ public void notifyObservers(); /*自身的操作*/ public void operation(); } public abstract class AbstractSubject implements Subject { private Vector&lt;Observer&gt; vector = new Vector&lt;Observer&gt;(); @Override public void add(Observer observer) { vector.add(observer); } @Override public void del(Observer observer) { vector.remove(observer); } @Override public void notifyObservers() { Enumeration&lt;Observer&gt; enumo = vector.elements(); while(enumo.hasMoreElements()){ enumo.nextElement().update(); } } } public class MySubject extends AbstractSubject { @Override public void operation() { System.out.println(&quot;update self!&quot;); notifyObservers(); } } public class ObserverTest { public static void main(String[] args) { Subject sub = new MySubject(); sub.add(new Observer1()); sub.add(new Observer2()); sub.operation(); } } 迭代子模式（Iterator）顾名思义，迭代器模式就是顺序访问聚集中的对象，一般来说，集合中非常常见，如果对集合类比较熟悉的话，理解本模式会十分轻松。这句话包含两层意思：一是需要遍历的对象，即聚集对象，二是迭代器对象，用于对聚集对象进行遍历访问。我们看下关系图： 这个思路和我们常用的一模一样，MyCollection中定义了集合的一些操作，MyIterator中定义了一系列迭代操作，且持有Collection实例，我们来看看实现代码： public interface Collection { public Iterator iterator(); /*取得集合元素*/ public Object get(int i); /*取得集合大小*/ public int size(); } public interface Iterator { //前移 public Object previous(); //后移 public Object next(); public boolean hasNext(); //取得第一个元素 public Object first(); } 两个实现： public class MyCollection implements Collection { public String string[] = {&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;}; @Override public Iterator iterator() { return new MyIterator(this); } @Override public Object get(int i) { return string[i]; } @Override public int size() { return string.length; } } public class MyIterator implements Iterator { private Collection collection; private int pos = -1; public MyIterator(Collection collection){ this.collection = collection; } @Override public Object previous() { if(pos &gt; 0){ pos--; } return collection.get(pos); } @Override public Object next() { if(pos&lt;collection.size()-1){ pos++; } return collection.get(pos); } @Override public boolean hasNext() { if(pos&lt;collection.size()-1){ return true; }else{ return false; } } @Override public Object first() { pos = 0; return collection.get(pos); } } 此处我们貌似模拟了一个集合类的过程 责任链模式（Chain of Responsibility）有多个对象，每个对象持有对下一个对象的引用，这样就会形成一条链，请求在这条链上传递，直到某一对象决定处理该请求。但是发出者并不清楚到底最终那个对象会处理该请求，所以，责任链模式可以实现，在隐瞒客户端的情况下，对系统进行动态的调整。先看看关系图： Abstracthandler类提供了get和set方法，方便MyHandle类设置和修改引用对象，MyHandle类是核心，实例化后生成一系列相互持有的对象，构成一条链。 public interface Handler { public void operator(); } public abstract class AbstractHandler { private Handler handler; public Handler getHandler() { return handler; } public void setHandler(Handler handler) { this.handler = handler; } } public class MyHandler extends AbstractHandler implements Handler { private String name; public MyHandler(String name) { this.name = name; } @Override public void operator() { System.out.println(name+&quot;deal!&quot;); if(getHandler()!=null){ getHandler().operator(); } } } public class Test { public static void main(String[] args) { MyHandler h1 = new MyHandler(&quot;h1&quot;); MyHandler h2 = new MyHandler(&quot;h2&quot;); MyHandler h3 = new MyHandler(&quot;h3&quot;); h1.setHandler(h2); h2.setHandler(h3); h1.operator(); } } 链接上的请求可以是一条链，可以是一个树，还可以是一个环，模式本身不约束这个，需要我们自己去实现，同时，在一个时刻，命令只允许由一个对象传给另一个对象，而不允许传给多个对象。 命令模式（Command）命令模式很好理解，举个例子，司令员下令让士兵去干件事情，从整个事情的角度来考虑，司令员的作用是，发出口令，口令经过传递，传到了士兵耳朵里，士兵去执行。这个过程好在，三者相互解耦，任何一方都不用去依赖其他人，只需要做好自己的事儿就行，司令员要的是结果，不会去关注到底士兵是怎么实现的。我们看看关系图：Invoker是调用者（司令员），Receiver是被调用者（士兵），MyCommand是命令，实现了Command接口，持有接收对象，看实现代码： public interface Command { public void exe(); } public class MyCommand implements Command { private Receiver receiver; public MyCommand(Receiver receiver) { this.receiver = receiver; } @Override public void exe() { receiver.action(); } } public class Receiver { public void action(){ System.out.println(&quot;command received!&quot;); } } public class Invoker { private Command command; public Invoker(Command command) { this.command = command; } public void action(){ command.exe(); } } 命令模式的目的就是达到命令的发出者和执行者之间解耦，实现请求和执行分开，熟悉Struts的同学应该知道，Struts其实就是一种将请求和呈现分离的技术，其中必然涉及命令模式的思想！ 备忘录模式（Memento)主要目的是保存一个对象的某个状态，以便在适当的时候恢复对象，个人觉得叫备份模式更形象些，通俗的讲下：假设有原始类A，A中有各种属性，A可以决定需要备份的属性，备忘录类B是用来存储A的一些内部状态，类C呢，就是一个用来存储备忘录的，且只能存储，不能修改等操作。做个图来分析一下： Original类是原始类，里面有需要保存的属性value及创建一个备忘录类，用来保存value值。Memento类是备忘录类，Storage类是存储备忘录的类，持有Memento类的实例，该模式很好理解。 public class Original { private String value; public String getValue() { return value; } public void setValue(String value) { this.value = value; } public Original(String value) { this.value = value; } public Memento createMemento(){ return new Memento(value); } public void restoreMemento(Memento memento){ this.value = memento.getValue(); } } public class Memento { private String value; public Memento(String value) { this.value = value; } public String getValue() { return value; } public void setValue(String value) { this.value = value; } } public class Storage { private Memento memento; public Storage(Memento memento) { this.memento = memento; } public Memento getMemento() { return memento; } public void setMemento(Memento memento) { this.memento = memento; } } public class Test { public static void main(String[] args) { // 创建原始类 Original origi = new Original(&quot;egg&quot;); // 创建备忘录 Storage storage = new Storage(origi.createMemento()); // 修改原始类的状态 System.out.println(&quot;初始化状态为：&quot; + origi.getValue()); origi.setValue(&quot;niu&quot;); System.out.println(&quot;修改后的状态为：&quot; + origi.getValue()); // 回复原始类的状态 origi.restoreMemento(storage.getMemento()); System.out.println(&quot;恢复后的状态为：&quot; + origi.getValue()); } } 新建原始类时，value被初始化为egg，后经过修改，将value的值置为niu，最后倒数第二行进行恢复状态，结果成功恢复了。其实我觉得这个模式叫“备份-恢复”模式最形象。 状态模式（State）核心思想就是：当对象的状态改变时，同时改变其行为，很好理解！就拿QQ来说，有几种状态，在线、隐身、忙碌等，每个状态对应不同的操作，而且你的好友也能看到你的状态，所以，状态模式就两点：1、可以通过改变状态来获得不同的行为。2、你的好友能同时看到你的变化。看图： State类是个状态类，Context类可以实现切换，我们来看看代码： public class State { private String value; public String getValue() { return value; } public void setValue(String value) { this.value = value; } public void method1(){ System.out.println(&quot;execute the first opt!&quot;); } public void method2(){ System.out.println(&quot;execute the second opt!&quot;); } } public class Context { private State state; public Context(State state) { this.state = state; } public State getState() { return state; } public void setState(State state) { this.state = state; } public void method() { if (state.getValue().equals(&quot;state1&quot;)) { state.method1(); } else if (state.getValue().equals(&quot;state2&quot;)) { state.method2(); } } } 根据这个特性，状态模式在日常开发中用的挺多的，尤其是做网站的时候，我们有时希望根据对象的某一属性，区别开他们的一些功能，比如说简单的权限控制等。 访问者模式（Visitor）访问者模式把数据结构和作用于结构上的操作解耦合，使得操作集合可相对自由地演化。访问者模式适用于数据结构相对稳定算法又易变化的系统。因为访问者模式使得算法操作增加变得容易。若系统数据结构对象易于变化，经常有新的数据对象增加进来，则不适合使用访问者模式。访问者模式的优点是增加操作很容易，因为增加操作意味着增加新的访问者。访问者模式将有关行为集中到一个访问者对象中，其改变不影响系统数据结构。其缺点就是增加新的数据结构很困难。 简单来说，访问者模式就是一种分离对象数据结构与行为的方法，通过这种分离，可达到为一个被访问者动态添加新的操作而无需做其它的修改的效果。简单关系图： 一个Visitor类，存放要访问的对象， public interface Visitor { public void visit(Subject sub); } public class MyVisitor implements Visitor { @Override public void visit(Subject sub) { System.out.println(&quot;visit the subject：&quot;+sub.getSubject()); } } Subject类，accept方法，接受将要访问它的对象，getSubject()获取将要被访问的属性， public interface Subject { public void accept(Visitor visitor); public String getSubject(); } public class MySubject implements Subject { @Override public void accept(Visitor visitor) { visitor.visit(this); } @Override public String getSubject() { return &quot;love&quot;; } } 该模式适用场景：如果我们想为一个现有的类增加新功能，不得不考虑几个事情：1、新功能会不会与现有功能出现兼容性问题？2、以后会不会再需要添加？3、如果类不允许修改代码怎么办？面对这些问题，最好的解决方法就是使用访问者模式，访问者模式适用于数据结构相对稳定的系统，把数据结构和算法解耦， 中介者模式（Mediator）中介者模式也是用来降低类类之间的耦合的，因为如果类类之间有依赖关系的话，不利于功能的拓展和维护，因为只要修改一个对象，其它关联的对象都得进行修改。如果使用中介者模式，只需关心和Mediator类的关系，具体类类之间的关系及调度交给Mediator就行，这有点像spring容器的作用。先看看图： User类统一接口，User1和User2分别是不同的对象，二者之间有关联，如果不采用中介者模式，则需要二者相互持有引用，这样二者的耦合度很高，为了解耦，引入了Mediator类，提供统一接口，MyMediator为其实现类，里面持有User1和User2的实例，用来实现对User1和User2的控制。这样User1和User2两个对象相互独立，他们只需要保持好和Mediator之间的关系就行，剩下的全由MyMediator类来维护！基本实现 public interface Mediator { public void createMediator(); public void workAll(); } public class MyMediator implements Mediator { private User user1; private User user2; public User getUser1() { return user1; } public User getUser2() { return user2; } @Override public void createMediator() { user1 = new User1(this); user2 = new User2(this); } @Override public void workAll() { user1.work(); user2.work(); } } public abstract class User { private Mediator mediator; public Mediator getMediator(){ return mediator; } public User(Mediator mediator) { this.mediator = mediator; } public abstract void work(); } public class User1 extends User { public User1(Mediator mediator){ super(mediator); } @Override public void work() { System.out.println(&quot;user1 exe!&quot;); } } public class User2 extends User { public User2(Mediator mediator){ super(mediator); } @Override public void work() { System.out.println(&quot;user2 exe!&quot;); } } 解释器模式（Interpreter）一般主要应用在OOP开发中的编译器的开发中，所以适用面比较窄。 Context类是一个上下文环境类，Plus和Minus分别是用来计算的实现，代码如下： public interface Expression { public int interpret(Context context); } public class Plus implements Expression { @Override public int interpret(Context context) { return context.getNum1()+context.getNum2(); } } public class Minus implements Expression { @Override public int interpret(Context context) { return context.getNum1()-context.getNum2(); } } public class Context { private int num1; private int num2; public Context(int num1, int num2) { this.num1 = num1; this.num2 = num2; } public int getNum1() { return num1; } public void setNum1(int num1) { this.num1 = num1; } public int getNum2() { return num2; } public void setNum2(int num2) { this.num2 = num2; } } public class Test { public static void main(String[] args) { // 计算9+2-8的值 int result = new Minus().interpret((new Context(new Plus().interpret(new Context(9, 2)), 8))); System.out.println(result); } } 解释器模式用来做各种各样的解释器，如正则表达式等的解释器等等！]]></content>
      <categories>
        <category>设计理论</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建高可用高并发系统]]></title>
    <url>%2F2019%2F08%2F18%2F%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[高可用高并发系统设计架构设计三大定律墨菲定律 任何事没有表面看起来那么简单所有的事都会比预计的时间长 - 可能出错的事情总会出错 - 担心某种事情发生，那么它就更有可能发生 康威定律 系统架构师公司组织架构的反映按照业务闭环进行系统拆分/组织架构划分，实现闭环、高内聚、低耦合，减少沟通成本如果沟通出现问题，应该考虑进行系统和组织架构的调整 适合时机进行系统拆分。不要一开始就吧系统、服务拆分拆的非常细，虽然闭环，但是每个人维护的系统多，维护成本高 - 微服务架构的理论基础 - 康威定律 二八定律 80%的结果取决于20%的原因 高可用所谓高可用，即要保证系统在几乎任何时候都能正常运行，功能正常，保证系统不出问题，“永不宕机”。 1.单机系统下的可用性问题，从Nginx-&gt;Tomcat-&gt;db/soa来看，单点问题会影响系统的高可用。比如要是这个链路上其中一个单点挂了，整个系统就不可以用了。（Nginx负载均衡等，Tomcat提供服务，db存储数据）。所以引申出来主备/集群模式，防止单点问题。2.高并发场景下，请求过多也会因为后端瓶颈点引起整个系统down掉，如周杰伦演唱会抢票，高铁抢票，所以一般情况下对并发场景我们会限流，采用mq等消息队列形式削峰，保证后端系统不会down掉。 设计建议1.减少单点去去单点首先要识别出整个系统所有主链路的单点，如机房（同城异地双机房）、应用服务器、DNS服务器、SFTP服务器、LBS（基于位置服务）缓存服务器、数据库、消息服务器、代理服务器和专线等。如系统通过专线调用对方服务，需要考虑同时拉联通和电信的专线，联通或电信的专线还是有一定效率出现问题但是同时出现问题的概率就会小很多。优先使用软负载（负载软件如Nginx），使用硬负载（外部网络和服务器间的硬件设备如F5）兜底。 2.减少依赖减少DNS依赖，减少远程服务依赖。DNS依赖可以尝试设置本地host，用工具给所有服务器推送最新的域名映射关系，通过本地缓存或者近端服务减少RPC（远程过程调用）调用。 3.限制循环避免无限死循环，导致CPU利用率百分百，可以设置for循环的最大循环次数，如最大1000次 4.增加限流对外服务增加限流，注意限流的值最好是压测过的，如果没有压测过，只能设置成平时的峰值流量，否则可能增加一点流量就不能提供服务了。 5.控制流量避免异常流量对应用服务器产生影响，可以对指定指定服务设置流量限制，如QPS(每秒查询率),TPS(每秒处理事务数),QPH(每小时总请求量),QPD(每天总请求量) 6.精准监控对CPU利用率，load，内存，带框，系统调用量，应用错误量，PV(页面浏览量),UV(独立访客量，以cookie为主)和业务进行监控，避免内存泄露和异常代码对系统产生影响，配置一定要精准，如平时设置内存利用率是50%，监控可以配置成60%进行报警，这样可以提前感知内存泄露问题，避免应用无响应。 7.无状态服务器不能保存用户状态数据，如在集群下不能用static保存用户数据，不能长时间把用户文件存放在服务器本地。服务器有状态会难以扩容，出现单点问题。 8.容量规划定期对容量进行评估，如大促前进行压测和容量预估，根据需要进行扩容。如双11进行扩容。 9.功能开关打开和关闭某些功能，如消息量过大，系统处理不了，把开关打开后直接丢弃信息不处理。上线新功能增加开关，如果出现问题就关闭新功能。 10.设置超时设置连接超时和读超时设置，不应该太大，如果是内部调用连接超时可以设置成1秒，读超时3秒，外部系统调用连接超时可以设置成3秒，读超时设置20秒。 11.重试策略当调用外部服务异常时可以设置重试策略，每次重试时间递增，但需要设置最大重试次数和重试开关，避免对下游系统产生影响。 12.隔离应用隔离，模块隔离，机房隔离，线程池隔离。按照优先级，不变和变几个维度来隔离应用和模块，如抽象和不变的代码放在一个模块，这个模块的代码几乎不会修改，可用性高，经常变的业务逻辑放在一个模块里，这样就算出现问题，也只影响某一业务。不同业务使用不同的线程池，避免低先级任务阻塞高优先级，或者高优先级任务过多影响低优先级任务永不执行。 13.异步调用同步调用变成异步调用，解决远程调用障碍或者调用超时对系统的影响。 14.热点缓存对热点数据进行缓存，降低RPC调用。如B系统提供名单服务，B系统可以提供一个client SDK提供近端缓存服务，定期去服务器读取数据，减少RPC调用。 15.缓存容灾当数据库不可用时可以使用缓存的数据。并设置分级缓存，如优先读取本地缓存，其次分布式缓存。 16.分级缓存优先读取本地缓存，其次读取分布式缓存。通过推模式更新本地缓存。 17.系统分级对系统进行分级，如ABC三个等级，高级别系统不依赖与低级别系统，并且高级别系统比低级别系统高可用虑高 18.服务降级如果系统出现响应缓慢等状况，可以关闭部分功能，从而释放系统资源，保证核心服务的正常运行。需要识别哪些服务可以降级，比如突然有大量消息流入，导致服务不可用，我们会直接把消息丢掉。或者设置流控，拒绝为低级别系统提供服务。 19.流量蓄洪当流量陡增时，可以将请求进行蓄洪，如把请求保存在数据库中，再按照指定的QPS进行泄洪，有效保护下游系统，也保证了服务的可用性。调用对方系统，对方系统缓慢或者无响应时，可采取自动蓄洪。 20.服务权重在集群环境中，可自动识别高性能服务，拒绝调用性能低的服务，如在集群环境中，对调用超时的服务器进行权重降低，优先调用权重高的服务器。 21.依赖简化减少系统间的依赖，如使用消息驱动。A和B系统通过消息服务器传递数据，A和B系统使用数据库进行读写分离，A系统负责往数据库写数据，B系统负责读数据，因为数据存放在数据库中，当A不可用时，短时间不影响B系统提供服务。 22.弹性扩容根据资源的使用率自动或者手动进行扩容。如带宽不够用，快速增加带宽。 23.灰度和回滚发布新功能只让部分服务器生效，且观察几天逐渐切流，如果出现问题只影响部分客户。出现问题快速回滚，或者直接下线灰度的机器。 24.减少远程调用优先调用本地JVM内服务，其次是同机房服务，然后是同城服务，最后是跨城服务。如A调用B，B调用互联网C的系统获取数据，B系统可以把数据缓存起来，并设置数据的保鲜度，减少B对C的依赖。配置中心把注册服务的地址推送到调用服务的系统本地。参数中心把参数配置信息推送到系统的本地内存，而不是让系统去远程服务器获取参数信息。 25.熔断机制增加熔断机制，当监控出现数据大幅涨跌时，及时中断，避免对业务产生更大影响。如我们做指标计算时，指标可以计算慢，但不能算错，如果发现某个用户的指标环比或同比增长一倍或跌零，会考虑保存所有信息，并终止该用户的指标计算。 26.运行时加载模块我们会把经常变的业务代码变成一个个业务模块，使用JAVA的ClassLoader在运行时动态加载和卸载模块，当模块有问题时，可以快速修复。 27.代码扫描#使用IDEA代码分析等工具进行代码扫描，识别出程序中的BUG,如空指针异常，循环依赖。 28.自动备份程序，系统配置和数据定期进行备份。可以使用Linux命令和shell脚本定时执行备份策略，自动进行本地或者异地备份。出现问题时能快速重新部署。 29.线上测压系统的对外服务需要进行压测，知道该服务承受的QPS和TPS,从而做出相对精准的限流。 高并发所谓高并发，即能够同时接受处理千万级乃至亿万级的并发访问。 高并发又分为cpu密集型和io密集型。前者要求网站的计算能力要高，后者要求网站的吞吐能力要高。 高并发设计有几个原则如下:1.无状态无状态应用，便于水平扩展 有状态配置可通过配置中心实现无状态 实践: Disconf、Yaconf、Zookpeer、Consul、Confd、Diamond、Xdiamond等 2.拆分系统维度：按照系统功能、业务拆分，如购物车，结算，订单等 功能维度：对系统功能在做细粒度拆分 读写维度：根据读写比例特征拆分；读多，可考虑多级缓存；写多，可考虑分库分表 AOP维度： 根据访问特征，按照AOP进行拆分，比如商品详情页可分为CDN、页面渲染系统，CDN就是一个AOP系统 模块维度：对整体代码结构划分Web、Service、DAO 3.服务化服务化演进: 进程内服务-单机远程服务-集群手动注册服务-自动注册和发现服务-服务的分组、隔离、路由-服务治理 考虑服务分组、隔离、限流、黑白名单、超时、重试机制、路由、故障补偿等 实践：利用Nginx、HaProxy、LVS等实现负载均衡，ZooKeeper、Consul等实现自动注册和发现服 4.消息队列目的: 服务解耦(一对多消费)、异步处理、流量削峰缓冲等 大流量缓冲： 牺牲强一致性，保证最终一致性 (案例：库存扣减，现在Redis中做扣减，记录扣减日志，通过后台进程将扣减日志应用到DB) 数据校对: 解决异步消息机制下消息丢失问题 5.数据异构数据异构: 通过消息队列机制接收数据变更，原子化存储 数据闭环: 屏蔽多从数据来源，将数据异构存储，形成闭环 6.缓存用户层: DNS缓存 浏览器DNS缓存 操作系统DNS缓存 本地DNS服务商缓存 DNS服务器缓存 客户端缓存 浏览器缓存(Expires、Cache-Control、Last-Modified、Etag) App客户缓存(js/css/image...) 代理层： CDN缓存(一般基于ATS、Varnish、Nginx、Squid等构建,边缘节点-二级节点-中心节点-源站) 接入层： Opcache： 缓存PHP的Opcodes Proxy_cache： 代理缓存,可以存储到/dev/shm或者SSD FastCGI Cache Nginx+Lua+Redis: 业务数据缓存 应用层： 页面静态化 业务数据缓存(Redis/Memcached/本地文件等) 消息队列 数据层： NoSQL： Redis、Memcache、SSDB等 MySQL： Innodb/MyISAM等Query Cache、Key Cache、Innodb Buffer Size等 系统层： CPU : L1/L2/L3 Cache/NUMA 内存 磁盘：磁盘本身缓存、dirtyratio/dirtybackground_ratio、阵列卡本身缓存]]></content>
      <categories>
        <category>设计理论</category>
      </categories>
      <tags>
        <tag>系统设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA中的相等比较]]></title>
    <url>%2F2019%2F08%2F16%2FJAVA%E4%B8%AD%E7%9A%84%E7%9B%B8%E7%AD%89%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[1、 == java中的数据类型，可分为两类: 1.基本数据类型，也称原始数据类型 byte、short、char、int、long、float、double、boolean，他们之间的比较 使用==时，比较的是他们的值 2.引用类型（类、接口、数组） 当他们使用==比较的时候，比较的是内存中存放的地址，所以，除非是同一个new出来的对象，他们比较结果为true，否则为false 当基本数据类型与其对应的对象比较时如，int和Integer进行比较时，Integer会自动拆箱为int，进行值的比较。 对象存放在堆中，栈中存放着对象的引用（地址）。由此可见，== 比较的是栈中的值进行比较。如果要比较两个对象的内容是否相等，那么就要重写equal方法了。 public static void main(String[] args) { int int1 = 12; int int2 = 12; Integer Integer1 = new Integer(12); Integer Integer2 = new Integer(12); Integer Integer3 = new Integer(127); Integer a1 = 127; Integer b1 = 127; Integer a = 128; Integer b = 128; String s1 = &quot;str&quot;; String s2 = &quot;str&quot;; String str1 = new String(&quot;str&quot;); String str2 = new String(&quot;str&quot;); System.out.println(&quot;int1==int2:&quot; + (int1 == int2)); System.out.println(&quot;int1==Integer1:&quot; + (int1 == Integer1)); System.out.println(&quot;Integer1==Integer2:&quot; + (Integer1 == Integer2)); System.out.println(&quot;Integer3==b1:&quot; + (Integer3 == b1)); System.out.println(&quot;a1==b1:&quot; + (a1 == b1)); System.out.println(&quot;a==b:&quot; + (a == b)); System.out.println(&quot;s1==s2:&quot; + (s1 == s2)); System.out.println(&quot;s1==str1:&quot; + (s1 == str1)); System.out.println(&quot;str1==str2:&quot; + (str1 == str2)); } 输出结果： int1==int2:true int1==Integer1:true //Integer会自动拆箱为int，所以为true Integer1==Integer2:false//不同对象，在内存存放地址不同，所以为false Integer3==b1:false//Integer3指向new的对象地址，b1指向缓存中127地址，地址不同，所以为false a1==b1:true a==b:false s1==s2:true s1==str1:false str1==str2:false ！！！敲黑板 Integer b1 = 127;java在编译的时候,被翻译成-&gt; Integer b1 = Integer.valueOf(127); 而该方法源码: public static Integer valueOf(int i) { assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } 所以，对应-128-127之间的数，会进行缓存，Integer b1 = 127时，会将127进行缓存，下次再写Integer i6 = 127时，就会直接从缓存中取，就不会new了。而b的值是128，因此不会有缓存。所以a1==b1:true a==b:false 2、 equals 1.默认情况下（即equals方法未被覆盖）equals方法都是调用Object类的equals方法，，而Object的equals方法主要用于判断对象的内存地址引用是不是同一个地址（是不是同一个对象）。下面是Object类中equals方法： public boolean equals(Object obj) { return (this == obj); } 所以此时，equals方法与==本质上是一样的 2.若类的equals方法被覆盖，则比较时根据代码实现的规则比较，一般都是比较对象内容是否相等。下面是String类equals方法的覆盖: public boolean equals(Object anObject) { if (this == anObject) { return true; } if (anObject instanceof String) { String anotherString = (String)anObject; int n = count; if (n == anotherString.count) { char v1[] = value; char v2[] = anotherString.value; int i = offset; int j = anotherString.offset; while (n– != 0) { if (v1[i++] != v2[j++]) return false; } return true; } } return false; } 即String中equals方法判断相等的步骤是： 1.若A==B 即是同一个String对象 返回true 2.若对比对象是String类型则继续，否则返回false 3.判断A、B长度是否一样，不一样的话返回false 4。逐个字符比较，若有不相等字符，返回false ！！！敲黑板 equals方法的覆盖需要注意5点 1 自反性：对任意引用值X，x.equals(x)的返回值一定为true. 2 对称性：对于任何引用值x,y,当且仅当y.equals(x)返回值为true时，x.equals(y)的返回值一定为true; 3 传递性：如果x.equals(y)=true, y.equals(z)=true,则x.equals(z)=true 4 一致性：如果参与比较的对象没任何改变，则对象比较的结果也不应该有任何改变 5 非空性：任何非空的引用值X，x.equals(null)的返回值一定为false 参照5个注意点，写出高质量的equals方法可以参考以下方式: 1.使用==符号检查“参数是否为这个对象的引用”。如果是，则返回true。这只不过是一种性能优化，如果比较操作有可能很昂贵，就值得这么做。 2.使用instanceof操作符检查“参数是否为正确的类型”。如果不是，则返回false。一般来说，所谓“正确的类型”是指equals方法所在的那个类。 3.把参数转换成正确的类型。因为转换之前进行过instanceof测试，所以确保会成功。 4.对于该类中的每个“关键”域，检查参数中的域是否与该对象中对应的域相匹配。如果这些测试全部成功，则返回true;否则返回false。 5.当编写完成了equals方法之后，检查“对称性”、“传递性”、“一致性”。 3、hashcode hashCode()方法返回的是一个数值，即hash码。它的主要用途是在对象进行散列的时候作为key输入。Object类提供的默认实现确保每个对象的hash码不同(在对象的内存地址基础上用特殊算法得出). 所有散列函数都有一个基本特征: 1.如果a=b，则h(a)=h(b) 2.如果a！=b 则h(a)和h(b)有可能得到相同的散列值 Object 的hashCode方法：返回一个int类型 哈希值的作用 举例来说,java集合中Set无序不重复，那么就存在一个问题，如何保证元素不重复。调用Obejct.equals方法可以判断两个元素是否相等。但是，如果使用顺序查找，当元素很多时，查找的复杂度就会变大。如，set已有1000元素，新增元素时最坏需要调用1000次equal方法确定是否已经存在。但是，当使用哈希表的时候，新增元素，计算该元素的hash值，从哈希表中看以该值为下标是否存在元素，即可判断重复与否。当然也存在哈希冲突解决问题。但大大减少了equal调用次数 4、equals和hashCode的关系 Java对于eqauls方法和hashCode方法是这样规定的： (1)同一对象上多次调用hashCode()方法，总是返回相同的整型值。 (2)如果a.equals(b)，则一定有a.hashCode() 一定等于 b.hashCode()。 (3)如果!a.equals(b)，则a.hashCode() 不一定等于 b.hashCode()。此时如果a.hashCode() 总是不等于 b.hashCode()，会提高hashtables的性能。 (4)a.hashCode()==b.hashCode() 则 a.equals(b)可真可假 (5)a.hashCode()！= b.hashCode() 则 a.equals(b)为假。 简而言之就是: 1、两个对象equal，java环境会认为hashcode一定相等 2、两个对象不equal，二者hashcode可能相等 反过来说 1、两个对象hashcode相等，不一定equal 2、两个对象hashcode不等，一等不equal ！！！敲黑板 关于这两个方法的重要规范： 规范1：若重写equals(Object obj)方法，有必要重写hashcode()方法，确保通过equals(Object obj)方法判断结果为true的两个对象具备相等的hashcode()返回值。说得简单点就是：“如果两个对象相同，那么他们的hashcode应该相等”。不过请注意：这个只是规范，如果你非要写一个类让equals(Object obj)返回true而hashcode()返回两个不相等的值，编译和运行都是不会报错的。不过这样违反了Java规范，程序也就埋下了BUG。 规范2：如果equals(Object obj)返回false，即两个对象“不相同”，并不要求对这两个对象调用hashcode()方法得到两个不相同的数。说的简单点就是：“如果两个对象不相同，他们的hashcode可能相同”。 5、为什么覆盖equals方法时总要覆盖hashCode 一个很常见的错误根源在于没有覆盖hashCode方法。在每个覆盖了equals方法的类中，也必须覆盖hashCode方法。如果不这样做的话，就会违反Object.hashCode的通用约定，从而导致该类无法结合所有基于散列的集合一起正常运作，这样的集合包括HashMap、HashSet和Hashtable。 1.在应用程序的执行期间，只要对象的equals方法的比较操作所用到的信息没有被修改，那么对这同一个对象调用多次，hashCode方法都必须始终如一地返回同一个整数。在同一个应用程序的多次执行过程中，每次执行所返回的整数可以不一致。 2.如果两个对象根据equals()方法比较是相等的，那么调用这两个对象中任意一个对象的hashCode方法都必须产生同样的整数结果。 3.如果两个对象根据equals()方法比较是不相等的，那么调用这两个对象中任意一个对象的hashCode方法，则不一定要产生相同的整数结果。但是程序员应该知道，给不相等的对象产生截然不同的整数结果，有可能提高散列表的性能。]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java常见集合系列]]></title>
    <url>%2F2019%2F03%2F07%2Fjava%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[1.java集合框架体系图 2.常见Map家族2.1 HashMap&nbsp;&nbsp;&nbsp;&nbsp;HashMap 是基于哈希表的 Map 接口的非同步实现。此实现提供所有可选的映射操作，HashMap最多只允许一条记录的键为null，允许多条记录的值为null。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。&nbsp;&nbsp;&nbsp;&nbsp;HashMap的底层数据结构是数组+链表。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法。其put方法的实现过程是，首先根据key的hashcode，进行高位运算，取模运算，并将结果作为数组下标，如果该位置已有值，则通过equals方法比较二者是否相等，如果相等则用新值覆盖旧值，如若不等，则将新建链表节点并插在已存节点的前面。同理，get方法的实现首先计算key的hashcode找到数组下标，通过equals方法比较链表中相等的键，然后返回该节点的value。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，put方法实现时可能存在扩容过程。因为Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。为了解resize机制，先看构造函数参数源码：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int threshold; //所能容纳的key-value对极限&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;final float loadFactor; // 负载因子&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int modCount;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int size;&nbsp;&nbsp;&nbsp;&nbsp;首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。&nbsp;&nbsp;&nbsp;&nbsp;结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择。&nbsp;&nbsp;&nbsp;&nbsp;size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。&nbsp;&nbsp;&nbsp;&nbsp;这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。 2.2 LinkedHashMap&nbsp;&nbsp;&nbsp;&nbsp;LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。在LinkedHashMap中，是通过双联表的结构来维护节点的顺序的，其他处理逻辑与HashMap一致，同样也没有锁保护，多线程使用存在风险。 2.3 TreeMap&nbsp;&nbsp;&nbsp;&nbsp;TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。底层是红黑树。 2.4 HashTable&nbsp;&nbsp;&nbsp;&nbsp;Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 3.常见List家族3.1 ArrayList&nbsp;&nbsp;&nbsp;&nbsp;ArrayList实现了可变大小的数组。它允许所有元素，包括null。ArrayList是基于数组实现的，是一个动态数组，其容量能自动增长，类似于C语言中的动态申请内存，动态增长内存。size，isEmpty，get，set方法运行时间为常数。但是add方法开销为分摊的常数，添加n个元素需要O(n)的时间。其他的方法运行时间为线性。&nbsp;&nbsp;&nbsp;&nbsp;每个ArrayList实例都有一个容量（Capacity），即用于存储元素的数组的大小。这个容量可随着不断添加新元素而自动增加，但是增长算法并 没有定义。当需要插入大量元素时，在插入前可以调用ensureCapacity方法来增加ArrayList的容量以提高插入效率。ArrayList是非同步的（unsynchronized）。特点是：寻址容易，插入和删除困难； 3.2 LinkedList&nbsp;&nbsp;&nbsp;&nbsp;LinkedList实现了List接口，允许null元素，底层是一个链表。此外LinkedList提供额外的get，remove，insert方法在 LinkedList的首部或尾部。这些操作使LinkedList可被用作堆栈（stack），队列（queue）或双向队列（deque）。它也是非同步的。 3.3 Vector&nbsp;&nbsp;&nbsp;&nbsp;Vector非常类似ArrayList，但是Vector是同步的。由Vector创建的Iterator，虽然和ArrayList创建的 Iterator是同一接口，但是，因为Vector是同步的，当一个Iterator被创建而且正在被使用，另一个线程改变了Vector的状态（例 如，添加或删除了一些元素），这时调用Iterator的方法时将抛出ConcurrentModificationException，因此必须捕获该 异常。 3.4 Stack&nbsp;&nbsp;&nbsp;&nbsp;Stack继承自Vector，实现一个后进先出的堆栈。Stack提供5个额外的方法使得 Vector得以被当作堆栈使用。基本的push和pop 方法，还有peek方法得到栈顶的元素，empty方法测试堆栈是否为空，search方法检测一个元素在堆栈中的位置。Stack刚创建后是空栈。 3.常见Set家族4.1 HashSet&nbsp;&nbsp;&nbsp;&nbsp;它不允许出现重复元素(根据hashCode比较)；&nbsp;&nbsp;&nbsp;&nbsp;不保证集合中元素的顺序&nbsp;&nbsp;&nbsp;&nbsp;允许包含值为null的元素，但最多只能有一个null元素。&nbsp;&nbsp;&nbsp;&nbsp;HashSet的实现是不同步的。&nbsp;&nbsp;&nbsp;&nbsp;HashSet的底层通过HashMap实现的。而HashMap在1.7之前使用的是数组+链表实现，在1.8+使用的数组+链表+红黑树实现。其实也可以这样理解，HashSet的底层实现和HashMap使用的是相同的方式，因为Map是无序的，因此HashSet也无法保证顺序。&nbsp;&nbsp;&nbsp;&nbsp;HashSet的方法，也是借助HashMap的方法来实现的。HashSet中的元素都存放在HashMap的key上面，而value中的值都是统一的一个private static final Object PRESENT = new Object();。 4.2 LinkedHashSet&nbsp;&nbsp;&nbsp;&nbsp;对于LinkedHashSet而言，它继承于HashSet、又基于LinkedHashMap来实现的。LinkedHashSet底层使用LinkedHashMap来保存所有元素，它继承于HashSet，其所有的方法操作上又与HashSet相同。&nbsp;&nbsp;&nbsp;&nbsp;LinkedHashSet是具有可预知迭代顺序的Set接口的哈希表和链接列表实现。此实现与HashSet的不同之处在于，后者维护着一个运行于所有条目的双重链接列表。此链接列表定义了迭代顺序，该迭代顺序可为插入顺序或是访问顺序。此实现不是同步的。 4.3 TreeSet&nbsp;&nbsp;&nbsp;&nbsp;TreeSet类实现 Set 接口，该接口由 TreeMap 实例支持。此类保证排序后的 set 按照升序排列元素，根据使用的构造方法不同，可能会按照元素的自然顺序 进行排序，或按照在创建 set 时所提供的比较器进行排序。&nbsp;&nbsp;&nbsp;&nbsp;TreeSet描述的是Set的一种变体——可以实现排序等功能的集合，它在将对象元素添加到集合中时会自动按照某种比较规则将其插入到有序的对象序列中.&nbsp;&nbsp;&nbsp;&nbsp;HashSet是基于Hash算法实现的,其性能通常优于TreeSet,我们通常都应该使用HashSet,在我们需要排序的功能时,我门才使用TreeSet;TreeSet是非同步的，线程不安全的。 4.4 HashSet，TreeSet，LinkedHashSet之间的区别&nbsp;&nbsp;&nbsp;&nbsp;HashSet只去重，TreeSet去重并排序，LinkedHashSet去重并保留插入顺序 5.List 、Set、 Map有什么区别和联系&nbsp;&nbsp;&nbsp;&nbsp;list 和set 有共同的父类 它们的用法也是一样的 唯一的不太就是set中不能有相同的元素 list中可以&nbsp;&nbsp;&nbsp;&nbsp;list和set的用途非常广泛 list可以完全代替数组来使用&nbsp;&nbsp;&nbsp;&nbsp;map 是独立的合集 它使用键值对的方式来储存数据 键不能有重复的 值可以用&nbsp;&nbsp;&nbsp;&nbsp;map不像上边两种集合那个用的广泛 不过在servlet 和jsp中map可是绝对的重中之重 页面之间传值全靠map]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典排序算法]]></title>
    <url>%2F2019%2F03%2F07%2F%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序算法是最经典的算法知识。因为其实现代码短，应该广，在面试中经常会问到排序算法及其相关的问题。一般在面试中最常考的是快速排序和归并排序等基本的排序算法，并且经常要求现场手写基本的排序算法。如果这些问题回答不好，估计面试就凉凉了。所以熟练掌握排序算法思想及其特点并能够熟练地手写代码至关重要。 下面介绍几种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、基数排序的思想，其代码均采用Java实现。 1.冒泡排序1.1.思想 冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端 1.2.算法描述比较相邻的元素。如果第一个比第二个大，就交换它们两个；对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；针对所有的元素重复以上的步骤，除了最后一个；重复步骤1~3，直到排序完成 1.3.动画演示 1.4.代码实现public static int[] bubble(int[] a){ int temp = 0; for (int i=0;i&lt;a.length;i++){//遍历整个数组 for (int j=0;j&lt;a.length-1-i;j++){//每次遍历跟相邻比较 if (a[j]&gt;a[j+1]){ //把大的值往后放 temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; } }//一次循环后就能把最大值（最小值）浮动到数组尾（头） } return a; } 2.选择排序2.1 思想选择排序是一种简单直观的排序算法，它也是一种交换排序算法，和冒泡排序有一定的相似度，可以认为选择排序是冒泡排序的一种改进。 2.2算法描述在未排序序列中找到最小（大）元素，存放到排序序列的起始位置从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。重复第二步，直到所有元素均排序完毕。 2.3.动画演示 2.4.代码实现 public static int[] select(int[] array){ int temp = 0; for (int i=0;i&lt;array.length;i++){ for (int j=i+1;j&lt;array.length;j++){//每次当前值都和后面所有值比较，找到比它小的就交换 if (array[i]&gt;array[j]){ temp = array[i]; array[i] = array[j]; array[j] = temp; } }//每次循环结束，就能找到相对最小值放在数组起那么 } return array; } //改进选择排序，记录最小值下标，只交换一次 public static int[] select2(int[] array){ int temp = 0; for (int i=0;i&lt;array.length;i++){ int minIndex = i; //记录下标值 for (int j=i+1;j&lt;array.length;j++){ if (array[minIndex]&gt;array[j]){ minIndex = j; } } temp = array[i]; array[i] = array[minIndex]; array[minIndex] = temp; } return array; } 3.插入排序3.1.思想插入排序是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。 3.2.算法描述把待排序的数组分成已排序和未排序两部分，初始的时候把第一个元素认为是已排好序的。从第二个元素开始，在已排好序的子数组中寻找到该元素合适的位置并插入该位置。重复上述过程直到最后一个元素被插入有序子数组中。 3.3.动画演示 3.4.代码实现//直插，总是假设前面是有序的，后面往前找到合适的位置插入 public static int[] insert(int[] a,int n){ int temp = 0 ; int j; for (int i=0;i&lt;n;i++){//遍历全部 temp = a[i+1]; //暂存当前的下一个 j=i; //j从当前开始 while (j&gt;-1&amp;&amp;temp&lt;a[j]){//如果后面的值小于当前值，进入循环 a[j+1] = a[j]; //temp已经存了下一个的值，可以直接覆盖 j--; } a[j+1] = temp; //恢复覆盖的值 } return a; } 4.归并排序4.1.思想归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。 4.2.算法描述迭代法（Bottom-up）原理如下（假设序列共有n个元素）： 将序列每相邻两个数字进行归并操作，形成ceil(n/2)个序列，排序后每个序列包含两/一个元素若此时序列数不是1个则将上述序列再次归并，形成ceil(n/4)个序列，每个序列包含四/三个元素重复步骤2，直到所有元素排序完毕，即序列数为1 4.3.动画演示 4.4.代码实现//归并，借助辅助交换数组,根据k长度进行归并 public static int[] merge(int[] a,int k){//k是分组的长度 int aLeft = 0; //第分组起始下标 int aRight; //a分组终止下标 int bLeft; //b分组起始下标 int bRight; //第分组终止下标 int[] swap = new int[a.length];//等长辅助数组 int m = 0; //m记录辅助数组下标位置 int i,j; //i记录a分组遍历，b记录b分组遍历 while (aLeft+k&lt;=a.length-1){//从相邻分组b起始遍历，将b往a里合并 bLeft = aLeft+k; //b分组的起始下标=第1分组起始+分组长度 aRight = bLeft-1; //a分组的终止是b分组起始往前退1 bRight = (bLeft+k&gt;a.length)? a.length-1:bLeft+k-1;//b分组=b起始+长度，但是不能超高a数组总长度 for (i=aLeft,j=bLeft;i&lt;=aRight&amp;&amp;j&lt;=bRight;m++){//从a分组开始扫描比较 if (a[j]&gt;=a[i]){//如果a分组小，放入辅助数组，a分组前进 swap[m] = a[i]; i++; }else {//如果b分组小，放入辅助数组，b分组前进 swap[m] = a[j]; j++; } } //遍历结束，一定至少有一个分组已经合并完 while (i&lt;=aRight){//如果a分组还没合并完 swap[m++] = a[i++]; //剩余数据压入辅助数组 } while (j&lt;=bRight){//如果b分组还没合并完 swap[m++] = a[j++]; } aLeft = bRight+1;//a,b合并完后下一个新a分组从旧b分组长度+1开始 } //此时所有能完整分组的已经合并完，剩下分组长度不足数的 for (i=aLeft;i&lt;a.length;i++){//从不足数分组起始遍历 swap[m++] = a[i]; //全部压入辅助数组中 } return swap; } //合并长度长1，2,2k... public static int[] mergeSort(int[] a){ int i,k=1; while (k&lt;a.length){ a = merge(a,k ); k = 2*k; } return a; } 5.快速排序5.1.思想快速排序是一个知名度极高的排序算法，其对于大数据的优秀排序性能和相同复杂度算法中相对简单的实现使它注定得到比其他算法更多的宠爱。 5.2.算法描述从数列中挑出一个元素，称为”基准”（pivot），重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任何一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。 5.3.动画演示 5.4代码实现//快排,从第一个元素开始，比他小的在左边，比他大的在右边，递归左右 public static int[] quick(int[] a,int left,int right){ int temp = a[left];//总是从最左第一个 int i = left; int j = right; while (i&lt;j){ while (i&lt;j&amp;&amp;temp&lt;=a[j]){//从右到左，找第一个比它小的 j--; } if (i&lt;j){//如果找到了 a[i] = a[j];//将比它大的值移到最右左边 i++; //左边距离前进一个单位 } while (i&lt;j&amp;&amp;a[i]&lt;temp){//从左向右，找第一个比它大的 i++; } if (i&lt;j){//如果找到了 a[j] = a[i];//将比他小的移到右边 j--; //右边距离缩短一个单位 } a[i] = temp; //找到了合适的位置放进去，左边都比它小，右边都比它大 } if (i&gt;left)quick(a,left ,i-1 );//递归左边的子集 if (i&lt;right)quick(a,j+1 ,right );//递归右边的子集 return a; } 6.堆排序6.1.思想堆排序(Heapsort)是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位指定索引的元素。堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。 6.1.1.堆概念堆是一种特殊的完全二叉树（complete binary tree）。完全二叉树的一个“优秀”的性质是，除了最底层之外，每一层都是满的，这使得堆可以利用数组来表示（普通的一般的二叉树通常用链表作为基本容器表示），每一个结点对应数组中的一个元素。如下图，是一个堆和数组的相互关系：对于给定的某个结点的下标 i，可以很容易的计算出这个结点的父结点、孩子结点的下标： Parent(i) = floor(i/2)，i 的父节点下标Left(i) = 2i，i 的左子节点下标Right(i) = 2i + 1，i 的右子节点下标二叉堆一般分为两种：最大堆和最小堆。最大堆中的最大元素值出现在根结点（堆顶）堆中每个父节点的元素值都大于等于其孩子结点（如果存在）最小堆中的最小元素值出现在根结点（堆顶）堆中每个父节点的元素值都小于等于其孩子结点（如果存在） 6.2.算法描述堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。在堆中定义以下几种操作： 最大堆调整（Max-Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点创建最大堆（Build-Max-Heap）：将堆所有数据重新排序，使其成为最大堆堆排序（Heap-Sort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算 继续进行下面的讨论前，需要注意的一个问题是：数组都是 Zero-Based，这就意味着我们的堆数据结构模型要发生改变 6.3.动画演示6.4代码实现//堆排序(最大堆) public static int[] heap(int[] a){ int temp = 0; initHeap(a,a.length ); //2.1初始化堆，将无序序列构造为堆。 for (int i=a.length-1;i&gt;0;i--){ temp = a[0]; //2.2 弹出堆顶 a[0] = a[i]; a[i] = temp; //将最大值放入数组尾 createHeap(a, 0,i );//2.3,缩小建堆范围，重新构建堆 } return a; } //从第一个非叶子节点开始建堆 public static int[] initHeap(int[] a,int n){ for (int i= (a.length-2)/2;i&gt;=0;i--){ a = createHeap(a,i,a.length); } return a; } //以h为建堆顶点,建立并调整堆 public static int[] createHeap(int[] a,int h,int n){ int i,j,tag;//tag循环结束条件（调整节点比左右都大直接出来） i = h; // i是要建堆的节点下标 j=2*i+1; //建堆节点的左孩子 int temp = a[i]; tag = 0; while (j&lt;n&amp;&amp;tag!=1){ if (j&lt;n-1&amp;&amp;a[j]&lt;a[j+1])j++;//比较左右，取大值 if (temp&gt;a[j]){ tag = 1; }else {//调整建堆顶点，向下调整 a[i] = a[j]; i = j; j = 2*i+1; } } a[i] = temp; return a; } 7.希尔排序7.1.思想在希尔排序出现之前，计算机界普遍存在“排序算法不可能突破O(n2)”的观点。希尔排序是第一个突破O(n2)的排序算法，它是简单插入排序的改进版。希尔排序的提出，主要基于以下两点：插入排序算法在数组基本有序的情况下，可以近似达到O(n)复杂度，效率极高。但插入排序每次只能将数据移动一位，在数组较大且基本无序的情况下性能会迅速恶化。 7.2.算法描述先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；按增量序列个数k，对序列进行 k 趟排序；每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 7.3.动画演示 7.4代码实现//希尔，把数组按步长分组，每组分别进行直插排序 public static int[] shell(int[]a,int[] spans){ int span; for (int i=0;i&lt;spans.length;i++){//遍历希尔步长次 span = spans[i]; for (int k=0;k&lt;span;k++){//全部数据按照步长分组 for (int j=k;j+span&lt;a.length;j+=span){//对每个分组进行直插排序 int t =j; int temp = a[j+span]; while (t&gt;-1&amp;&amp;a[t]&gt;temp){ a[t+span] = a[t]; t -= span; } a[t+span] = temp; } } } return a; } 8.基数排序8.1.思想基数排序(Radix Sort)是桶排序的扩展，它的基本思想是：将整数按位数切割成不同的数字，然后按每个位数分别比较。排序过程：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。 8.2算法描述取得数组中的最大数，并取得位数；arr为原始数组，从最低位开始取每个位组成radix数组；对radix进行计数排序（利用计数排序适用于小范围数的特点）； 8.3.动画演示 8.4代码实现基数（桶）借用链式队列数组，按位填入 public static int[] radix(int[] a,int m){//m表示最大整数有m位 LinkedBlockingQueue&lt;Integer&gt;[] bucket = new LinkedBlockingQueue[10];//因为是10进制，所以需要10个桶 for (int i=0;i&lt;bucket.length;i++){ //初始化每个队列 bucket[i] = new LinkedBlockingQueue(); } Integer pop; //保存从桶中弹出的数 for (int i=1;i&lt;=m;i++){ //根据位数遍历 for (int j=0;j&lt;a.length;j++){ //低位开始第i位，取出每个数字对应的位数作为桶下标， double val = Math.floor(a[j]/Math.pow(10,i-1))-10*Math.floor(a[j]/Math.pow(10,i));//取位公式 bucket[(int)val] .add(a[j]); //放入桶中 } int c=0; for (int k=0;k&lt;bucket.length;k++){ //遍历所有桶 while ((pop=bucket[k].poll())!=null){ //取出数据重新放入a中 a[c++] = pop; } } } return a; } 9.算法比较总结]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>tag 算法</tag>
        <tag>tag 排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git基本命令]]></title>
    <url>%2F2019%2F03%2F06%2Fgit%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[工作区-暂存区-本地仓库-远程仓库关系对于任何一个文件，在 Git 内都只有三种状态：已提交（committed），已修改（modified）和已暂存（staged）。已提交表示该文件已经被安全地保存在本地仓库中了；已修改表示修改了某个文件，但还没有提交保存；已暂存表示把已修改的文件放在下次提交时要保存的清单中。将本地仓库与远程仓库关联，然后可以将本地仓库内容推送到远程仓库中。 本地仓库基本操作创建本地仓库mkdir test #创建本地仓库工作目录 git init #初始化本地仓库 echo &quot;first file&quot; &gt;&gt; #test.txt 在工作目录test里添加文件 git add test.txt #将工作目录里的文件添加到暂存区 git commit -m &quot;first commit&quot; #将暂存区里的文件提交到版本地仓库 删除回退操作修改了文件内容并add了文件,但尚未commit,回退到修改前git reset HEAD test.txt git checkout -- test.txt 修改了文件内容并commit了文件，回退git log #拿到commit-id git reset --hard &quot;commit-id&quot; #执行回退 清空本地仓库git rm test.txt #删了文件，暂存区还有记录 git commit -m &quot;delete&quot; #提交删除，清空暂存区 远程仓库创建ssh key1.ssh-keygen -t rsa &quot;yourmail@example.com&quot; #创建ssh key 2.到用户目录下的.ssh文件夹 复制.pub到github构建ssh key 3.ssh -T git@github.com 测试是否连接成功 创建本地仓库，并提交到github远程仓库mkdir test2 echo &quot;test2&quot; &gt;&gt; README.md git init git add README.md git commit -m &quot;test2&quot; git remote add origin yourgithbub@name.git #添加一个新的远程仓库 git push -u origin master #(推送到远程仓库。-u等于关联，后面可以直接git push) 克隆远程仓库，修改文件并提交git clone yourgithub@name.git #克隆远程仓库 cd name #进入目录 echo &quot;clone add file&quot; &gt;&gt; test3.txt git add test3.txt git commit -m &quot;clone&quot; git push 标签关联git tag #列出所有标签 git tag v1.0.1 #新建标签v1.0.1 git tag -a tagName -m &quot;comment&quot; #创建tag并且添加了附注信息 git push origin --tags v1.0.1 #将tag推送到远程仓库 git tag -d tagName #删除tag 分支管理git branch #列出所有分支 git branch name #新建分支name git checkout name #切换到name分支 echo &quot;in branch&quot; &gt;&gt; branch.txt git add branch.txt git commit -m &quot;branch&quot; git push --set-upstream origin name #将name分支提交到远程仓库 check out master git merge name #合并分支 git branch -d name #删除分支 git fetch origin dev:dev #将远程的dev分支拉取到本地的dev分支 git pull origin master:brantest #pull=fetch+merge,将远程的mater分支fetch下来并和branchtest合并]]></content>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存模型]]></title>
    <url>%2F2019%2F03%2F06%2FJVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[1.首先看个整体图 2.内存模型解释2.1.程序计数器&nbsp;&nbsp;&nbsp;&nbsp;当前线程所执行字节码的行号指示器，通过改变它的值来选取下一条指令。分支、循环、异常处理、线程恢复等都需要依赖它。它也是唯一一个不会抛出OutOfMemoryError异常的区域。 2.2.虚拟机栈(java栈)&nbsp;&nbsp;&nbsp;&nbsp;java栈描述java方法执行的内存模型。一个方法的执行时，会虚拟机会创建一个栈帧，存储局部变量表，操作数栈等。方法的调用到执行结束，相当于java栈的入栈出栈。该区域可能会产生两种异常。线程请求的栈的深度大于虚拟机允许的最大深度，抛出StackOverflowError。若该栈支持动态拓展（一般都支持），扩展时无法申请到足够的内存，抛出OutOfMemoryError异常。 2.3.本地方法栈&nbsp;&nbsp;&nbsp;&nbsp;本地方法栈与java栈功能差不多，只是java栈为java程序方法服务，而它为本地方法服务。有的虚拟机（如sun HotSpot）甚至会把二者合二为一。 如java栈一样，该区域也会抛StackOverflowError、OutOfMemoryError异常。 2.4.JAVA堆&nbsp;&nbsp;&nbsp;&nbsp;对于大多数应用来说，java堆是虚拟机管理的内存中分配最大的一部分。java堆是被所有线程共享的一块内存区域。&nbsp;&nbsp;&nbsp;&nbsp;虚拟机启动时便创建。存放对象实例，几乎所有的对象实例都在这里分配内存。该区域也是垃圾收集器管理的主要区域，因此很多时候也被称为GC堆。&nbsp;&nbsp;&nbsp;&nbsp;细分出来，该区域可以分为新生代，老年代，新生代可以再分为一个Eden空间，两个Survivor空间（from survivor，to survivor）。不论如何划分，存放的始终是实例对象。进一步划分的目的是利于回收内存，或者更快的分配内存。(内存收集器基本采用分代收集的方法)&nbsp;&nbsp;&nbsp;&nbsp;java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。如果在堆中没有内存完成实例分配，且堆无法再拓展，将会抛出OutOfMemoryError异常。 2.5.方法区&nbsp;&nbsp;&nbsp;&nbsp;方法区与java堆一样，都是线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器（JIT)编译后的代码等数据。java虚拟机规范把方法区描述为java堆的一个逻辑部分，习惯在HotSpot虚拟机上开发的程序员更愿意称其为”永久代”。&nbsp;&nbsp;&nbsp;&nbsp;当方法区无法满足内存分配需求时，将会抛出OutOfMemoryError异常。 2.6.运行时常量池&nbsp;&nbsp;&nbsp;&nbsp;运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容在类加载后将进入方法区的运行时常量池中存放。&nbsp;&nbsp;&nbsp;&nbsp;作为方法区的一部分，运行时常量池受内存限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 3.一个对象的一辈子&nbsp;&nbsp;&nbsp;&nbsp;我是一个普通的java对象，我出生在Eden区，在Eden区我还看到和我长的很像的小兄弟，我们在Eden区中玩了挺长时间。有一天Eden区中的人实在是太多了，我就被迫去了Survivor区的“From”区，自从去了Survivor区，我就开始漂了，有时候在Survivor的“From”区，有时候在Survivor的“To”区，居无定所。直到我18岁的时候，爸爸说我成人了，该去社会上闯闯了。于是我就去了年老代那边，年老代里，人很多，并且年龄都挺大的，我在这里也认识了很多人。在年老代里，我生活了20年(每次GC加一岁)，然后被回收。 &nbsp;&nbsp;&nbsp;&nbsp;1、一个人（对象）出来（new 出来）后会在Eden Space（伊甸园）无忧无虑的生活，直到GC到来打破了他们平静的生活。GC会逐一问清楚每个对象的情况，有没有钱（此对象的引用）啊，因为GC想赚钱呀，有钱的才可以敲诈嘛。然后富人就会进入Survivor Space（幸存者区），穷人的就直接kill掉。&nbsp;&nbsp;&nbsp;&nbsp;2、并不是进入Survivor Space（幸存者区）后就保证人身是安全的，但至少可以活段时间。GC会定期（可以自定义）会对这些人进行敲诈，亿万富翁每次都给钱，GC很满意，就让其进入了Genured Gen(养老区)。万元户经不住几次敲诈就没钱了，GC看没有啥价值啦，就直接kill掉了。&nbsp;&nbsp;&nbsp;&nbsp;3、进入到养老区的人基本就可以保证人身安全啦，但是亿万富豪有的也会挥霍成穷光蛋，只要钱没了，GC还是kill掉。&nbsp;&nbsp;&nbsp;&nbsp;分区的目的：新生区由于对象产生的比较多并且大都是朝生夕灭的，所以直接采用标记-清理算法。而养老区生命力很强，则采用复制算法，针对不同情况使用不同算法]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jsp开发过程中的乱码问题及其解决方案]]></title>
    <url>%2F2018%2F10%2F10%2Fjsp%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[jsp开发过程中的乱码问题及其解决方案1.必须先理清的关系jsp开发过程中,我们会看到page指令里有pageEncoding，contentType里的charset（后面一律简称charset),而浏览器自己也可以设置页面的编码格式。首先，pageEncoding表明，你这个文件将以什么编码形式保存起来。charset表明，你希望这里的代码以什么编码展示在浏览器上。浏览器自己也可以设置编码方式，当你的charset与浏览器不对应时就会出现乱码。 2.常见的几种编码 ISO-8895-1编码是单字节编码，因而可以达到数据无损,但不支持中文。 UTF-8编码多字节编码，支持中文等多种语言，是很通用的编码方式 gbk2312编码是针对中文而弄的一种编码 … 3.必须要知道的一些默认编码首先，get请求和post请求携带参数的方式不同（get直接在url上) 对于post请求，中文编码方式会受到上面提到的pageEncoding，charset，以及jsp内置对象request和response的setCharacterEncoding方法影响，后面会具体说明。 对于get请求，其中文编码会受到charset以及Tomcat服务器的配置信息影响，配置的是URLEncoding，在/conf/servlet.xml的文件中。据了解，Tomcat7及以下，默认采用ISO-8895-1,Tomcat8及以上采用UTF-8。 jsp中,request对象获取参数中需要特别注意到的一点是，对于get请求，采用request.getQueryString()得到的参数和用request.getParameter()得到的参数编码是不同的，因为方法getParameter()将会采用Tomcat服务器配置的URLEncoding自动解码一次,而getQueryString()会受到charset的影响 4.正式讲讲jsp中的编码问题 首先强调一点，内置对象的setCharacterEncoding只对post请求有效 对于post请求，当发送端用了response.setCharacterEncoding(Xxx),即设置了响应的编码格式，那么在服务器端，你可以选择用request.setCharacterEncoding(Xxx),即设置请求的编码方式来解决中文乱码问题。这一Xxx是必须一致的，response对应request。又或者，你可以自己手动转码的方式，把通过request.getParameter()得到的乱码数据data采用java.net.URLDecoder.decode(data, “Xxx”)或者new String(data.getBytes(“ISO-8895-1”),”Xxx”)从而解决乱码问题。当发送端没有设置response.setCharacterEncoding，那么此时需要参照contentType里的charset,这里的charset等价于上面的Xxx,依然可以用上述两种方式解决乱码问题。举个例子,A页面charset是utf-8，response.setCharacterEncoding是gbk2312，此时打开浏览器会是乱码，可以设置浏览器的编码为gbk，编码正常，而B页面charset也是utf-8，request.setCharacterEncoding必须是gbk，打印获取到的结果，在浏览器上还是乱码，因为浏览器在上一步被你设置成了gbk，换行utf-8正常。所以尽量控制charset与setCharacterEncoding是一致的 对于get请求，发送端的中文编码取决charset设置的编码方式，假如是utf-8，到了服务端的时候，若使用request.getParameter()，而此时你的Tomcat的URLEncoding是UTF-8,那么会自动用utf-8帮你解码一次，因而是不会出现乱码的情况。此时如果调用getQueryString(),打印的结果就是用charset设置utf-8编码方式编码的结果，需要手动解码回正常中文。 有一种无法挽回的特殊情况是，对于get请求，若发送端你的charset设置的是gbk2312，到了服务器端，假如你的Tomcat的URLEncoding是UTF-8，你用request.getParameter()获取参数，整个过程就等价于数据用了gbk2312编码，却用了utf-8自动解码，这样就会造成数据无法转回来了。当然此时你通过getQueryString()得到的数据通过解gbk2312码是可以得到正常结果的。 5.建议 控制contentType里的charset与pageEncoding与setCharacterEncoding()一致 对于中文数据尽量不用get请求提交，毕竟可能会造成上述说的无法挽回的结果。 可以设置拦截器，对请求统一进行编码，就不用一个页面调用设置编码的函数了]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jsp</tag>
        <tag>中文乱码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈社团招新]]></title>
    <url>%2F2018%2F09%2F06%2F%E8%B0%88%E7%A4%BE%E5%9B%A2%E6%8B%9B%E6%96%B0%2F</url>
    <content type="text"><![CDATA[1 自从开学后，就开始准备招新事宜，我留任校团委网络中心，已经大三的我，不论当时留下来的原因是什么，如今尘埃落定，居其位,思其责，做其事。我其实很想逃避这些东西，但如今我逃避不了了。谈起招新，谈起扫楼，谈起跟其他组织竞争，可能有人会在背后说闲话，但我只能说，我只是在尽力做我能做的事情，没有恶意，我只是提供了一个选择，一个通往我部门的选择而已。但似乎，从其他人眼中，我所做的似有不妥。可能毕竟是竞争，可能我做的还不够好。 2我渐渐觉得社团是一个很迷的地方。如果一个人，坚持了一开始的想法，那么可能他就是体验社团一年，尝尝新鲜感，留下美好的回忆，然后大二离场。有的人，开始很融入这个社团，然后开始改变自己，改变想法，成功地走上了一条新的路，或者说被社团改造。我不能说这两种情况哪一个比较好，毕竟未来谁能预料地到。社团这条路，一开始，一群人挤着抢着上车，司机也各显神通地邀请，然而讽刺的是，到最后，幸运的人成功的进入了社团，可怜的人，从被抢来抢去，到被抛来抛去，最后再也鼓不起勇气去报其他。而更讽刺的是，某些幸运的人没有做出他应该做到的表现，而当时如果招入的是其他人，结局也又未可知。这时，我们往往会说，这就是命，或者说，缘分使然，感怀亦是徒然。 3不知为何，我开始会想很多东西，考虑很多东西，我开始担心自己做的不够好，我甚至害怕带不起他们。我开始为这些事操心，明明，我应该大胆放手，让他们成长。我似乎很自卑，但在一部分人眼中，我好像也很“完美”。我感觉我变了，我开始想写一些感受，我的话开始变的很多。 4我的大学只选择了一个社团，可能我是无法体会到那些报了多个社团的人的感受，我甚至都无法去评论，因为那样显得很片面。而有的人也是只选择了一个社团，但是他却也局限于只了解这一社团，似有井底之蛙之嫌。谈到社团，却又不得不提归属感一词，有的人愿意为部门付出很多，而且无怨无悔，甚至乐此不疲，而有的人唯恐避之不及。有的人只想得到什么，不打算去付出。我不知道每一个他们是怎么想的，我也不知道他们是否认真考虑过它的意义。或许是我的成长环境决定了我的所思所想，在外人看来觉得完全没有必要去做某些我认为才是真正该做该学的事。但想回来，我应该是个利己主义者，但为何偏偏去替他人担忧他的未来。是因为他们过的比我洒脱，我需要自我安慰自己？我想有部分原因是这样的。可是明明，我对自己的未来都没能把控好，但何苦去评判他人。这一点，我不知道为什么，或者说，我还没能想到这一层。 5走走停停，大学就这么过去了，可能毕业后的自己，回想如今，又是千思百绪，又或者嘲笑自己。甚至于说，多年之后，我才记起，我在大三的招新工作里，写了这么一篇文章。如果现在的我，无意间翻到了初中时的我写的东西，多么稚嫩，却也很美好。]]></content>
      <categories>
        <category>我说</category>
      </categories>
      <tags>
        <tag>生活闲谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http模拟登陆]]></title>
    <url>%2F2018%2F09%2F03%2Fhttp%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86%2F</url>
    <content type="text"><![CDATA[使用java作为后台语言，实现带验证码的模拟登陆。采用springboot快速开发。简单而言，过程分两步 一、获取验证码图片通过抓包工具如fiddler等，或者直接在浏览器控制台找到获取验证码图片的url。然后后台发起http请求，拿到图片并展示。 如下获取验证码图片函数 private void getImg(HttpServletResponse response){ HttpGet get = new HttpGet(&quot;验证码的url&quot;); try { CloseableHttpResponse res = client.execute(get); HttpEntity entity = res.getEntity(); OutputStream out = response.getOutputStream(); byte[] buffer = new byte[1024]; int end; while ((end=entity.getContent().read(buffer))!=-1){ out.write(buffer); } out.close(); response.setContentType(&quot;image/jpeg&quot;);//设置相应类型,告诉浏览器输出的内容为图片 response.setHeader(&quot;Pragma&quot;, &quot;No-cache&quot;);//设置响应头信息，告诉浏览器不要缓存此内容 response.setHeader(&quot;Cache-Control&quot;, &quot;no-cache&quot;); response.setDateHeader(&quot;Expire&quot;, 0); // 将内存中的图片通过流动形式输出到客户端 } catch (IOException e) { e.printStackTrace(); } 二、模拟登陆通过抓包工具如fiddler等，或者直接在浏览器控制台拿到模拟登陆所需要的参数的键值，后台拼接参数后向对应的路径发送请求，一般是post请求，就能正常模拟登陆成功了。 public void doLogin(@RequestParam(&quot;stuid&quot;)String stuid, @RequestParam(&quot;password&quot;)String password, @RequestParam(&quot;code&quot;) String code, HttpServletResponse response2) throws IOException { HttpPost post = new HttpPost(&quot;登陆的url&quot;); //装填参数 List&lt;NameValuePair&gt; nvps = new ArrayList&lt;NameValuePair&gt;(); nvps.add(new BasicNameValuePair(&quot;参数1&quot;,&quot;值1&quot;)); nvps.add(new BasicNameValuePair(&quot;参数1&quot;,&quot;值2&quot; )); post.setEntity(new UrlEncodedFormEntity(nvps, &quot;UTF-8&quot;)); post.setHeader(&quot;Content-type&quot;, &quot;application/x-www-form-urlencoded&quot;); post.setHeader(&quot;User-Agent&quot;, &quot;Mozilla/4.0 (compatible; MSIE 5.0; Windows NT; DigExt)&quot;); CloseableHttpResponse response = client.execute(post); response.close(); 难点模拟难点在于控制cookie的一致，或者说要保证获取验证码时的会话要跟提交参数登陆时的会话保持一致，这样保证验证码是正确的。代码中httpclicent对象最好是全局变量，这样会自动帮我们维持cookie的一致性（同一对象等价于同一个cookie)]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[First]]></title>
    <url>%2F2018%2F08%2F25%2FFirst%2F</url>
    <content type="text"><![CDATA[这是我的第一个博客，喜欢鼓捣很多东西]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F08%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
